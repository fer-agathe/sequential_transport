# Classifier {#sec-classifier}



::: callout-note

## Objectives

This chapter presents classifier (logistic regression) trained on the dataset presented in @sec-data.

:::

```{r setup, message=FALSE, warning=FALSE}
#| code-fold: true
#| code-summary: Display the setting codes

# Required packages----
library(tidyverse)

# Graphs----
font_main = font_title = 'Times New Roman'
extrafont::loadfonts(quiet = T)
face_text='plain'
face_title='plain'
size_title = 14
size_text = 11
legend_size = 11

global_theme <- function() {
  theme_minimal() %+replace%
    theme(
      text = element_text(family = font_main, size = size_text, face = face_text),
      legend.text = element_text(family = font_main, size = legend_size),
      axis.text = element_text(size = size_text, face = face_text), 
      plot.title = element_text(
        family = font_title, 
        size = size_title, 
        hjust = 0.5
      ),
      plot.subtitle = element_text(hjust = 0.5)
    )
}

# Seed
set.seed(2025)

source("../functions/utils.R")
```



Following @Kusner17, a logistic regression model is trained. To convert \(Y\) into a categorical variable, the median is used as a threshold, in line with @black2020fliptest. The race, denoted as the sensitive attribute \(S\), has two categories: White and Black. The dataset is divided into training and testing sets. The classifier is first trained and used to compute the necessary quantities for counterfactual inference on the training set. Subsequently, the trained classifier is applied to the test set to make predictions and perform counterfactual analyses. The results of the counterfactuals will also be evaluated on the training set due to the limitation that Optimal Transport in the multivariate case cannot be computed for new samples, unlike the methodologies used in FairAdapt (@plevcko2021fairadapt) and the approach developed in this paper.


## Load Data

We load the data obtained in [Chapter -@sec-data-save]:
```{r}
load("../data/df_race.rda")
```

## Pre-processing

First, we transform $Y$ into a binary variable:
```{r define-df_race_c}
med <- median(df_race$Y)
df_race_c <- df_race |> 
  mutate(
    Y_c = ifelse(Y > med, 1, 0)
  ) |> 
  select(S, X1, X2, Y = Y_c)
```

We turn the response variable to a factor:
```{r define-y-factor}
df_race_c$Y <- as.factor(df_race_c$Y)
levels(df_race_c$Y)
```

Let us split the dataset into train/test sets (we use the `split_dataset()`{.R} function defined in `functions/utils.R`):
```{r define-train-test}
seed <- 2025
sets <- split_dataset(df_race_c, seed)
data_train <- sets$data_train
data_test <- sets$data_test
```

## Training the Model

Then, we train two models:

1. **unaware logistic regression classifier**: model without including the sensitive attribute.
2. **aware logistic regression classifier**: model with the sensitive attribute included in the set of features.

The model is trained using the `log_reg_train()`{.R} function defined in `functions/utils.R`:
```{r}
log_reg_train
```
Let us train the two models. Then, we extract the predicted values on both the train set and the test set.

```{r train-classif, message=FALSE, warning=FALSE}
# Unaware logistic regression classifier (model without S)
pred_unaware <- log_reg_train(data_train, data_test, type = "unaware")
pred_unaware_train <- pred_unaware$pred_train
pred_unaware_test <- pred_unaware$pred_test

# Aware logistic regression classifier (model with S)
pred_aware <- log_reg_train(data_train, data_test, type = "aware")
pred_aware_train <- pred_aware$pred_train
pred_aware_test <- pred_aware$pred_test
```

We create a table for each model, with the sensitive attribute and the predicted value by the model (\(\hat{y}\)), only for observations from the test set.
```{r define-df_test_unaware}
df_test_unaware <- tibble(
  S = data_test$S, 
  pred = pred_unaware_test
)

df_test_aware <- tibble(
  S = data_test$S, 
  pred = pred_aware_test
)
```

:::{.panel-tabset}

### Unaware

```{r plot-pred-unaware}
#| fig-cap: Density of predictions on the test set, for the unaware model, when the sensitive attribute is the race
#| label: fig-density-pred-unaware
ggplot(
  data = df_test_unaware, 
  mapping = aes(x = pred, fill = S)) +
  geom_histogram(
    mapping = aes(y = after_stat(density)), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Unaware Model, with S being Race",
    x = "Predictions for Y",
    y = "Density"
  ) +
  global_theme()
```


### Aware

```{r plot-pred-unaware}
#| fig-cap: Density of predictions on the test set, for the aware model, when the sensitive attribute is the race
#| label: fig-density-pred-aware
ggplot(
  data = df_test_aware,
  mapping = aes(x = pred, fill = S)) +
  geom_histogram(
    mapping = aes(y = after_stat(density)), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware Model, with S being Race",
    x = "Predictions for Y",
    y = "Density"
  ) +
  global_theme()
```


:::

## Predictions

We predict values with the unaware model on the factuals:
```{r define-pred_unaware_all}
model_unaware <- pred_unaware$model
pred_unaware_all <- predict(
  model_unaware, 
  newdata = df_race_c |> select(S, X1, X2), 
  type = "response"
)
```

And with the aware model:
```{r define-pred_aware_all}
model_aware <- pred_aware$model
pred_aware_all <- predict(
  model_aware, 
  newdata = df_race_c |> select(S, X1, X2), 
  type = "response"
)
```



## Saving Objects {#sec-classifier-save}

```{r}
save(df_race_c, file = "../data/df_race_c.rda")
save(pred_aware, file = "../data/pred_aware.rda")
save(pred_unaware, file = "../data/pred_unaware.rda")
save(pred_unaware_all, file = "../data/pred_unaware_all.rda")
save(pred_aware_all, file = "../data/pred_aware_all.rda")
```

