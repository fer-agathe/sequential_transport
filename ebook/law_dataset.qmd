# Law Dataset

:::{.callout-note}

## Objective

In this notebook, ...

:::

This law school dataset contains information collected through a survey conducted from 1991 through 1997 by the Law School Admission Council across 163 law schools in the United States of America (@Wightman1998LSACNL). In total, 21,790 law students were tracked through law school, graduation, and sittings for bar exams.

We use the formatted data from @de2024transport, also used by @delara2021transportbased (see the github associated to the paper: <https://github.com/lucasdelara/PI-Fair.git>).

Each row from the raw data gives information for a student. The following characteristics are available:

- `race`: Race of the student (character: Amerindian, Asian, Black, Hispanic, Mexican, Other, Puertorican, White).
- `sex`: Sex of the student (numeric: 1 female, 2 male).
- `LSAT`: LSAT score received by the student (numeric).
- `UGPA`: Undergraduate GPA of the student (numeric).
- `region_first`: region in which the student took their first bar examination (Far West, Great Lakes, Midsouth, Midwest, Mountain West, Northeast, New England, Northwest, South Central, South East) (character)
- `ZFYA`: standardized first-year law school grades (first year average grade, FYA) (numeric).
- `sander_index`: Sander index of the student: weighted average of normalized UGPA and LSAT scores (however, no details are given for this specific dataset, see @sander2004systemic, p. 393) (numeric)
- `first_pf`: Probably a binary variable that indicates whether the student passed on their first trial ? No information is given about this variable... (numeric 0/1).



```{r setup, message=FALSE, warning=FALSE}
#| code-fold: true
#| code-summary: Display the setting codes

# Required packages----
library(wesanderson)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(fairadapt)
library(quantreg)
library(latex2exp)
library(T4transport)

# Graphs----
font_main = font_title = 'Times New Roman'
extrafont::loadfonts(quiet = T)
face_text='plain'
face_title='plain'
size_title = 14
size_text = 11
legend_size = 11

global_theme <- function() {
  theme_minimal() %+replace%
    theme(
      text = element_text(family = font_main, size = size_text, face = face_text),
      legend.text = element_text(family = font_main, size = legend_size),
      axis.text = element_text(size = size_text, face = face_text), 
      plot.title = element_text(
        family = font_title, 
        size = size_title, 
        hjust = 0.5
      ),
      plot.subtitle = element_text(hjust = 0.5)
    )
}

# Colours
colors_ <- wes_palette('Rushmore1')

# Seed
set.seed(2025)

# Use defined functions
source("functions/utils.R")
#source("functions/quantile_reg.R")
source("functions/graphs.R")
```

## Data Pre-Processing

We load the data:
```{r load-data, message=FALSE, warning=FALSE}
df <- read_csv('data/law_data.csv')
```

Then, we focus on a subset of variables of interest:
```{r select-subset-col}
df <- df |> 
  select(
    race,
    sex, # we can take S = gender
    LSAT, # or S = race (white/black)
    UGPA,
    ZFYA # Y
  )
```

We create a dataset where the only protected class is the race:
```{r create-df_race}
# Table for S = race
df_race <- df |> 
  select(
    race,
    UGPA,
    LSAT,
    ZFYA
  ) |> 
  filter(
    race %in% c("White", "Black")
  ) |> 
  rename(
    S = race,
    X1 = UGPA,
    X2 = LSAT,
    Y = ZFYA
  ) |>  # no NA values
  mutate(
    S = as.factor(S)
  )
```

And another dataset in which the only protected class is the sex:
```{r create-df_gender, message=FALSE, warning=FALSE}
# Table for S = gender
df_gender <- df |> 
  select(
    sex,
    UGPA,
    LSAT,
    ZFYA
  ) |> 
  rename(
    S = sex,
    X1 = UGPA,
    X2 = LSAT,
    Y = ZFYA
  ) |>  # no NA values
  mutate(
    S = as.factor(S)
  )
```

:::{panel-tabset}

### S = Race

```{r plot-density-race, message=FALSE, warning=FALSE}
#| fig-cap: Distribution of the standardized first-year law school grades among the two groups, when $S$ is the race
#| label: fig-density-zfya-race
ggplot(
  data = df_race, 
  mapping = aes(x = Y, fill = S)
) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.5
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Race",
    x = "Y",
    y = "Density"
  ) +
  global_theme()
```


### S = Gender

```{r plot-density-gender, message=FALSE, warning=FALSE}
#| fig-cap: Distribution of the standardized first-year law school grades among the two groups, when $S$ is the gender
#| label: fig-density-zfya-gender
ggplot(
  data = df_gender, 
  mapping = aes(x = Y, fill = S)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.5
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Gender",
    x = "Y",
    y = "Density"
  ) +
  global_theme()
```

:::

## Causal graph

The assumed causal graph we use here is different from that of the different papers @de2024transport, @Kusner17, @black2020fliptest using the same dataset.

We make the following assumptions:

- The sensitive attribute, \(S\) (race), has no parents.
- The two other explanatory variables, \(X_1\) (UGPA) and \(X_2\) (LSAT), both directly depend on the sensitive attribute.
- The second variable, \(X_2\) (LSAT), also depends on the first variable, \(X_1\) (UGPA). This is done for illustrative purposes, assuming that the score obtained on the LSAT is influenced by the UGPA.
- The two variables, \(X_1\) (UGPA) and \(X_2\) (LSAT), cause the target variable \(Y\), i.e., whether the student obtained a high standardized first-year average (ZFYA).

The corresponding Structural Equation Model writes:

$$
\begin{cases}
S: \text{ sensitive attribute (race)} \\
X_1 = h_1(S, U_1): \text{ UGPA, dependent on } S \\
X_2 = h_2(S, X_1, U_2): \text{ LSAT, dependent on } S \text{ and } X_1 \\
Y = h_3(X_1, X_2, U_Y): \text{ ZFYA, dependent on } X_1 \text{ and } X_2 \\
\end{cases}
$$

where \(U_1\), \(U_2\), and \(U_Y\) are independent error terms.

In R, we construct the upper triangular adjacency matrix to reflect our assumed causal structure:
```{r causal-set-up, message=FALSE, warning=FALSE}
variables <- colnames(df_race)
# Adjacency matrix: upper triangular
adj <- matrix(
  c(0, 1, 1, 1,
    0, 0, 1, 1,
    0, 0, 0, 1,
    0, 0, 0, 0),
  ncol = length(variables), 
  dimnames = rep(list(variables), 2),
  byrow = TRUE
)
```

Which can be visualized as follows:

```{r}
#| fig-cap: Causal Graph
#| label: fig-causal-graph-race
causal_graph <- fairadapt::graphModel(adj)
plot(causal_graph)
```

The topological order:
```{r}
top_order <- variables
top_order
```


## Classification

Following @Kusner17, a logistic regression model is trained. To convert \(Y\) into a categorical variable, the median is used as a threshold, in line with @black2020fliptest. The race, denoted as the sensitive attribute \(S\), has two categories: White and Black. The dataset is divided into training and testing sets. The classifier is first trained and used to compute the necessary quantities for counterfactual inference on the training set. Subsequently, the trained classifier is applied to the test set to make predictions and perform counterfactual analyses. The results of the counterfactuals will also be evaluated on the training set due to the limitation that Optimal Transport in the multivariate case cannot be computed for new samples, unlike the methodologies used in FairAdapt (@plevcko2021fairadapt) and the approach developed in this paper.


First, we transform $Y$ into a binary variable:
```{r define-df_race_c}
med <- median(df_race$Y)
df_race_c <- df_race |> 
  mutate(
    Y_c = ifelse(Y > med, 1, 0)
  ) |> 
  select(S, X1, X2, Y = Y_c)
```

We turn the response variable to a factor:
```{r define-y-factor}
df_race_c$Y <- as.factor(df_race_c$Y)
levels(df_race_c$Y)
```

Let us split the dataset into train/test sets (we use the `split_dataset()`{.R} function defined in `functions/utils.R`):
```{r define-train-test}
seed <- 2025
sets <- split_dataset(df_race_c, seed)
data_train <- sets$data_train
data_test <- sets$data_test
```

Then, we train two models:

1. **unaware logistic regression classifier**: model without including the sensitive attribute.
2. **aware logistic regression classifier**: model with the sensitive attribute included in the set of features.

The model is trained using the `log_reg_train()`{.R} function defined in `functions/utils.R`:
```{r}
log_reg_train
```
Let us train the two models. Then, we extract the predicted values on both the train set and the test set.

```{r train-classif, message=FALSE, warning=FALSE}
# Unaware logistic regression classifier (model without S)
pred_unaware <- log_reg_train(data_train, data_test, type = "unaware")
pred_unaware_train <- pred_unaware$pred_train
pred_unaware_test <- pred_unaware$pred_test

# Aware logistic regression classifier (model with S)
pred_aware <- log_reg_train(data_train, data_test, type = "aware")
pred_aware_train <- pred_aware$pred_train
pred_aware_test <- pred_aware$pred_test
```

We create a table for each model, with the sensitive attribute and the predicted value by the model (\(\hat{y}\)), only for observations from the test set.
```{r define-df_test_unaware}
df_test_unaware <- tibble(
  S = data_test$S, 
  pred = pred_unaware_test
)

df_test_aware <- tibble(
  S = data_test$S, 
  pred = pred_aware_test
)
```

:::{panel-tabset}

### Unaware

```{r plot-pred-unaware}
#| fig-cap: Density of predictions on the test set, for the unaware model, when the sensitive attribute is the race
#| label: fig-density-pred-unaware
ggplot(
  data = df_test_unaware, 
  mapping = aes(x = pred, fill = S)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Unaware Model, with S being Race",
    x = "Predictions for Y",
    y = "Density"
  ) +
  global_theme()
```


### Aware

```{r plot-pred-unaware}
#| fig-cap: Density of predictions on the test set, for the aware model, when the sensitive attribute is the race
#| label: fig-density-pred-aware
ggplot(
  data = df_test_aware,
  mapping = aes(x = pred, fill = S)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware Model, with S being Race",
    x = "Predictions for Y",
    y = "Density"
  ) +
  global_theme()
```

:::


## Counterfactual inference

Let us now turn to counterfactual inference. We will use three methods:

1. Fairadapt
2. Multivariate optimal transport
3. Sequential transport (the methodology we develop in the paper).

### Fairadapt

We adapt the code from @plevcko2021fairadapt to handle the test set. This avoids estimating cumulative distribution and quantile functions on the test set, which would otherwise necessitate recalculating quantile regression functions for each new sample.

We do not need to adapt Y here, so we need to remove it from the adjacency matrix:
```{r define-fairadapt-adj_wo_Y}
adj_wo_Y <- adj[-4,-4]
adj_wo_Y
```

We create a dataset with the sensitive attribute and the two other predictors:
```{r define-fairadapt-df_race_fpt}
df_race_fpt <- df_race_c |> select(S, X1, X2)
```

Let us have a look at the levels of our sensitive variable:
```{r show-levels-sensitive}
levels(df_race_fpt$S)
```

The reference class here consists of Black individuals.

Two configurations will be considered in turn:

1. The reference class consists of Black individuals, and FairAdapt will be used to obtain the counterfactual UGPA and LSAT scores for White individuals as if they had been Black.
2. The reference class consists of White individuals, and FairAdapt will be used to obtain the counterfactual UGPA and LSAT scores for Black individuals as if they had been White.


```{r fairadapt-application, message=FALSE, warning=FALSE}
# White (factuals) --> Black (counterfactuals)
fpt_model_white <- fairadapt(
  X2 ~ ., 
  train.data = df_race_fpt,
  prot.attr = "S", adj.mat = adj_wo_Y,
  quant.method = linearQuants
)
adapt_df_white <- adaptedData(fpt_model_white)

# Black (factuals) --> White (counterfactuals)
df_race_fpt$S <- factor(df_race_fpt$S, levels = c("White", "Black"))
fpt_model_black <- fairadapt(
  X2 ~ ., 
  train.data = df_race_fpt,
  prot.attr = "S", adj.mat = adj_wo_Y,
  quant.method = linearQuants
)
adapt_df_black <- adaptedData(fpt_model_black)
```

Let us wrap up:

- we have two predictive models for the FYA (above median = 1, or below median = 0): 

  - unaware (without S)
  - aware (with S)

- we have the counterfactual characteristics obtained with fairadapt in two situations depending on the reference class:

  - Black individuals as reference
  - White individuals as reference.
  
The predictive models will be used to compare predictions made using:

- Raw characteristics (initial characteristics).
- Characteristics possibly altered through FairAdapt for individuals who were not in the reference group (i.e., using counterfactuals).

#### Unaware Model

The predicted values using the initial characteristics, for the unaware model:
```{r define-fairadapt-pred_unaware_all}
model_unaware <- pred_unaware$model
pred_unaware_all <- predict(
  model_unaware, newdata = df_race_fpt, type = "response"
)
```

We put in a table the initial characteristics (factuals) and the prediction made by the unaware model:
```{r define-fairadapt-factuals_unaware}
factuals_unaware <- tibble(
  S = df_race$S,
  X1 = df_race$X1,
  X2 = df_race$X2,
  pred = pred_unaware_all
)
```

Let us save this dataset in a csv file (this file will be used to perform multivariate transport in python).
```{r write-fairadapt-factuals_unaware}
write.csv(
  factuals_unaware, 
  file = "data/factuals_unaware.csv", row.names = FALSE
)
```


Let us build a dataset containing only counterfactual characteristics (obtained with fairadapt): values for $X_1$ and $X_2$ of White individuals as if they had been Black, and values for $X_1$ and $X_2$ of Black individuals as if they had been White.
```{r define-fairadapt-df_counterfactuals}
ind_white <- which(df_race_fpt$S == "White")
ind_black <- which(df_race_fpt$S == "Black")
df_counterfactuals_fpt <- factuals_unaware |>  select(-pred)
df_counterfactuals_fpt[ind_white, ] <- 
  adapt_df_white[ind_white, ] |> select(S, X1, X2)
df_counterfactuals_fpt[ind_black, ] <- 
  adapt_df_black[ind_black,] |> select(S, X1, X2)
```

Let us get the predicted values for the counterfactuals, using the unaware model:
```{r define-fairadapt-pred-unaware-counterfactuals}
pred_unaware_fpt <- predict(
  model_unaware, newdata = df_counterfactuals_fpt, type = "response"
)
```

We create a table with the counterfactual characteristics and the prediction by the unaware model:
```{r define-fairadapt-counterfactuals_unaware_fpt}
counterfactuals_unaware_fpt <- tibble(
  S = df_counterfactuals_fpt$S,
  X1 = df_counterfactuals_fpt$X1,
  X2 = df_counterfactuals_fpt$X2,
  pred = pred_unaware_fpt
)
```

We merge the two datasets, `factuals_unaware` and `counterfactuals_unaware_fpt` in a single one. We add a column, `type`, to state whether the row gives the initial observations and predictions or the counterfactuals and correspoonding predictions.
```{r define-fairadapt-unaware_fpt}
# dataset with factuals, for unaware model
factuals_unaware <- factuals_unaware |> mutate(type = "factual")
# dataset with counterfactuals, for unaware model
counterfactuals_unaware_fpt <- counterfactuals_unaware_fpt |> 
  mutate(type = "counterfactual")
# Bind the two:
unaware_fpt <- bind_rows(factuals_unaware, counterfactuals_unaware_fpt)
```

Now, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute. 
```{r define-fairadapt-unaware_fpt_white}
unaware_fpt_white <- unaware_fpt |> filter(S == "White") 
unaware_fpt_black <- unaware_fpt |> filter(S == "Black")
```

:::{panel-tabset}

##### Ref: Black

```{r, message=FALSE, warning=FALSE}
#| fig-cap: "Unaware model, Sensitive: Race, Reference: Black individuals"
#| label: fig-fpt-unaware-race-ref-black
ggplot(unaware_fpt_black, aes(x = pred, fill = type)) +
  geom_histogram(
    aes(y = ..density..), alpha = 0.5, position = "identity", binwidth = 0.05) +
  geom_density(alpha = 0.5) +
  labs(title = "Unaware model, Sensitive: Race, Reference: Black individuals",
       x = "Predictions for Y",
       y = "Density") +
  global_theme()
```

##### Ref: White

```{r, message=FALSE, warning=FALSE}
#| fig-cap: "Unaware model, Sensitive: Race, Reference: White individuals"
#| label: fig-fpt-unaware-race-ref-white
ggplot(
  data = unaware_fpt_white,
  mapping = aes(x = pred, fill = type)
) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Unaware model, Sensitive: Race, Reference: White individuals",
       x = "Predictions for Y",
       y = "Density"
  ) +
  global_theme()
```

:::

#### Aware Model

Now, we turn to the model that includes the sensitive attribute, i.e., the aware model.

The predicted values by the model, on the initial characteristics (on the factuals):
```{r define-fairadapt-pred_aware_all}
model_aware <- pred_aware$model
pred_aware_all <- predict(model_aware, newdata = df_race_fpt, type = "response")
```

We create a tibble with the factuals and the predictions by the aware model:
```{r define-fairadapt-factuals_aware}
factuals_aware <- tibble(
  S = df_race$S,
  X1 = df_race$X1,
  X2 = df_race$X2,
  pred = pred_aware_all
)
```


Let us save this table in a CSV file (this file will be used to perform multivariate transport in python):
```{r}
write.csv(factuals_aware, file = "data/factuals_aware.csv", row.names = FALSE)
```

Recall we created an object called `df_counterfactuals_fpt` which contains the counterfactual characteristics of all students, obtained with fairadapt:
```{r show-df_counterfactuals_fpt}
df_counterfactuals_fpt
```

We make predictions with the aware model on these counterfactuals:
```{r predict-fairadapt-aware-counterfactuals}
pred_aware_fpt <- predict(
  model_aware, newdata = df_counterfactuals_fpt, type = "response"
)
```

Then, we create a table with the counterfactuals and the predicted value by the aware model:
```{r define-fairadapt-counterfactuals_aware}
counterfactuals_aware_fpt <- tibble(
  S = df_counterfactuals_fpt$S,
  X1 = df_counterfactuals_fpt$X1,
  X2 = df_counterfactuals_fpt$X2,
  pred = pred_aware_fpt
)
```


We bind together the table with the factuals and the counterfactuals (as well as their predicted values by the aware model):
```{r define-fairadapt-aware_fpt}
factuals_aware <- factuals_aware |> mutate(type = "factual")
counterfactuals_aware_fpt <- counterfactuals_aware_fpt |> 
  mutate(type = "counterfactual")
aware_fpt <- bind_rows(factuals_aware, counterfactuals_aware_fpt)
```

Lastly, we can visualize the distribution of predicted values by the aware model once the characteristics of the individuals who are not on the reference group have been modified using fairadapt.
```{r fairadapt-aware-ftp_white-black}
aware_fpt_white <- aware_fpt %>% filter(S == "White") 
aware_fpt_black <- aware_fpt %>% filter(S == "Black")
```

:::{panel-tabset}

##### Ref: Black

```{r, message=FALSE, warning=FALSE}
#| fig-cap: "Aware model, Sensitive: Race, Reference: Black individuals"
#| label: fig-fpt-aware-race-ref-black
ggplot(
  data = aware_fpt_black, 
  mapping = aes(x = pred, fill = type)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware model, Sensitive: Race, Reference: Black individuals",
    x = "Predictions for Y",
    y = "Density"
  ) +
  global_theme()
```

##### Ref: White

```{r, message=FALSE, warning=FALSE}
#| fig-cap: "Aware model, Sensitive: Race, Reference: White individuals"
#| label: fig-fpt-aware-race-ref-white

ggplot(
  data = aware_fpt_white, 
  mapping = aes(x = pred, fill = type)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware model, Sensitive: Race, Reference: White individuals",
    x = "Predictions for Y",
    y = "Density"
  ) +
  global_theme()
```

:::


#### Comparison for two individuals

Let us focus on two individuals: the 24th (Black) and the 25th (White) of the dataset.
```{r define-fairadapt-indiv_factuals}
(indiv_factuals_unaware <- factuals_unaware[24:25, ])
```
The characteristics of these two individuals would be, according to what was estimated using fairadapt, if the reference group was the one in which they do not belong:
```{r define-fairadapt-indiv_counterfactuals}
(indiv_counterfactuals_unaware_fpt <- counterfactuals_unaware_fpt[24:25, ])
```

We put the factuals and counterfactuals in a single table:
```{r definefairadapt--indiv}
indiv_unaware_fpt <- bind_rows(
  indiv_factuals_unaware |> mutate(id = c(24, 25)), 
  indiv_counterfactuals_unaware_fpt |> mutate(id = c(24, 25))
)
indiv_unaware_fpt
```

The difference between the counterfactual and the factual for these two individuals:
```{r fairadapt-show-indiv}
indiv_unaware_fpt |> select(id , type, pred) |> 
  pivot_wider(names_from = type, values_from = pred) |> 
  mutate(diff_fpt = counterfactual - factual)
```
We apply the same procedure with the aware model:
```{r define-fairadapt-indiv-aware}
indiv_aware_fpt <- bind_rows(
  factuals_aware[c(24, 25),] |> mutate(id = c(24, 25)),
  counterfactuals_aware_fpt[c(24, 25),] |> mutate(id = c(24, 25))
)
indiv_aware_fpt
```

The difference between the counterfactual and the factual for these two individuals, when using the aware model:
```{r fairadapt-show-indiv_aware_fpt}
indiv_aware_fpt |> select(id , type, pred) |> 
  pivot_wider(names_from = type, values_from = pred) |> 
  mutate(diff = counterfactual - factual)
```

#### Demographic Parity


Let us assume here that the reference group is "White individuals" (i.e., the group with the most individuals in the dataset). We focus on the minority, i.e., Black individuals. We consider here that the model is fair towards the minority class if:
$$
P(\hat{Y}_{S \leftarrow \text{White}} = 1 | S = \text{Black}, X_1, X_2) = P(\hat{Y} = 1 | S = \text{White}, X_1, X_2)
$$
If the model is fair with respect to this criterion, the proportion of Black individuals predicted to have grades above the median should be the same as if they had been white.


For predictions made with the unaware model:
```{r define-dp_unaware_fpt}
dp_unaware_fpt <- mean(
  counterfactuals_unaware_fpt |> filter(S == "White") |> pull("pred") - 
    factuals_unaware |> filter(S == "Black") |> pull("pred")
)
dp_unaware_fpt
```

We do the same with the aware model:
```{r define-dp_fpt_aware}
dp_aware_fpt <- mean(
  counterfactuals_aware_fpt |> filter(S == "White") |> pull("pred") - 
    factuals_aware |> filter(S == "Black") |> pull("pred")
)
dp_aware_fpt
```


### Multivariate Optimal Transport

We apply multivariate optimal transport (OT), following the methodology developed in @de2024transport. Note that with OT, it is not possible to handle new cases. Counterfactuals will only be calculated on the train set.

The codes are run in python. We use the {reticulate} R package to call python in this notebook.
```{r load-library-reticulate}
library(reticulate)
```

Some libraries need to be loaded (including POT called ot)
```{python import-libraries}
import ot
import pandas as pd
import numpy as np
import matplotlib.pyplot as pl
import ot.plot
```

The data with the factuals need to be loaded:
```{python import-data-python}
df_aware = pd.read_csv('data/factuals_aware.csv')
df_unaware = pd.read_csv('data/factuals_unaware.csv')
```

```{python define-x_S}
x_S = df_aware.drop(columns=['pred'])
x_S.head()
```
```{python ot-python-define-x_white}
x_white = x_S[x_S['S'] == 'White']
x_white = x_white.drop(columns=['S'])
x_black = x_S[x_S['S'] == 'Black']
x_black = x_black.drop(columns=['S'])

n_white = len(x_white)
n_black = len(x_black)
# Uniform weights
w_white = (1/n_white)*np.ones(n_white)
w_black = (1/n_black)*np.ones(n_black)
```

Cost matrix between both distributions:
```{python ot-python-cost}
x_white = x_white.to_numpy()
x_black = x_black.to_numpy()
C = ot.dist(x_white, x_black)
```


```{python}
#| fig-cap: Source and target distributions
#| label: fig-ot-source-target-distrib
pl.figure(1)
pl.plot(x_white[:, 0], x_white[:, 1], '+b', label='Source samples')
pl.plot(x_black[:, 0], x_black[:, 1], 'xr', label='Target samples')
pl.legend(loc=0)
pl.title('Source and target distributions')
```


```{python}
#| fig-cap: Cost matric C
#| label: fig-ot-cost-matrix
pl.figure(2)
pl.imshow(C, interpolation='nearest')
pl.title('Cost matrix C')
```

The transport plan: white --> black

```{python define-pi_white_black}
pi_white_black = ot.emd(w_white, w_black, C, numItermax=1e8)
pi_black_white = pi_white_black.T
pi_white_black.shape
```

```{python show-sum_of_rows}
sum_of_rows = np.sum(pi_white_black, axis=1)
sum_of_rows*n_white
```

```{python show-pi_black_white.shape}
pi_black_white.shape
sum_of_rows = np.sum(pi_black_white, axis=1)
sum_of_rows*n_black
```


```{python}
#| fig-cap: OT matrix pi_white_black
#| label: fig-ot-matrix-pi-white-black
pl.figure(3)
pl.imshow(pi_white_black, interpolation='nearest')
pl.title('OT matrix pi_white_black')

pl.figure(4)
ot.plot.plot2D_samples_mat(x_white, x_black, pi_white_black, c=[.5, .5, 1])
pl.plot(x_white[:, 0], x_white[:, 1], '+b', label='Source samples')
pl.plot(x_black[:, 0], x_black[:, 1], 'xr', label='Target samples')
pl.legend(loc=0)
pl.title('OT matrix with samples')
```

```{python define-transformed_x_white}
transformed_x_white = n_white*pi_white_black@x_black
```

```{python show-define-transformed_x_white.shape}
transformed_x_white.shape
```


```{python show-transformed_x_white}
transformed_x_white
```

```{python define-transformed_x_black-}
transformed_x_black = n_black*pi_black_white@x_white
```

```{python show-transformed_x_black.shape}
transformed_x_black.shape
```

```{python show-transformed_x_black}
transformed_x_black
```


```{python define-counterfactual_x}
counterfactual_x = x_S.drop(columns=['S'])
counterfactual_x[x_S['S'] == 'White'] = transformed_x_white
counterfactual_x[x_S['S'] == 'Black'] = transformed_x_black
```

```{python show-counterfactual_x.head}
counterfactual_x.head()
```
```{python show-counterfactual_x.shape}
counterfactual_x.shape
```

Lastly, we export the results in a CSV file:
```{python counterfactual_x.to_csv}
csv_file_path = 'data/counterfactuals_ot.csv'
counterfactual_x.to_csv(csv_file_path, index=False)
```


Let us get back to R, and load the results.
```{r load-counterfactuals_ot.csv, message=FALSE, warning=FALSE}
counterfactuals_ot <- read_csv('data/counterfactuals_ot.csv')
```
We add the sensitive attribute to the dataset (Black individuals become White, and conversely):
```{r ot-add-sensitive-attribute-df}
counterfactuals_ot <- counterfactuals_ot |> 
  mutate(S = counterfactuals_unaware_fpt$S)
```

#### Unaware Model

Let us make prediction with the unaware model on the counterfactuals obtained with OT:
```{r ot-define-counterfactuals_ot_unaware}
pred_unaware_ot <- predict(
  model_unaware, newdata = counterfactuals_ot, type = "response"
)
counterfactuals_unaware_ot <- counterfactuals_ot |> 
  mutate(pred = pred_unaware_ot, type = "counterfactual")
```

We bind the factuals and counterfactuals with their respective predicted values in a single dataset:
```{r ot-define-unaware_ot}
unaware_ot <- bind_rows(
  # predicted values on factuals
  factuals_unaware, 
  # predicted values on counterfactuals obtained with OT
  counterfactuals_unaware_ot
)
```

Then, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute.
```{r}
unaware_ot_white <- unaware_ot %>% filter(S == "White") 
unaware_ot_black <- unaware_ot %>% filter(S == "Black")
```



:::{panel-tabset}

##### Ref: Black

```{r}
#| fig-cap: "Unaware model, Sensitive: Race, Reference: Black individuals"
#| label: fig-ot-unaware-race-ref-black

ggplot(
  data = unaware_ot_black, 
  mapping = aes(x = pred, fill = type)
) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Unaware model, Sensitive: Race, Reference: Black individual",
       x = "Predictions for Y",
       y = "Density"
  ) +
  global_theme()
```


##### Ref: White

```{r}
#| fig-cap: "Unaware model, Sensitive: Race, Reference: White individuals"
#| label: fig-ot-unaware-race-ref-white
ggplot(
  data = unaware_ot_white, 
  mapping = aes(x = pred, fill = type)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Unaware model, Sensitive: Race, Reference: White",
       x = "Predictions for Y",
       y = "Density") +
  global_theme()
```



#### Aware Model

Let us make prediction with the aware model on the counterfactuals obtained with OT:
```{r ot-define-counterfactuals_ot_aware}
pred_aware_ot <- predict(
  model_aware, newdata = counterfactuals_ot, type = "response"
)
counterfactuals_aware_ot <- counterfactuals_ot |>  
  mutate(pred = pred_aware_ot, type = "counterfactual")
counterfactuals_aware_ot
```

We bind the factuals and counterfactuals with their respective predicted values in a single dataset:
```{r ot-define-aware_ot}
aware_ot <- bind_rows(
  factuals_aware, 
  counterfactuals_aware_ot
)
```

Then, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute.

```{r}
aware_ot_white <- aware_ot |> filter(S == "White") 
aware_ot_black <- aware_ot |>  filter(S == "Black")
```

:::{panel-tabset}

##### Ref: Black

```{r}
#| fig-cap: "Aware model, Sensitive: Race, Reference: Black individuals"
#| label: fig-ot-aware-race-ref-black

ggplot(
  data = aware_ot_black, 
  mapping = aes(x = pred, fill = type)
) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware model, Sensitive: Race, Reference: Black individual",
       x = "Predictions for Y",
       y = "Density"
  ) +
  global_theme()
```


##### Ref: White

```{r}
#| fig-cap: "Aware model, Sensitive: Race, Reference: White individuals"
#| label: fig-ot-aware-race-ref-white
ggplot(
  data = aware_ot_white, 
  mapping = aes(x = pred, fill = type)) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware model, Sensitive: Race, Reference: White",
       x = "Predictions for Y",
       y = "Density") +
  global_theme()
```

:::

#### Comparison for two individuals

Let us, again, focus on two individuals: 24 (Black) and 25 (White):
```{r ot-define-indiv_factuals}
indiv_factuals_unaware
```

The counterfactuals for those individuals, using the unaware model:
```{r ot-define-indiv_counterfactuals}
(indiv_counterfactuals_unaware_ot <- counterfactuals_unaware_ot[24:25, ])
```

Let us put the factuals and counterfactuals in a single table:
```{r ot-define-indiv-unaware}
indiv_unaware_ot <- bind_rows(
  indiv_factuals_unaware |> mutate(id = c(24, 25)),
  indiv_counterfactuals_unaware_ot |> mutate(id = c(24, 25))
)
indiv_unaware_ot
```

We compute the difference between the predicted value by the unaware model using the counterfactuals and the predicted value by the unaware model using the factuals:
```{r ot-show-indiv-unaware-diff}
indiv_unaware_ot |> select(id , type, pred) |> 
  pivot_wider(names_from = type, values_from = pred) |> 
  mutate(diff = counterfactual - factual)
```

We do the same for the aware model:
```{r}
indiv_aware_ot <- bind_rows(
  factuals_aware[c(24, 25),] |> mutate(id = c(24, 25)),
  counterfactuals_aware_ot[c(24, 25),] |> mutate(id = c(24, 25))
)
indiv_aware_ot
```


The difference between the counterfactual and the factual for these two individuals, when using the aware model:
```{r fairadapt-show-indiv-aware}
indiv_aware_ot |> select(id , type, pred) |> 
  pivot_wider(names_from = type, values_from = pred) |> 
  mutate(diff = counterfactual - factual)
```

#### Demographic Parity

As for the counterfactuals obtained with fairadapt, we assume here that the reference group is "White individuals" (i.e., the group with the most individuals in the dataset). We focus on the minority, i.e., Black individuals. We consider here that the model is fair towards the minority class if:
$$
P(\hat{Y}_{S \leftarrow \text{White}} = 1 | S = \text{Black}, X_1, X_2) = P(\hat{Y} = 1 | S = \text{White}, X_1, X_2)
$$
If the model is fair with respect to this criterion, the proportion of Black individuals predicted to have grades above the median should be the same as if they had been white.

For predictions made with the unaware model:
```{r define-dp_fpt_unaware}
dp_unaware_pt <- mean(
  counterfactuals_unaware_ot |> filter(S == "White") |> pull("pred") - 
    factuals_unaware |> filter(S == "Black") |> pull("pred")
)
dp_unaware_pt
```

We do the same with the aware model:
```{r define-dp_aware_ot}
dp_aware_ot <- mean(
  counterfactuals_aware_ot |> filter(S == "White") |> pull("pred") - 
    factuals_aware |> filter(S == "Black") |> pull("pred")
)
dp_aware_ot
```


### Sequential transport


Lastly, we turn to sequential transport (the methodology developed in our paper). We define a function, `fonction_transport()`{.R} (see in `functions/utils.R`) to perform a fast sequential transport on causal graph.
```{r, eval=FALSE}
#' Sequential transport
#'
#' @param data dataset with three columns:
#'  - S: sensitive attribute, factor White/Black
#'  - X1: first predictor, assumed to be causally linked to S
#'  - X2: second predictor, assumed to be causally linked to S and X1
#' @param number of cells in each dimension (default to 15)
#' @param h small value added to extend the area covered by the grid (default
#'  to .2)
#' @param d neighborhood weight when conditioning by x1 (default to .5)
fonction_transport <- function(data,
                              n_grid = 15,
                              h = .2,
                              d = .5) {

  # Subset of the data: 0 for Black, 1 for White
  D_SXY_0 <- data[data$S =="Black", ]
  D_SXY_1 <- data[data$S =="White", ]

  # Coordinates of the cells of the grid on subset of 0 (Black)
  vx1_0 <- seq(min(D_SXY_0$X1) - h, max(D_SXY_0$X1) + h, length = n_grid + 1)
  vx2_0 <- seq(min(D_SXY_0$X2) - h, max(D_SXY_0$X2) + h, length = n_grid + 1)
  # and middle point of the cells
  vx1_0_mid <- (vx1_0[2:(1+n_grid)]+vx1_0[1:(n_grid)]) / 2
  vx2_0_mid <- (vx2_0[2:(1+n_grid)]+vx2_0[1:(n_grid)]) / 2

  # Coordinates of the cells of the grid on subset of 1 (White)
  vx1_1 <- seq(min(D_SXY_1$X1) -h, max(D_SXY_1$X1) + h, length = n_grid + 1)
  vx1_1_mid <- (vx1_1[2:(1 + n_grid)] + vx1_1[1:(n_grid)]) / 2
  # and middle point of the cells
  vx2_1 <- seq(min(D_SXY_1$X2) - h, max(D_SXY_1$X2) + h, length = n_grid + 1)
  vx2_1_mid <- (vx2_1[2:(1 + n_grid)] + vx2_1[1:(n_grid)]) / 2

  # Creation of the grids for the CDF and Quantile function
  # init with NA values
  # One grid for X1 and X2, on both subsets of the data (Black/White)
  F1_0 <- F2_0 <- F1_1 <- F2_1 <- matrix(NA, n_grid, n_grid)
  Q1_0 <- Q2_0 <- Q1_1 <- Q2_1 <- matrix(NA, n_grid, n_grid)

  # Empirical CDF for X1 on subset of Black
  FdR1_0 <- Vectorize(function(x) mean(D_SXY_0$X1 <= x))
  f1_0 <- FdR1_0(vx1_0_mid)
  # Empirical CDF for X2 on subset of Black
  FdR2_0 <- Vectorize(function(x) mean(D_SXY_0$X2 <= x))
  f2_0 <- FdR2_0(vx2_0_mid)
  # Empirical CDF for X1 on subset of White
  FdR1_1 <- Vectorize(function(x) mean(D_SXY_1$X1 <= x))
  f1_1 <- FdR1_1(vx1_1_mid)
  # Empirical CDF for X2 on subset of White
  FdR2_1 <- Vectorize(function(x) mean(D_SXY_1$X2 <= x))
  f2_1 <- FdR2_1(vx2_1_mid)

  u <- (1:n_grid) / (n_grid + 1)
  # Empirical quantiles for X1 on subset of Black
  Qtl1_0 <- Vectorize(function(x) quantile(D_SXY_0$X1, x))
  q1_0 <- Qtl1_0(u)
  # Empirical quantiles for X2 on subset of Black
  Qtl2_0 <- Vectorize(function(x) quantile(D_SXY_0$X2, x))
  q2_0 <- Qtl2_0(u)
  # Empirical quantiles for X1 on subset of White
  Qtl1_1 <- Vectorize(function(x) quantile(D_SXY_1$X1, x))
  q1_1 <- Qtl1_1(u)
  # Empirical quantiles for X2 on subset of White
  Qtl2_1 <- Vectorize(function(x) quantile(D_SXY_1$X2, x))
  q2_1 <- Qtl2_1(u)

  for(i in 1:n_grid) {
    # Subset of Black
    idx1_0 <- which(abs(D_SXY_0$X1 - vx1_0_mid[i]) < d)
    FdR2_0 <- Vectorize(function(x) mean(D_SXY_0$X2[idx1_0] <= x))
    F2_0[, i] <- FdR2_0(vx2_0_mid)
    Qtl2_0 <- Vectorize(function(x) quantile(D_SXY_0$X2[idx1_0], x))
    Q2_0[, i] <- Qtl2_0(u)

    idx2_0 <- which(abs(D_SXY_0$X2 - vx2_0_mid[i]) < d)
    FdR1_0 <- Vectorize(function(x) mean(D_SXY_0$X1[idx2_0] <= x))
    F1_0[, i] <- FdR1_0(vx1_0_mid)
    Qtl1_0 <- Vectorize(function(x) quantile(D_SXY_0$X1[idx2_0], x))
    Q1_0[, i] <- Qtl1_0(u)

    # Subset of White
    idx1_1 <- which(abs(D_SXY_1$X1 - vx1_1_mid[i]) < d)
    FdR2_1 <- Vectorize(function(x) mean(D_SXY_1$X2[idx1_1] <= x))
    F2_1[, i] <- FdR2_1(vx2_1_mid)
    Qtl2_1 <- Vectorize(function(x) quantile(D_SXY_1$X2[idx1_1], x))
    Q2_1[, i] <- Qtl2_1(u)

    idx2_1 <- which(abs(D_SXY_1$X2-vx2_1_mid[i])<d)
    FdR1_1 <- Vectorize(function(x) mean(D_SXY_1$X1[idx2_1] <= x))
    F1_1[, i] <- FdR1_1(vx1_1_mid)
    Qtl1_1 <- Vectorize(function(x) quantile(D_SXY_1$X1[idx2_1], x))
    Q1_1[, i] <- Qtl1_1(u)
  }

  # Transport for X2
  T2 <- function(x2) {
    i <- which.min(abs(vx2_0_mid - x2))
    p <- f2_0[i]
    i <- which.min(abs(u - p))
    x2star <- q2_1[i]
    x2star
  }

  # Transport for X1
  T1 <- function(x1) {
    i <- which.min(abs(vx1_0_mid - x1))
    p <- f1_0[i]
    i <- which.min(abs(u - p))
    x1star <- q1_1[i]
    x1star
  }

  # Transport for X2 conditional on X1
  T2_cond_x1 <- function(x2, x1) {
    k0 <- which.min(abs(vx1_0_mid - x1))
    k1 <- which.min(abs(vx1_1_mid - T1(x1)))
    i <- which.min(abs(vx2_0_mid - x2))
    p <- F2_0[i, k0]
    i <- which.min(abs(u - p))
    x2star <- Q2_1[i, k1]
    x2star
  }

  # Transport for X1 conditional on X2
  T1_cond_x2 <- function(x1, x2) {
    k0 <- which.min(abs(vx2_0_mid - x2))
    k1 <- which.min(abs(vx2_1_mid - x2))
    i <- which.min(abs(vx1_0_mid - x1))
    p <- F1_0[i, k0]
    i <- which.min(abs(u - p))
    x1star <- Q1_1[i, k1]
    x1star
  }

  list(
    Transport_x1 = T1,
    Transport_x2 = T2,
    Transport_x1_cond_x2 = T1_cond_x2,
    Transport_x2_cond_x1 = T2_cond_x1
  )
}
```


:::{.callout-note}

#### Note

The `fonction_transport()`{.R} function returns not only the functions `Transport_x1()`{.R}, `Transport_x2()`{.R}, `Transport_x1_cond_x2()`{.R}, `Transport_x2_cond_x1()`{.R}, but also the useful values of the grid (e.g., `vx1_0_mid` defined in the environment of the function and used in the functions). Note that defining a global object named `vx1_0_mid` will not alter the object of the same name defined in the environment of `fonction_transport()`{.R}: R will call the `vx1_0_mid` from that environment and not the one that may be defined in the global environment.

:::

Let us apply this function. Note that we use a grid of length 500 to fasten the computation of sequential transport (the estimation takes about 45 seconds on a standard computer).
```{r seqt-define-seq_functions}
seq_functions <- fonction_transport(data = df_race_fpt, n_grid = 500)
```

Let us extract the transport functions to transport $X_1$ and $X_2$:
```{r seqt-define-T_X1}
T_X1 <- seq_functions$Transport_x1
T_X2 <- seq_functions$Transport_x2
```

We also do the same with the transport of $X_2$ conditional on $X_1$:
```{r seqt-define-T_X2_c_X1}
T_X2_c_X1 <- seq_functions$Transport_x2_cond_x1
```

Now, we can apply these functions to the subset of Black individuals to sequentially transport $X_1$ (UGPA) and then $X_2$ (LSAT) conditional on the transported value of $X_1$:

The values of $X_1$ and $X_2$ for Black individuals:
```{r seqt-define-a10}
a10 <- df_race_fpt$X1[ind_black]
a20 <- df_race_fpt$X2[ind_black]
```

The transported values:
```{r seqt-define-x1_star}
x1_star <- map_dbl(a10, T_X1) # Transport X1 to group S=White
x2_star <- map2_dbl(a20, a10, T_X2_c_X1) # Transport X2|X1 to group S=White
```

We build a dataset with the sensitive attribute of Black individuals changed to white, and their characteristics changed to their transported characteristics:
```{r}
df_counterfactuals_seq_black <- 
  df_race_fpt |> mutate(id = row_number()) |> 
  filter(S == "Black") |> 
  mutate(
    S = "White",
    X1 = x1_star,
    X2 = x2_star
  )
```

We make predictions based on those counterfactuals obrained with sequential transport, on both models (the unaware model, and the aware model):
```{r seqt-pred_seqt_unaware}
pred_seq_unaware <- predict(
  model_unaware, newdata = df_counterfactuals_seq_black,type = "response"
)
pred_seq_aware <- predict(
  model_aware, newdata = df_counterfactuals_seq_black,type = "response"
)
```

```{r}
counterfactuals_seq_unaware_black <- 
  df_counterfactuals_seq_black |> 
  mutate(pred = pred_seq_unaware, type = "counterfactual")
counterfactuals_seq_aware_black <- 
  df_counterfactuals_seq_black |> 
  mutate(pred = pred_seq_aware, type = "counterfactual")
```


```{r}
aware_seq_black <- bind_rows(
  factuals_aware |> filter(S == "Black"), 
  counterfactuals_seq_aware_black
)
unaware_seq_black <- bind_rows(
  factuals_unaware |> filter(S == "Black"), 
  counterfactuals_seq_aware_black)
```

:::{.panel-tabset}

#### Unaware

```{r, message=FALSE, warning=FALSE}
#| fig-cap: "Unaware model, Sensitive: Race, Reference: White individuals"
#| label: fig-seq-unaware-race-ref-white
ggplot(
  data = unaware_seq_black, 
  mapping = aes(x = pred, fill = type)
) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Unware model, S: Race - Black --> White",
       x = "Predictions for Y",
       y = "Density") +
  global_theme()
```

#### Aware

```{r}
#| fig-cap: "Aware model, Sensitive: Race, Reference: White individuals"
#| label: fig-seq-aware-race-ref-white
ggplot(
  data = aware_seq_black, 
  mapping = aes(x = pred, fill = type)
) +
  geom_histogram(
    mapping = aes(y = ..density..), 
    alpha = 0.5, position = "identity", binwidth = 0.05
  ) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Aware model, S: Race - Black --> White",
       x = "Predictions for Y",
       y = "Density") +
  global_theme()
```


:::


#### Comparison for two individuals

Let us focus on the first three Black individuals of the dataset. 
```{r}
factuals_unaware |> 
  filter(S == "Black") |> 
  dplyr::slice(1:3)
```

Their characteristics after sequential transport (and the predicted value with the unaware model):
```{r seq-ot-comparison-indiv}
indiv_counterfactuals_seq_unaware <- counterfactuals_seq_unaware_black[c(1:3), ]
indiv_counterfactuals_seq_unaware
```

```{r seq-define-indiv_unaware_seq}
indiv_unaware_seq <- bind_rows(
  factuals_unaware |> 
    filter(S == "Black") |> 
    dplyr::slice(1:3) |> 
    mutate(id_indiv_black = c(1:3)), 
  indiv_counterfactuals_seq_unaware |> mutate(id_indiv_black = c(1:3))
)
indiv_unaware_seq
```

And with the aware model:
```{r seq-ot-comparison-indiv-awar}
indiv_counterfactuals_seq_aware <- counterfactuals_seq_aware_black[c(1:3), ]
indiv_counterfactuals_seq_aware
```

```{r seq-define-indiv_aware_seq}
indiv_aware_seq <- bind_rows(
  factuals_aware |> 
    filter(S == "Black") |> 
    dplyr::slice(1:3) |> 
    mutate(id_indiv_black = c(1:3)), 
  indiv_counterfactuals_seq_aware |> mutate(id_indiv_black = c(1:3))
)
indiv_aware_seq
```

#### Demographic Parity

For the unaware model:
```{r}
mean(
  counterfactuals_seq_unaware_black$pred -
    factuals_unaware |> filter(S == "Black") |> pull("pred")
)
```


For the aware model:
```{r}
mean(
  counterfactuals_seq_aware_black$pred - 
    factuals_aware |> filter(S == "Black") |> pull("pred")
)
```

### Comparison


:::{.panel-tabset}

#### Unaware Model

```{r}
tb_indiv_unaware <- 
  factuals_unaware |> mutate(id = row_number(), counterfactual = "none") |> 
  # Fairadapt
  bind_rows(
    counterfactuals_unaware_fpt |> 
      mutate(id = row_number(), counterfactual = "fpt")
  ) |> 
  # Multivariate optimal transport
  bind_rows(
    counterfactuals_unaware_ot |> mutate(id = row_number(), counterfactual = "ot")
  ) |> 
  # Sequential transport
  bind_rows(
    counterfactuals_seq_unaware_black |> mutate(counterfactual = "seq")
  ) |> 
  filter(id %in% counterfactuals_seq_unaware_black$id[1:3])

tb_indiv_unaware
```

```{r}
#| fig-cap: Predictions by the unaware model for three Black individuals.
#| label: fig-example-3-black-inviv-unaware
#| fig-width: 6
#| fig-height: 4
#| code-fold: true
par(mar = c(4.1, 4.1, 0, 0))
# Initial characteristics with the unaware model
tb_indiv_unaware_factual <- 
  tb_indiv_unaware |> filter(type == "factual")
colour_factual <- "black"
colour_fpt <- "#D55E00"
colour_ot <- "#56B4E9"
colour_seq <- "#009E73"
colours_all <- c(
  "Factual" = colour_factual,
  "fairadapt" = colour_fpt,
  "OT" = colour_ot,
  "Seq T." = colour_seq
)
range_x1 <- range(tb_indiv_unaware$X1)
expansion_amount_x1 <- .1*range_x1
range_x2 <- range(tb_indiv_unaware$X2)
expansion_amount_x2 <- .05*range_x2

plot(
  x = tb_indiv_unaware_factual$X1,
  y = tb_indiv_unaware_factual$X2,
  col = colour_factual,
  xlab = "X1 (UGPA)", ylab = "X2 (LSAT)",
  xlim = c(range_x1[1] - expansion_amount_x1[1], range_x1[2] + expansion_amount_x1[2]),
  ylim = c(range_x2[1] - expansion_amount_x2[1], range_x2[2] + expansion_amount_x2[2]),
  pch = 19,
  axes = FALSE
)
axis(1)
axis(2)
text(
  x = tb_indiv_unaware_factual$X1, 
  y = tb_indiv_unaware_factual$X2 + 1,
  paste0(round(100*tb_indiv_unaware_factual$pred, 2), "%"),
  col = colour_factual
)
# Transported characteristics with fairadapt
tb_indiv_unaware_fpt <- 
  tb_indiv_unaware |> filter(counterfactual == "fpt")
points(
  x = tb_indiv_unaware_fpt$X1,
  y = tb_indiv_unaware_fpt$X2,
  col = colour_fpt,
  xlab = "X1", ylab = "X2",
  pch = 19
)
# x1 then x2
segments(
  x0 = tb_indiv_unaware_factual$X1, 
  y0 = tb_indiv_unaware_factual$X2,
  x1 = tb_indiv_unaware_fpt$X1, 
  y1 = tb_indiv_unaware_factual$X2, 
  col = colour_fpt,
  lty = 2
)
segments(
  x0 = tb_indiv_unaware_fpt$X1, 
  y0 = tb_indiv_unaware_factual$X2,
  x1 = tb_indiv_unaware_fpt$X1, 
  y1 = tb_indiv_unaware_fpt$X2, 
  col = colour_fpt,
  lty = 2
)
text(
  x = tb_indiv_unaware_fpt$X1, 
  y = tb_indiv_unaware_fpt$X2 + 1,
  paste0(round(100*tb_indiv_unaware_fpt$pred, 2), "%"),
  col = colour_fpt
)
# Transported characteristics with OT
tb_indiv_unaware_ot <- 
  tb_indiv_unaware |> filter(counterfactual == "ot")
points(
  x = tb_indiv_unaware_ot$X1,
  y = tb_indiv_unaware_ot$X2,
  col = colour_ot,
  xlab = "X1", ylab = "X2",
  pch = 19
)
# x1 then x2
segments(
  x0 = tb_indiv_unaware_factual$X1, 
  y0 = tb_indiv_unaware_factual$X2,
  x1 = tb_indiv_unaware_ot$X1, 
  y1 = tb_indiv_unaware_factual$X2, 
  col = colour_ot,
  lty = 2
)
segments(
  x0 = tb_indiv_unaware_ot$X1, 
  y0 = tb_indiv_unaware_factual$X2,
  x1 = tb_indiv_unaware_ot$X1, 
  y1 = tb_indiv_unaware_ot$X2, 
  col = colour_ot,
  lty = 2
)
text(
  x = tb_indiv_unaware_ot$X1 - .15, 
  y = tb_indiv_unaware_ot$X2,
  paste0(round(100*tb_indiv_unaware_ot$pred, 2), "%"),
  col = colour_ot
)

# Transported characteristics with Sequential transport
tb_indiv_unaware_seq <- 
  tb_indiv_unaware |> filter(counterfactual == "seq")
points(
  x = tb_indiv_unaware_seq$X1,
  y = tb_indiv_unaware_seq$X2,
  col = colour_seq,
  xlab = "X1", ylab = "X2",
  pch = 19
)
# x1 then x2
segments(
  x0 = tb_indiv_unaware_factual$X1, 
  y0 = tb_indiv_unaware_factual$X2,
  x1 = tb_indiv_unaware_seq$X1, 
  y1 = tb_indiv_unaware_factual$X2, 
  col = colour_seq,
  lty = 2
)
segments(
  x0 = tb_indiv_unaware_seq$X1, 
  y0 = tb_indiv_unaware_factual$X2,
  x1 = tb_indiv_unaware_seq$X1, 
  y1 = tb_indiv_unaware_seq$X2, 
  col = colour_seq,
  lty = 2
)
text(
  x = tb_indiv_unaware_seq$X1 - .11, 
  y = tb_indiv_unaware_seq$X2 - 1,
  paste0(round(100*tb_indiv_unaware_seq$pred, 2), "%"),
  col = colour_seq
)
legend(
  "topleft", 
  pch = 19, col = colours_all, legend = names(colours_all)
)
```


#### Aware Model

```{r}
tb_indiv_aware <- 
  factuals_aware |> mutate(id = row_number(), counterfactual = "none") |> 
  # Fairadapt
  bind_rows(
    counterfactuals_aware_fpt |> 
      mutate(id = row_number(), counterfactual = "fpt")
  ) |> 
  # Multivariate optimal transport
  bind_rows(
    counterfactuals_aware_ot |> mutate(id = row_number(), counterfactual = "ot")
  ) |> 
  # Sequential transport
  bind_rows(
    counterfactuals_seq_aware_black |> mutate(counterfactual = "seq")
  ) |> 
  filter(id %in% counterfactuals_seq_aware_black$id[1:3])

tb_indiv_aware
```

```{r}
#| fig-cap: Predictions by the aware model for three Black individuals.
#| label: fig-example-3-black-inviv-aware
#| fig-width: 6
#| fig-height: 4
#| code-fold: true
par(mar = c(4.1, 4.1, 0, 0))
# Initial characteristics with the aware model
tb_indiv_aware_factual <- 
  tb_indiv_aware |> filter(type == "factual")
colour_factual <- "black"
colour_fpt <- "#D55E00"
colour_ot <- "#56B4E9"
colour_seq <- "#009E73"
colours_all <- c(
  "Factual" = colour_factual,
  "fairadapt" = colour_fpt,
  "OT" = colour_ot,
  "Seq T." = colour_seq
)
range_x1 <- range(tb_indiv_aware$X1)
expansion_amount_x1 <- .1*range_x1
range_x2 <- range(tb_indiv_aware$X2)
expansion_amount_x2 <- .05*range_x2

plot(
  x = tb_indiv_aware_factual$X1,
  y = tb_indiv_aware_factual$X2,
  col = colour_factual,
  xlab = "", ylab = "",
  # xlab = "X1 (UGPA)", ylab = "X2 (LSAT)",
  xlim = c(range_x1[1] - expansion_amount_x1[1], range_x1[2] + expansion_amount_x1[2]),
  ylim = c(range_x2[1] - expansion_amount_x2[1], range_x2[2] + expansion_amount_x2[2]),
  pch = 19,
  axes = FALSE
)
axis(1)
mtext(expression(X[1]~(UGCA)), side = 1)
axis(2)
mtext(expression(X[2]~(LSAT)), side = 2)
text(
  x = tb_indiv_aware_factual$X1, 
  y = tb_indiv_aware_factual$X2 + 1,
  paste0(round(100*tb_indiv_aware_factual$pred, 2), "%"),
  col = colour_factual
)
# Transported characteristics with fairadapt
tb_indiv_aware_fpt <- 
  tb_indiv_aware |> filter(counterfactual == "fpt")
points(
  x = tb_indiv_aware_fpt$X1,
  y = tb_indiv_aware_fpt$X2,
  col = colour_fpt,
  xlab = "X1", ylab = "X2",
  pch = 19
)
# x1 then x2
segments(
  x0 = tb_indiv_aware_factual$X1, 
  y0 = tb_indiv_aware_factual$X2,
  x1 = tb_indiv_aware_fpt$X1, 
  y1 = tb_indiv_aware_factual$X2, 
  col = colour_fpt,
  lty = 2
)
segments(
  x0 = tb_indiv_aware_fpt$X1, 
  y0 = tb_indiv_aware_factual$X2,
  x1 = tb_indiv_aware_fpt$X1, 
  y1 = tb_indiv_aware_fpt$X2, 
  col = colour_fpt,
  lty = 2
)
text(
  x = tb_indiv_aware_fpt$X1, 
  y = tb_indiv_aware_fpt$X2 + 1,
  paste0(round(100*tb_indiv_aware_fpt$pred, 2), "%"),
  col = colour_fpt
)
# Transported characteristics with OT
tb_indiv_aware_ot <- 
  tb_indiv_aware |> filter(counterfactual == "ot")
points(
  x = tb_indiv_aware_ot$X1,
  y = tb_indiv_aware_ot$X2,
  col = colour_ot,
  xlab = "X1", ylab = "X2",
  pch = 19
)
# x1 then x2
segments(
  x0 = tb_indiv_aware_factual$X1, 
  y0 = tb_indiv_aware_factual$X2,
  x1 = tb_indiv_aware_ot$X1, 
  y1 = tb_indiv_aware_factual$X2, 
  col = colour_ot,
  lty = 2
)
segments(
  x0 = tb_indiv_aware_ot$X1, 
  y0 = tb_indiv_aware_factual$X2,
  x1 = tb_indiv_aware_ot$X1, 
  y1 = tb_indiv_aware_ot$X2, 
  col = colour_ot,
  lty = 2
)
text(
  x = tb_indiv_aware_ot$X1 - .15, 
  y = tb_indiv_aware_ot$X2,
  paste0(round(100*tb_indiv_aware_ot$pred, 2), "%"),
  col = colour_ot
)

# Transported characteristics with Sequential transport
tb_indiv_aware_seq <- 
  tb_indiv_aware |> filter(counterfactual == "seq")
points(
  x = tb_indiv_aware_seq$X1,
  y = tb_indiv_aware_seq$X2,
  col = colour_seq,
  xlab = "X1", ylab = "X2",
  pch = 19
)
# x1 then x2
segments(
  x0 = tb_indiv_aware_factual$X1, 
  y0 = tb_indiv_aware_factual$X2,
  x1 = tb_indiv_aware_seq$X1, 
  y1 = tb_indiv_aware_factual$X2, 
  col = colour_seq,
  lty = 2
)
segments(
  x0 = tb_indiv_aware_seq$X1, 
  y0 = tb_indiv_aware_factual$X2,
  x1 = tb_indiv_aware_seq$X1, 
  y1 = tb_indiv_aware_seq$X2, 
  col = colour_seq,
  lty = 2
)
text(
  x = tb_indiv_aware_seq$X1 - .11, 
  y = tb_indiv_aware_seq$X2 - 1,
  paste0(round(100*tb_indiv_aware_seq$pred, 2), "%"),
  col = colour_seq
)
legend(
  "topleft", 
  pch = 19, col = colours_all, legend = names(colours_all)
)
```

:::





