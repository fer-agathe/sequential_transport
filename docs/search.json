[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sequential Conditional (Marginally Optimal) Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness",
    "section": "",
    "text": "Introduction\nThis ebook provides the replication codes to the article titled ‘Sequential Conditional (Marginally Optimal) Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness.’",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Sequential Conditional (Marginally Optimal) Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness",
    "section": "Abstract",
    "text": "Abstract\nIn this paper, we link two existing approaches to derive counterfactuals: adaptations based on a causal graph, as suggested in Plečko and Meinshausen (2020) and optimal transport, as in De Lara et al. (2024). We extend “Knothe’s rearrangement” Bonnotte (2013) and “triangular transport” Zech and Marzouk (2022) to probabilistic graphical models, and use this counterfactual approach, referred to as sequential transport, to discuss individual fairness. After establishing the theoretical foundations of the proposed method, we demonstrate its application through numerical experiments on both synthetic and real datasets.\nKeywords: Machine Learning (ML) -&gt; ML: Ethics – Bias, Fairness, Transparency & Privacy",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Sequential Conditional (Marginally Optimal) Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness",
    "section": "Outline",
    "text": "Outline\nThis ebook is made of fourt parts:\n\nOptimal Transport We provide some background for optimal transport (Chapter 1  Optimal Transport).\nSimulations\nUsing data simulated from bivariate Gaussian distributions in two subgroups of the population (\\(S=0\\) and \\(S=1\\)), we illustrate the sequential transport algorithm (Chapter 2  Gaussian Simulations). Then, we demonstrate how this algorithm can be used in an interpretable counterfactual fairness context (Chapter 3  Fast Transport on a Grid with Numerical Covariates). We then present another algorithm which can be used if the covariates are not all numeric (Chapter 4  Faster Algorithm). Lastly, we explore what happens when assuming a wrong DAG (Chapter 5  Wrong Causal Assumptions).\nThe third part shows an example with real data. The law datatest used as an illustration is first presented (Chapter 6  Data). In this data, the individuals (students) may be part of a protected group (\\(S=0\\)) or not (\\(S=1\\)). Then, a GLM model is estimated to predict a binary outcome (Chapter 7  Classifier). We then present three methods to produce counterfactuals from group \\(S=0\\) to group \\(S=1\\): fairadapt (Chapter 9  Fairadapt), multivariate optimal transport (Chapter 10  Multivariate Optimal Transport), and sequential transport (Chapter 11  Sequential Transport). A comparison of the results is presented in (Chapter 12  Counterfactuals: comparison).\nThe fourth part replicates the analysis from the previous part, using the UCI Adult dataset (Chapter 13  Adult Dataset).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#small-package",
    "href": "index.html#small-package",
    "title": "Sequential Conditional (Marginally Optimal) Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness",
    "section": "Small Package",
    "text": "Small Package\nWe defined some of the functions used in this ebook in a small R package, {seqtransfairness}, which can be downloaded from the github repository associated with the paper.\nTo install the package:\n\nremotes::install_github(\n  repo = \"fer-agathe/sequential_transport\", subdir = \"seqtransfairness\"\n)\n\nThen, the package can be loaded as follows:\n\nlibrary(seqtransfairness)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#replication-codes",
    "href": "index.html#replication-codes",
    "title": "Sequential Conditional (Marginally Optimal) Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness",
    "section": "Replication Codes",
    "text": "Replication Codes\nThe codes to replicate the results displayed in the paper are presented in this ebook. The following structure is adopted:\nSupplementary-materials\n├ ── replication_book\n│    └── index.html\n│    └── ...\n├ ── data\n├ ── functions\n│    └── utils.R\n│    └── graphs.R\n├ ── scripts\n|    └── 01_optimal_transport.R\n|    └── 02_gaussian.R\n|    └── 03_regression.R\n|    └── 04_1_law_data.R\n|    └── 04_2_law_classifier.R\n|    └── 04_3_law_fairadapt.R\n|    └── 04_4a_law_optimal_transport.R\n|    └── 04_4b_law_optimal_transport.R\n|    └── 04_5_law_sequential_transport.R\n|    └── 04_6_comparison.R\n|    └── sequential_transport.Rproj\nTo replicate the codes, provided you have installed R and Rstudio on your computer, double click on the following file to open RStudio (so that the correct working directory is set): Supplementary-materials/scripts/sequential_transport.Rproj. Then, the scripts can be launched.\n\n\n\n\nBonnotte, Nicolas. 2013. “From Knothe’s Rearrangement to Brenier’s Optimal Transport Map.” SIAM Journal on Mathematical Analysis 45 (1): 64–87.\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser, and Jean-Michel Loubes. 2024. “Transport-Based Counterfactual Models.” Journal of Machine Learning Research 25 (136): 1–59.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data Adaptation with Quantile Preservation.” Journal of Machine Learning Research 21 (242): 1–44.\n\n\nZech, Jakob, and Youssef Marzouk. 2022. “Sparse Approximation of Triangular Transports, Part I: The Finite-Dimensional Case.” Constructive Approximation 55 (3): 919–86.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "optimal-transport.html",
    "href": "optimal-transport.html",
    "title": "1  Optimal Transport",
    "section": "",
    "text": "1.1 Univariate Optimal Transport",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "optimal-transport.html#univariate-optimal-transport",
    "href": "optimal-transport.html#univariate-optimal-transport",
    "title": "1  Optimal Transport",
    "section": "",
    "text": "1.1.1 Gaussian distribution\nThe Gaussian case is the most simple one since mapping \\({T}^\\star\\), corresponding to OT, can be expressed analytically (it will be a linear mapping). Furthermore, conditional distributions of a multivariate Gaussian distribution are Gaussian distributions, and that can be used to consider an iteration of simple conditional (univariate) transports, as a substitute to joint transport \\({T}^\\star\\). Here \\(\\Phi\\) denotes the univariate cumulative distribution function of the standard Gaussian distribution \\(\\mathcal{N}(0,1)\\).\nOne can easily prove that the optimal mapping, from a \\(\\mathcal{N}(\\mu_0,\\sigma_0^2)\\) to a \\(\\mathcal{N}(\\mu_1,\\sigma_1^2)\\) distribution is: \\[\nx_{1}={T}^\\star(x_{0})= \\mu_{1}+\\frac{\\sigma_{1}}{\\sigma_{0}}(x_{0}-\\mu_{0}),\n\\] which is a nondecreasing linear transformation.\nLet us illustrate this. We start by simulating two Univariate Gaussian distributions with their densities: one for the subset \\(S=0\\) and one for the subset \\(S=1\\).\n\n# Univariate Gaussian distribution S=0\nx1_grid &lt;- seq(-5, 5, length = 251)\nm0 &lt;- -1\ns0 &lt;- 1.2\nd0x1 &lt;- dnorm(x1_grid, m0, s0)\nd_0 &lt;- data.frame(x = x1_grid, y = d0x1)\n\n# Univariate Gaussian distribution S=1\nm1 &lt;- 1.5\ns1 &lt;- .9\nd1x1 &lt;- dnorm(x1_grid, m1, s1)\nd_1 &lt;- data.frame(x = x1_grid, y = d1x1)\n\nIn the following graphs, we plot the optimal transport mapping for one example individual from subset \\(S=0\\):\n\nu &lt;- 0.1586553\n# u-quantile of X1 for subset S=0\nx1 &lt;- qnorm(u, m0, s0)\n# u-quantile of X1 for subset S=1\nx1_star &lt;- qnorm(u, m1, s1)\n\nWe also calculate the indices of \\(X_1\\) grid that are below this individual (\\(x_1\\)) and its counterfactual (\\(x_1^*\\)) in order to plot the cdf’s (for this individual) of \\(X_1\\) in both subsets \\(S=0\\) and \\(S=1\\) in the following graphs:\n\nidx1 &lt;- which(x1_grid &lt;= x1)\nidx1_star &lt;- which(x1_grid &lt;= x1_star)\n\nWe then plot the Optimal Transport line between \\(X_1|S=0\\) and \\(X_1|S=1\\):\n\n\nCodes used to create the Figure.\n# Graph parameters\nlimA &lt;- c(-5, 5)\nlimB &lt;- c(-5, 5) \nlimY &lt;- c(0, .5)\nlab &lt;- c(\"A\", \"B\")\nsub &lt;- 6\n\n{\n  mat &lt;- matrix(c(1, 2, 0, 3), 2)\n  par(mfrow = c(2, 2))\n  layout(mat, c(3.5, 1), c(1, 3))\n  par(mar = c(0.5, 4.5, 0.5, 0.5))\n}\n\n# Density of X1 in subset S=0\nplot(\n  d_0$x, d_0$y, type = \"l\", col = colors[lab[1]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limA, ylim = limY\n)\npolygon(\n  c(0, d_0$x, 1), c(0, d_0$y, 0), \n  col = scales::alpha(colors[lab[1]], 0.1), \n  border = NA\n)\n# cdf of X1 in subset S=0\npolygon(\n  c(min(d_0$x), d_0$x[idx1], max(d_0$x[idx1])),\n  c(0, d_0$y[idx1], 0),\n  col = scales::alpha(colors[\"A\"],.2),\n  border = NA\n)\n# Add x-axis\naxis(\n  1, at = seq(limA[1], limA[2], length = sub), \n  label = c(NA, seq(limA[1], limA[2], length = sub)[-1])\n)\n\n# Optimal transport from subset S=0 to S=1 (defined with quantile functions)\npar(mar = c(4.5, 4.5, 0.5, 0.5))\nu_grid &lt;- seq(0, 1, length=261)\nq_0 &lt;- qnorm(u_grid, m0, s0)\nq_1 &lt;- qnorm(u_grid, m1, s1)\nplot(\n  q_0, q_1, col = colors[\"1\"], lwd = 2, type = \"l\", \n  xlab = \"\", ylab = \"\", xlim = limA, ylim = limB, axes = FALSE\n)\nabline(a = 0, b = 1, col = colors[\"0\"], lty = 2)\n# Add x-axis and y-axis\naxis(1)\naxis(2)\n# Legend\nmtext(\"distribution (group 0)\", side = 1, line = 3, col = \"black\")\nmtext(\"distribution (group 1)\", side = 2, line = 3, col = \"black\")\n# Example individual\npoints(x1, x1_star, pch = 19, col = colors[\"1\"])\nsegments(x1, x1_star, x1, 10, lwd = .4, col = colors[\"1\"])\nsegments(x1, x1_star, 10, x1_star, lwd = .4, col = colors[\"1\"])\n\n# Density of X1 in subset S=1\npar(mar = c(4.5, 0.5, 0.5, 0.5))\nplot(\n  d_1$y, d_1$x, type = \"l\", col = colors[lab[2]], lwd = 2,\n  ylim = limB, xlim = limY, xlab = \"\", ylab = \"\", axes = FALSE\n)\npolygon(\n  c(0, d_1$y, 0), c(0, d_1$x, 1), \n  col = scales::alpha(colors[lab[2]], 0.1), border = NA\n)\n# cdf of X1 in subset S=1\npolygon(\n  c(0, d_1$y[idx1_star], 0),\n  c(min(d_1$x), d_1$x[idx1_star], max(d_1$x[idx1_star])),\n  col = scales::alpha(colors[\"B\"],.2),\n  border = NA\n)\n# Add y-axis\naxis(\n  2, at = seq(limB[1], limB[2], length = sub), \n  label = c(NA, seq(limB[1], limB[2], length = sub)[-c(1, sub)], NA)\n)\n\n\n\n\nUnivariate optimal transport, with Gaussian distributions\n\n\n\n\n\n\n\n1.1.2 General distribution\nWe simulate two general univariate distributions based on Gaussian distributions with their densities, cdf’s and quantile functions: one for the subset \\(S=0\\) and one for the subset \\(S=1\\).\n\n# General distribution for subset S=0\nx0 &lt;- rnorm(13, m0, s0)\nf0 &lt;- density(x0, from = -5, to = 5, n = length(x1_grid))\nd0 &lt;- f0$y\nd_0 &lt;- data.frame(x = x1_grid, y = d0)\nx0s &lt;- sample(x0, size = 1e3, replace = TRUE) + rnorm(1e3, 0, f0$bw)\nF0 &lt;- Vectorize(function(x) mean(x0s &lt;= x))\nQ0 &lt;- Vectorize(function(x) as.numeric(quantile(x0s, x)))\n\n# General distribution for subset S=1\nx1 &lt;- rnorm(7, m1, 1)\nf1 &lt;- density(x1, from = -5, to = 5, n = length(x1_grid))\nd1 &lt;- f1$y\nd_1 &lt;- data.frame(x = x1_grid, y = d1)\nx1s &lt;- sample(x1, size = 1e3, replace = TRUE) + rnorm(1e3, 0, f1$bw)\nF1 &lt;- Vectorize(function(x) mean(x1s &lt;= x))\nQ1 &lt;- Vectorize(function(x) as.numeric(quantile(x1s, x)))\n\nIn the following graphs, we plot the optimal transport mapping for one example individual from subset \\(S=0\\):\n\nu &lt;- 0.1586553\nx1 &lt;- Q0(u)\nx1_star &lt;- Q1(u)\n\nWe also calculate the indices of \\(X_1\\) grid that are below this individual (\\(x_1\\)) and its counterfactual (\\(x_1^*\\)) in order to plot the cdf’s (for this individual) of \\(X_1\\) in both subsets \\(S=0\\) and \\(S=1\\) in the following graphs:\n\nidx1 &lt;- which(x1_grid &lt;= x1)\nidx1_star &lt;- which(x1_grid &lt;= x1_star)\n\nWe then plot the Optimal Transport line between \\(X_1|S=0\\) and \\(X_1|S=1\\):\n\n\nCodes used to create the Figure.\n{\n  mat &lt;- matrix(c(1, 2, 0, 3), 2)\n  par(mfrow = c(2, 2))\n  layout(mat, c(3.5, 1), c(1, 3))\n  par(mar = c(0.5, 4.5, 0.5, 0.5))\n}\n\n# Density of X1 in subset S=0\nplot(d_0$x, d_0$y, type = \"l\", col = colors[lab[1]], lwd = 2,\n     axes = FALSE, xlab = \"\", ylab = \"\", xlim = limA, ylim = limY)\npolygon(c(0, d_0$x, 1), c(0, d_0$y, 0), \n        col = scales::alpha(colors[lab[1]], 0.1), \n        border = NA)\n# cdf of X1 in subset S=0\npolygon(\n  c(min(d_0$x), d_0$x[idx1], max(d_0$x[idx1])),\n  c(0, d_0$y[idx1], 0),\n  col = scales::alpha(colors[\"A\"],.2),\n  border = NA\n)\n# Add x-axis\naxis(\n  1, at = seq(limA[1], limA[2], length = sub), \n  label = c(NA, seq(limA[1], limA[2], length = sub)[-1])\n)\n\n# Optimal transport from subset S=0 to S=1 (defined with quantile functions)\npar(mar = c(4.5, 4.5, 0.5, 0.5))\nu_grid &lt;- seq(0, 1, length=261)\nq_0 &lt;- Q0(u_grid)\nq_1 &lt;- Q1(u_grid)\nplot(\n  q_0, q_1, col = colors[\"1\"], lwd = 2, type = \"l\", \n  xlab = \"\", ylab = \"\", xlim = limA, ylim = limB, axes = FALSE\n)\nabline(a = 0, b = 1, col = colors[\"0\"], lty = 2)\n# Add x-axis and y-axis\naxis(1)\naxis(2)\n# Legend\nmtext(\"distribution (group 0)\", side = 1, line = 3, col = \"black\")\nmtext(\"distribution (group 1)\", side = 2, line = 3, col = \"black\")\n# Example individual\npoints(x1, x1_star, pch = 19, col = colors[\"1\"])\nsegments(x1, x1_star, x1, 10, lwd = .4, col = colors[\"1\"])\nsegments(x1, x1_star, 10, x1_star, lwd = .4, col = colors[\"1\"])\n\n# Density of X1 in subset S=1\npar(mar = c(4.5, 0.5, 0.5, 0.5))\nplot(\n  d_1$y, d_1$x, type = \"l\", col = colors[lab[2]], lwd = 2,\n  ylim = limB, xlim = limY, xlab = \"\", ylab = \"\", axes = FALSE\n)\npolygon(\n  c(0, d_1$y, 0), c(0, d_1$x, 1), \n  col = scales::alpha(colors[lab[2]], 0.1), border = NA\n)\n# cdf of X1 in subset S=1\npolygon(\n  c(0, d_1$y[idx1_star], 0),\n  c(min(d_1$x), d_1$x[idx1_star], max(d_1$x[idx1_star])),\n  col = scales::alpha(colors[\"B\"],.2),\n  border = NA\n)\n# Add y-axis\naxis(\n  2, at = seq(limB[1], limB[2], length = sub), \n  label = c(NA, seq(limB[1], limB[2], length = sub)[-c(1, sub)], NA)\n)\n\n\n\n\nGeneral marginal distribution",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "optimal-transport.html#multivariate-optimal-gaussian-transport",
    "href": "optimal-transport.html#multivariate-optimal-gaussian-transport",
    "title": "1  Optimal Transport",
    "section": "1.2 Multivariate Optimal Gaussian Transport",
    "text": "1.2 Multivariate Optimal Gaussian Transport\nRecall that \\(\\boldsymbol{X}\\sim\\mathcal{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\) if its density, with respect to Lebesgue measure is \\[\n\\begin{equation}\n{\\displaystyle f(\\boldsymbol{x})\\propto{{\\exp \\left(-{\\frac {1}{2}}\\left({\\boldsymbol{x} }-{\\boldsymbol {\\mu }}\\right)^{\\top}{\\boldsymbol {\\Sigma }}^{-1}\\left({\\boldsymbol {x} }-{\\boldsymbol {\\mu }}\\right)\\right)}.%{\\sqrt {(2\\pi )^{k}|{\\boldsymbol {\\Sigma }}|}}}}\n}\n}\n\\end{equation}\n\\tag{1.1}\\]\nIf \\(\\boldsymbol{X}_0\\sim\\mathcal{N}(\\boldsymbol{\\mu}_0,\\boldsymbol{\\Sigma}_0)\\) and \\(\\boldsymbol{X}_1\\sim\\mathcal{N}(\\boldsymbol{\\mu}_1,\\boldsymbol{\\Sigma}_1)\\), the optimal mapping is also linear, \\[\n\\boldsymbol{x}_{1} = T^\\star(\\boldsymbol{x}_{0})=\\boldsymbol{\\mu}_{1} + \\boldsymbol{A}(\\boldsymbol{x}_{0}-\\boldsymbol{\\mu}_{0}),\n\\] where \\(\\boldsymbol{A}\\) is a symmetric positive matrix that satisfies \\(\\boldsymbol{A}\\boldsymbol{\\Sigma}_{0}\\boldsymbol{A}=\\boldsymbol{\\Sigma}_{1}\\), which has a unique solution given by \\(\\boldsymbol{A}=\\boldsymbol{\\Sigma}_{0}^{-1/2}\\big(\\boldsymbol{\\Sigma}_{0}^{1/2}\\boldsymbol{\\Sigma}_{1}\\boldsymbol{\\Sigma}_{0}^{1/2}\\big)^{1/2}\\boldsymbol{\\Sigma}_{0}^{-1/2}\\), where \\(\\boldsymbol{M}^{1/2}\\) is the square root of the square (symmetric) positive matrix \\(\\boldsymbol{M}\\) based on the Schur decomposition (\\(\\boldsymbol{M}^{1/2}\\) is a positive symmetric matrix), as described in Higham (2008). If \\(\\boldsymbol{\\Sigma}=\\displaystyle\\begin{pmatrix}1&r\\\\r&1\\end{pmatrix}\\), and if \\(a=\\sqrt{(1-\\sqrt{1-r^2})/2}\\), then: \\[\n\\boldsymbol{\\Sigma}^{1/2}=\\displaystyle\\begin{pmatrix}\\sqrt{1-a^2}&a\\\\a&\\sqrt{1-a^2}\\end{pmatrix}.\n\\]\nObserve further this mapping is the gradient of the convex function \\[\n\\psi(\\boldsymbol{x})=\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu}_0)^\\top\\boldsymbol{A}(\\boldsymbol{x}-\\boldsymbol{\\mu}_0)+\\boldsymbol{x}-\\boldsymbol{\\mu}_1^\\top\\boldsymbol{x}\n\\] and \\(\\nabla T^\\star = \\boldsymbol{A}\\) (see Takatsu (2011) for more properties of Gaussian transport). And if \\(\\boldsymbol{\\mu}_0=\\boldsymbol{\\mu}_1=\\boldsymbol{0}\\), and if \\(\\boldsymbol{\\Sigma}_{0}=\\mathbb{I}\\) and \\(\\boldsymbol{\\Sigma}_{1}=\\boldsymbol{\\Sigma}\\), \\(\\boldsymbol{x}_{1} = T^\\star(\\boldsymbol{x}_{0})=\\boldsymbol{\\Sigma}^{1/2}\\boldsymbol{x}_{0}\\). Hence, \\(\\boldsymbol{\\Sigma}^{1/2}\\) is a linear operator that maps from \\(\\boldsymbol{X}_0\\sim\\mathcal{N}(\\boldsymbol{0},\\mathbb{I})\\) (the reference density) to \\(\\boldsymbol{X}_1\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\) (the target density).",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "optimal-transport.html#sec-cond-gauss",
    "href": "optimal-transport.html#sec-cond-gauss",
    "title": "1  Optimal Transport",
    "section": "1.3 Conditional Gaussian Transport",
    "text": "1.3 Conditional Gaussian Transport\nAlternatively, since \\(\\boldsymbol{\\Sigma}\\) is a positive definite matrix, from the Cholesky decomposition, it can be written as the product of a lower (or upper) triangular matrix and its conjugate transpose, \\[\n\\boldsymbol{\\Sigma}=\\boldsymbol{L}\\boldsymbol{L}^\\top=\\boldsymbol{U}^\\top\\boldsymbol{U}.\n\\]\n\n1.3.1 Remark\nIf \\(\\boldsymbol{\\Sigma}=\\displaystyle\\begin{pmatrix}1&r\\\\r&1\\end{pmatrix}\\), then \\(\\boldsymbol{L}=\\boldsymbol{\\Sigma}_{2|1}^{1/2}=\\displaystyle\\begin{pmatrix}1&0\\\\r&\\sqrt{1-r^2}\\end{pmatrix}\\) while \\(\\boldsymbol{U}=\\boldsymbol{\\Sigma}_{1|2}^{1/2}=\\boldsymbol{\\Sigma}_{2|1}^{1/2\\top}=\\boldsymbol{L}^\\top\\). Then \\(\\boldsymbol{L}^\\top\\boldsymbol{L}=\\boldsymbol{\\Sigma}=\\boldsymbol{U}^\\top\\boldsymbol{U}\\).\n\nBoth \\(\\boldsymbol{L}\\) and \\(\\boldsymbol{U}\\) are linear operators that map from \\(\\boldsymbol{X}_0\\sim\\mathcal{N}(\\boldsymbol{0},\\mathbb{I})\\) (the reference density) to \\(\\boldsymbol{X}_1\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\) (the target density). \\(\\boldsymbol{x}_0\\mapsto\\boldsymbol{L}\\boldsymbol{x}_0\\) and \\(\\boldsymbol{x}_0\\mapsto\\boldsymbol{U}\\boldsymbol{x}_0\\) are respectively linear lower and upper triangular transport maps.\nMore generally, in dimension 2, consider the following (lower triangular) mapping \\(T(x_0,y_0) = (T_x(x_0),T_{y|x}(y_0|x_0))\\), \\[\\begin{eqnarray*}\n&&\n\\mathcal{N}\\left(\n\\begin{pmatrix}\n    \\mu_{0x}\\\\\n    \\mu_{0y}\\\\\n\\end{pmatrix},\n\\begin{pmatrix}\n    \\sigma_{0x}^2 & r_0\\sigma_{0x}\\sigma_{0y}\\\\\n    r_0\\sigma_{0x}\\sigma_{0y} & \\sigma_{0y}^2\\\\\n\\end{pmatrix}\n\\right)\n%\\\\\n\\overset{T}{\\longrightarrow}\n\\mathcal{N}\\left(\n\\begin{pmatrix}\n    \\mu_{1x}\\\\\n    \\mu_{1y}\\\\\n\\end{pmatrix},\n\\begin{pmatrix}\n    \\sigma_{1x}^2 & r_1\\sigma_{1x}\\sigma_{1y}\\\\\n    r_1\\sigma_{1x}\\sigma_{1y} & \\sigma_{1y}^2\\\\\n\\end{pmatrix}\n\\right),\n\\end{eqnarray*}\\]\nwhere \\(T_x(x_0)\\) and \\(T_{y|x}(y_0)\\) are respectively \\[\n\\begin{cases}\n   \\mu_{1x} +\\displaystyle\\frac{\\sigma_{1x}}{\\sigma_{0x}}(x_0-\\mu_{0x})\\phantom{\\displaystyle\\int}\\\\\n     \\mu_{1y}+\\displaystyle\\frac{r_1\\sigma_{1y}}{\\sigma_{1x}}(T_x(x_0)-\\mu_{1x})+\\sqrt{\\displaystyle\\frac{\\sigma_{0x}^2(\\sigma_{1y}^2{\\sigma_{1x}^2}-{r_1^2\\sigma_{1y}^2})}{(\\sigma_{0y}^2{\\sigma_{0x}^2}-{r_0^2\\sigma_{0y}^2})\\sigma_{1x}^2}}(y_0\\!-\\!\\mu_{0y}\\!-\\!\\displaystyle\\frac{r_0\\sigma_{0y}}{\\sigma_{0x}}(x_0\\!-\\!\\mu_{0x}))\n\\end{cases}\n\\]\nthat are both linear mappings. Let us visualize this.\n\n\nCodes used to create the Figure.\npar(mar = c(3.5, 4, 0, 0))\npar(mfrow = c(1, 1))\n\n# Assumed cdf for the individual of interest\np1 &lt;- 0.1586553\n# y coordinate for that individual\nb1 &lt;- 3\n\nvx &lt;- seq(-5, 5, length = 6001)\nvy1 &lt;- dnorm(vx,-1, 1.2)*4\nvy2 &lt;- dnorm(vx, 1.5, .9)*4\n\n# Marginal density of x0 in source group (at the bottom of graph)\nplot(\n  vx, vy1, \n  col = colors[\"A\"], xlab = \"\", ylab = \"\", axes = FALSE, type = \"l\", \n  ylim = c(0, 10)\n)\npolygon(\n  c(min(vx), vx, max(vx)),\n  c(0, vy1, 0),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# Marginal density of x1 in target group (at the bottom of graph)\nlines(vx, vy2, col = colors[\"B\"])\npolygon(\n  c(min(vx), vx, max(vx)),\n  c(0, vy2, 0),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n\n# Corresponding quantile in the marginal distribution\na1 &lt;- qnorm(p1, -1, 1.2) # in source group\n# Transported value along x\na2 &lt;- qnorm(p1, 1.5, .9) # in target group\n# Identify observation in x below this quantile a1\nidx1 &lt;- which(vx &lt;= a1)\n# Identify observation in x below this quantile a2\nidx2 &lt;- which(vx &lt;= a2)\n# Showing P(X_1 &lt; a1 | S = 0) on the marginal density plots\npolygon(\n  c(min(vx), vx[idx1], max(vx[idx1])),\n  c(0, vy1[idx1],0),\n  col = scales::alpha(colors[\"A\"],.2),\n  border = NA\n)\n# vertical line to show quantile a1\nsegments(a1, 0, a1, 100, col = colors[\"A\"])\n# Showing P(X_1 &lt; a2 | S = 1) on the marginal density plots\npolygon(\n  c(min(vx), vx[idx2], max(vx[idx2])),\n  c(0, vy2[idx2], 0),\n  col=scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n# vertical line to show quantile a2\nsegments(a2, 0, a2, 100, col = colors[\"B\"])\n\n# Mean and variance matrix in both groups\nM1 &lt;- c(-1,-1+5)\nM2 &lt;- c(1.5,1.5+5)\nS1 &lt;- matrix(c(1,.5,.5,1)*1.2^2,2,2)\nS2 &lt;- matrix(c(1,-.4,-.4,1)*.9^2,2,2)\n\nA &lt;- sqrtm(S1) %*% S2 %*% (sqrtm(S1))\nA &lt;- solve(sqrtm(S1)) %*% sqrtm(A) %*% solve((sqrtm(S1)))\nT &lt;- function(x) as.vector(M2 + A %*% (x - M1))\n\n# Bivariate Gaussian density\nlibrary(mvtnorm)\nvx0 &lt;- seq(-5, 5, length = 251)\ndata.grid &lt;- expand.grid(x = vx0, y = vx0 + 5)\ndgauss1 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M1, sigma = S1), length(vx0), length(vx0)\n)\ndgauss2 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M2, sigma = S2), length(vx0), length(vx0)\n)\n\n# Contour of the bivariate Gaussian density in source group\ncontour(vx0, vx0 + 5, dgauss1, col = colors[\"A\"], add = TRUE)\n# Contour of the bivariate Gaussian density in target group\ncontour(vx0, vx0 + 5, dgauss2, col = colors[\"B\"], add = TRUE)\n\naxis(1, at = seq(-2, 2) * 2, labels = NA)\naxis(\n  1, at = a1,\n  labels = expression(x[0]),\n  col.ticks = NA,\n  col.axis = colors[\"A\"], line = .5\n)\naxis(\n  1, at = a2,\n  labels = bquote(\n    x[1]~\"=\"~mu[1][x] + frac(sigma[1][x],sigma[0][x])~(x[0]-mu[0][x])\n  ),\n  col.ticks = NA,\n  col.axis = colors[\"B\"], line = .5\n)\naxis(\n  1, at = a1,\n  labels = NA,\n  col.ticks = colors[\"A\"], line = -.5\n)\naxis(\n  1, at = a2,\n  labels = NA,\n  col.ticks = colors[\"B\"], line = -.5\n)\n\n###\n# Second axis\n###\ny &lt;- b1\nvx &lt;- vx + 5\nmu1 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (a1 - M1[1])\nsig1 &lt;- sqrt(S1[2, 2] - S1[2, 1]^2 / S1[2, 2])\nmu2 &lt;- M2[2] + S2[1, 2] / S2[1, 1] * (a2 - M2[1])\nsig2 &lt;- sqrt(S2[2, 2]- S2[2, 1]^2 / S2[2, 2])\nvz1 &lt;- dnorm(vx, mu1, sig1) * 3\nvz2 &lt;- dnorm(vx, mu2, sig2) * 3\n\n# Marginal density on y, source group\nlines(vz1 - 5, vx, col = colors[\"A\"])\npolygon(\n  c(0, vz1, 0) - 5,\n  c(min(vx), vx, max(vx)),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# target group\nlines(vz2 - 5, vx, col = colors[\"B\"])\npolygon(\n  c(0, vz2, 0) - 5,\n  c(min(vx), vx, max(vx)),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n\n# Identify the cdf at b1 in the marginal distribution\np1 &lt;- pnorm(b1, mu1, sig1)\n# Transported value in the target marginal distribution\nb2 &lt;- qnorm(p1, mu2, sig2)\n# Identify observation in y below this quantile b1\nidx1 &lt;- which(vx &lt;= b1)\n# Identify observation in y below this quantile b2\nidx2 &lt;- which(vx &lt;= b2)\n# Showing P(X_2 &lt; b1 | S = 0) on the marginal density plots\npolygon(\n  c(0, vz1[idx1], 0) - 5,\n  c(min(vx), vx[idx1], max(vx[idx1])),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# Showing P(X_2 &lt; b2 | S = 1) on the marginal density plots\npolygon(\n  c(0, vz2[idx2], 0) - 5,\n  c(min(vx), vx[idx2], max(vx[idx2])),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n# horizontal line to show quantile b1\nsegments(-5, b1, 100, b1, col = colors[\"A\"])\n# horizontal line to show quantile b2\nsegments(-5, b2, 100, b2, col = colors[\"B\"])\n\n# Draw the individual of interest \npoints(a1, b1, pch = 19)\n\n\naxis(2, at = c(0,1,3,4,5) * 2, labels = NA)\naxis(\n  2, at = b1,\n  labels = expression(y[0]),\n  col.ticks = NA,\n  col.axis = colors[\"A\"], line = .5\n)\naxis(\n  2, at = b2,\n  labels = bquote(y[1]),\n  col.ticks = NA,\n  col.axis = colors[\"B\"], line = .5\n)\naxis(\n  2,at = b1,\n  labels = NA,\n  col.ticks = colors[\"A\"], line = -.5\n)\naxis(\n  2,at = b2,\n  labels = NA,\n  col.ticks = colors[\"B\"], line = -.5\n)\n\n# Drawing transported point\npoints(a2, b2, pch = 19)\n\n# Decomposition of the sequential transport\n# First transport along the x axis\nsegments(a1, b1, a2, b1, lwd = 2)\n# Then transport along the y axis\narrows(a2, b1, a2, b2 - .1, length = .1, lwd = 2)\n\n# Storing in a matrix the coordinates of the point before and after transport\nX_then_Y &lt;- matrix(c(a1, b1, a2, b2), 2, 2)\ncolnames(X_then_Y) = c(\"start\",\"x_then_y\")\n\n# Showing the transported point if we assume another sequential transport:\n# first along the y axis, and then along the x axis\nM1 &lt;- c(-1, -1+5)\nM2 &lt;- c(1.5, 1.5)\nS1 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\nS2 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\n\n# Transport\nAA &lt;- sqrtm(S1) %*% S2 %*% (sqrtm(S1))\nAA &lt;- solve(sqrtm(S1)) %*% sqrtm(AA) %*% solve((sqrtm(S1)))\nT &lt;- function(x) as.vector(M2 + AA %*% (x - M1))\nopt_transp &lt;- T(c(a1, b1))\nXYopt &lt;- matrix(c(a1, b1, opt_transp[1], opt_transp[2] + 5), 2, 2)\ncolnames(XYopt) = c(\"start\",\"OT\")\n\n# Drawing the point transported with the different order in the sequence\npoints(opt_transp[1], opt_transp[2] + 5, pch = 15, col = \"#C93312\")\n\n\n\n\nGaussian conditional optimal transport. The process begins with a univariate transport along the \\(x\\) axis (using \\(T_x^*\\)), followed by a transport along the \\(y\\) axis on the conditional distribution (using \\(T_{y|x}^*\\)), corresponding to the “lower triangular affine mapping.” The red square is the multivariate optimal transport of the point considering an “upper triangular affine mapping” instead.\n\n\n\n\n\nNow, let us transport first along the \\(y\\) axis, and then along the \\(x\\) axis.\n\n\nCodes used to create the Figure.\npar(mar = c(3.5, 4, 0, 0))\npar(mfrow = c(1, 1))\n\n# Mean and variance matrix in both groups\nM1 &lt;- c(-1, -1 + 5)\nM2 &lt;- c(1.5, 1.5 + 5)\nS1 &lt;- matrix(c(1,.5,.5,1)*1.2^2,2,2)\nS2 &lt;- matrix(c(1,-.4,-.4,1)*.9^2,2,2)\n\n# Quantile for the observartion of interest, in the distribution of x\na1 &lt;- -2.2\n# y coordinate for the individual of interest\nb1 &lt;- 3\nb2 &lt;- qnorm(pnorm(b1, 5 - 1, 1.2), 5 + 1.5, .9)\n\nmu1 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (b1 - M1[1] - 5)\nsig1 &lt;- sqrt(S1[2, 2] - S1[2, 1]^2 / S1[2, 2])\nmu2 &lt;- M2[2] + S2[1, 2] / S2[1, 1] * (b2 - M2[1] - 5)\nsig2 &lt;- sqrt(S2[2, 2] - S2[2, 1]^2 / S2[2, 2])\n\n# Assumed cdf for the individual of interest\np1 &lt;- pnorm(a1 + 5, mu1, sig1)\n\nvx &lt;- seq(-5, 5, length = 6001)\nvx &lt;- vx+5\nvy1 &lt;- dnorm(vx, mu1, sig1) * 3\nvy2 &lt;- dnorm(vx, mu2, sig2) * 3\n\nvz1 &lt;- dnorm(vx - 5, -1, 1.2) * 4\nvz2 &lt;- dnorm(vx - 5, 1.5, .9) * 4\n\n# Marginal density of x0 in source group (at the bottom of graph)\nplot(\n  vx, vy1,\n  col = colors[\"A\"], xlab = \"\", ylab = \"\", axes = FALSE, \n  type = \"l\", ylim = c(0, 10)\n)\nlines(vz1 - 5, vx, col = colors[\"A\"])\npolygon(\n  c(min(vx), vx, max(vx)),\n  c(0, vy1, 0),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# Marginal density of x1 in target group (at the bottom of graph)\nlines(vx, vy2, col = colors[\"B\"])\npolygon(\n  c(min(vx), vx, max(vx)),\n  c(0, vy2, 0),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n\n\n# Transported value along x\na2 &lt;- qnorm(p1, mu2, sig2)\na1 &lt;- a1 + 5\n# Identify observation in x below this quantile a1\nidx1 &lt;- which(vx &lt;= a1)\n# Identify observation in x below this quantile a2\nidx2 &lt;- which(vx &lt;= a2)\n# Showing P(X_1 &lt; a1 | S = 0) on the marginal density plots\npolygon(\n  c(min(vx), vx[idx1], max(vx[idx1])),\n  c(0, vy1[idx1], 0),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# vertical line to show quantile a1\nsegments(a1, 0, a1, 100, col = colors[\"A\"])\n# Showing P(X_1 &lt; a2 | S = 1) on the marginal density plots\npolygon(\n  c(min(vx), vx[idx2], max(vx[idx2])),\n  c(0, vy2[idx2], 0),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n# vertical line to show quantile a2\nsegments(a2, 0, a2, 100, col = colors[\"B\"])\n\n# Bivariate Gaussian density\nlibrary(mvtnorm)\nvx0 &lt;- seq(-5, 5, length = 251)\ndata.grid &lt;- expand.grid(x = vx0, y = vx0 + 5)\ndgauss1 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M1, sigma = S1), length(vx0), length(vx0)\n)\ndgauss2 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M2, sigma = S2), length(vx0), length(vx0)\n)\n\n# Contour of the bivariate Gaussian density in source group\ncontour(vx0 + 5,vx0 + 5, dgauss1, col = colors[\"A\"], add = TRUE)\n# Contour of the bivariate Gaussian density in target group\ncontour(vx0 + 5, vx0 + 5, dgauss2, col = colors[\"B\"], add = TRUE)\n\n\n# Showing and annoting x axis\naxis(1, at = 5 + seq(-2, 2) * 2, labels = NA)\naxis(\n  1, at = a1,\n  labels = expression(x[0]),\n  col.ticks = NA,\n  col.axis = colors[\"A\"], line = .5\n)\naxis(\n  1, at = a2,\n  labels = bquote(x[1]),\n  col.ticks = NA,\n  col.axis = colors[\"B\"], line = .5\n)\naxis(\n  1, at = a1,\n  labels = NA,\n  col.ticks = colors[\"A\"], line = -.5\n)\naxis(\n  1, at = a2,\n  labels = NA,\n  col.ticks = colors[\"B\"], line = -.5\n)\n\n###\n# Second axis\n###\n\n# Marginal density on y, source group\nlines(vz1, vx, col = colors[\"A\"])\npolygon(\n  c(0, vz1, 0),\n  c(min(vx), vx, max(vx)),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# target group\nlines(vz2, vx, col = colors[\"B\"])\npolygon(\n  c(0, vz2, 0),\n  c(min(vx), vx, max(vx)),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n\n# Identify the cdf at b1 in the marginal distribution\np1 &lt;- pnorm(b1, 5 - 1, 1.2)\n# Transported value in the target marginal distribution\nb2 &lt;- qnorm(p1, 5 + 1.5, .9)\n# Identify observation in y below this quantile b1\nidx1 &lt;- which(vx &lt;= b1)\n# Identify observation in y below this quantile b2\nidx2 &lt;- which(vx &lt;= b2)\n# Showing P(X_2 &lt; b1 | S = 0) on the marginal density plots\npolygon(\n  c(0, vz1[idx1], 0),\n  c(min(vx), vx[idx1], max(vx[idx1])),\n  col = scales::alpha(colors[\"A\"], .2),\n  border = NA\n)\n# Showing P(X_2 &lt; b2 | S = 1) on the marginal density plots\npolygon(\n  c(0, vz2[idx2], 0),\n  c(min(vx), vx[idx2], max(vx[idx2])),\n  col = scales::alpha(colors[\"B\"], .2),\n  border = NA\n)\n\n# horizontal line to show quantile b1\nsegments(0, b1, 100, b1, col = colors[\"A\"])\n# horizontal line to show quantile b2\nsegments(0, b2, 100, b2, col = colors[\"B\"])\n\n# Draw the individual of interest \npoints(a1, b1, pch = 19)\n\n# Drawing y axis\naxis(2, at = c(0, 1, 3, 4, 5) * 2, labels = NA)\naxis(\n  2, at = b1,\n  labels = expression(y[0]),\n  col.ticks = NA,\n  col.axis = colors[\"A\"], line = 0\n)\naxis(\n  2, at = b2,\n  labels = bquote(\n    y[1]~\"=\"~mu[1][y]+frac(sigma[1][y],sigma[0][y])~(y[0]-mu[0][y])\n  ),\n  col.ticks = NA,\n  col.axis = colors[\"B\"], line = .5\n)\naxis(\n  2, at = b1,\n  labels=NA,\n  col.ticks = colors[\"A\"],line = -.5\n)\naxis(\n  2,at = b2,\n  labels = NA,\n  col.ticks = colors[\"B\"], line = -.5\n)\n\n# Drawing transported point\npoints(a2, b2, pch = 19)\n\n# Decomposition of the sequential transport\n# First transport along the x axis\nsegments(a1, b1, a1, b2, lwd = 2)\n# Then transport along the y axis\narrows(a1, b2, a2 - .1, b2, length = .1, lwd = 2)\n\n# Storing in a matrix the coordinates of the point before and after transport\nY_then_X = matrix(c(a1, b1, a2, b2), 2, 2)\ncolnames(Y_then_X) = c(\"start\",\"y_then_x\")\n\n# Showing the transported point if we assume another sequential transport:\n# first along the x axis, and then along the y axis\nM1 &lt;- c(-1, -1)\nM2 &lt;- c(1.5, 1.5)\nS1 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\nS2 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\n\n# Transport\nAA &lt;- sqrtm(S1) %*% S2 %*% (sqrtm(S1))\nAA &lt;- solve(sqrtm(S1)) %*% sqrtm(AA) %*% solve((sqrtm(S1)))\nT &lt;- function(x) as.vector(M2 + AA %*% (x - M1))\nopt_transp &lt;- T(c(a1 - 5, b1 - 5))\n\n# Drawing the point transported with the different order in the sequence\npoints(opt_transp[1] + 5, opt_transp[2] + 5, pch = 15, col = \"#C93312\")\n\n\n\n\nGaussian conditional optimal transport. The process begins with a univariate transport along the \\(y\\) axis (using \\(T_y^*\\)), followed by a transport along the \\(x\\) axis on the conditional distribution (using \\(T_{x|y}^*\\)), corresponding to the “upper triangular affine mapping.” The red square is the multivariate optimal transport of the point considering a “lower triangular affine mapping” instead.\n\n\n\n\n\nOf course, this is highly dependent on the axis parametrization. Instead of considering projections on the axis, one could consider transport in the direction \\(\\overrightarrow{u}\\), followed by transport in the direction \\(\\overrightarrow{u}^\\perp\\) (on conditional distributions). This will be visualized in Figure 1.1 and Figure 1.2",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "optimal-transport.html#gaussian-probabilistic-graphical-models",
    "href": "optimal-transport.html#gaussian-probabilistic-graphical-models",
    "title": "1  Optimal Transport",
    "section": "1.4 Gaussian Probabilistic Graphical Models",
    "text": "1.4 Gaussian Probabilistic Graphical Models\nAn interesting feature of the Gaussian multivariate distribution is that any marginal and any conditional distribution (given other components) is still Gaussian. More precisely, if \\[\n{\\displaystyle \\boldsymbol {x} ={\\begin{pmatrix}\\boldsymbol {x} _{1}\\\\\\boldsymbol {x} _{2}\\end{pmatrix}}},~{\\displaystyle {\\boldsymbol {\\mu }}={\\begin{pmatrix}{\\boldsymbol {\\mu }}_{1}\\\\{\\boldsymbol {\\mu }}_{2}\\end{pmatrix}}}\\text{ and } {\\displaystyle {\\boldsymbol {\\Sigma }}={\\begin{pmatrix}{\\boldsymbol {\\Sigma }}_{11}&{\\boldsymbol {\\Sigma }}_{12}\\\\{\\boldsymbol {\\Sigma }}_{21}&{\\boldsymbol {\\Sigma }}_{22}\\end{pmatrix}}},\n\\] then \\(\\boldsymbol{X}_1\\sim\\mathcal{N}(\\boldsymbol{\\mu}_1,\\boldsymbol{\\Sigma}_{11})\\), while, with notations of Equation 1.1, we can also write \\({\\displaystyle { {\\boldsymbol {B }_{1}}}={\\boldsymbol {B }}_{11}-{\\boldsymbol {B }}_{12}{\\boldsymbol {B }}_{22}^{-1}{\\boldsymbol {B }}_{21}}\\) (based on properties of inverses of block matrices, also called the Schur complement of a block matrix). Furthermore, conditional distributions are also Gaussian, \\(\\boldsymbol{X}_1|\\boldsymbol{X}_2=\\boldsymbol{x}_2\\sim\\mathcal{N}({\\boldsymbol {\\mu }_{1|2}},{\\boldsymbol {\\Sigma }_{1|2}}),\\) \\[\n\\begin{cases}\n   {\\displaystyle { {\\boldsymbol {\\mu }_{1|2}}}={\\boldsymbol {\\mu }}_{1}+{\\boldsymbol {\\Sigma }}_{12}{\\boldsymbol {\\Sigma }}_{22}^{-1}\\left(\\boldsymbol{x}_2 -{\\boldsymbol {\\mu }}_{2}\\right)}\n   \\\\\n   {\\displaystyle { {\\boldsymbol {\\Sigma }_{1|2}}}={\\boldsymbol {\\Sigma }}_{11}-{\\boldsymbol {\\Sigma }}_{12}{\\boldsymbol {\\Sigma }}_{22}^{-1}{\\boldsymbol {\\Sigma }}_{21},}\n\\end{cases}\n\\] and the inverse of the conditional variance is simply \\(\\boldsymbol {B }_{11}\\).\nIt is well known that if \\(\\boldsymbol{X}\\sim\\mathcal{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\), \\(X_i\\indep X_j\\) if and only if \\(\\Sigma_{i,j}=0\\). More interestingly, we also have the following result, initiated by :\n\n\n\n\n\n\nProposition\n\n\n\nIf \\(\\boldsymbol{X}\\sim\\mathcal{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\), with notations of Equation 1.1, \\(\\boldsymbol{B}=\\boldsymbol{\\Sigma}^{-1}\\), \\(\\boldsymbol{X}\\) is Markov with respect to \\(\\mathcal{G}=(E,V)\\) if and only if \\(B_{i,j}=0\\) whenever \\((i,j),(j,i)\\notin E\\).\n\n\n\n\n\n\n\n\nProof\n\n\n\nThis is a direct consequence of the following property : if \\(\\boldsymbol{X}\\sim\\mathcal{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})\\), \\(X_i\\indep X_j |\\boldsymbol{X}_{-i,j}\\) if and only if \\(B_{i,j}=0\\) (since the log-density has separate terms in \\(x_i\\) and \\(x_j\\)).",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "optimal-transport.html#sequential-transport",
    "href": "optimal-transport.html#sequential-transport",
    "title": "1  Optimal Transport",
    "section": "1.5 Sequential transport",
    "text": "1.5 Sequential transport\nIn the Gaussian case we obviously recover the results of Section 1.3, if we plug Gaussian distributions in the expressions shown in the “Sequential Transport” of the paper: \\[\n\\begin{cases}\n   X_{0:1}\\!\\sim\\!\\mathcal{N}(\\mu_{0:1},\\sigma_{0:1}^2),\\text{ hence }F_{0:1}(x)\\!=\\!\\Phi\\big(\\sigma_{0:1}^{-1}(x\\!-\\!\\mu_{0:1})\\big)\\\\\n   X_{1:1}\\!\\sim\\!\\mathcal{N}(\\mu_{1:1},\\sigma_{1:1}^2),\\text{ hence }F_{1:1}^{-1}(u)\\!=\\!\\mu_{1:1}\\!+\\!\\sigma_{1:1}\\!\\Phi^{-1}(u)\n\\end{cases}\n\\] thus \\[\nT_1^\\star(x) = F_{1:1}^{-1}\\big(F_{0:1}(x)\\big)=\\mu_{1:1} +\\displaystyle\\frac{\\sigma_{1:1}}{\\sigma_{0:1}}(x-\\mu_{0:1}),\n\\] while \\[\n\\begin{cases}\n   X_{0:2}|x_{0:1}\\sim\\mathcal{N}(\\mu_{0:2|1},\\sigma_{0:2|1}^2),\\\\\n   X_{1:2}|x_{0:1}\\sim\\mathcal{N}(\\mu_{1:2|1},\\sigma_{1:2|1}^2),\\\\\n\\end{cases}\n\\] i.e., \\[\n\\begin{cases}\n  F_{0:2|1}(x)=\\Phi\\big(\\sigma_{0:2|1}^{-1}(x-\\mu_{0:2|1})\\big),\\\\\n  F_{1:2|1}^{-1}(u)=\\mu_{1:2|1}+\\sigma_{1:2|1}\\Phi^{-1}(u),\n\\end{cases}\n\\] where we consider \\(X_{0:2}\\) conditional to \\(X_{0:1}=x_{0:1}\\) in the first place, \\[\n\\begin{cases}\n   \\mu_{0:2|1} = \\mu_{0:2} +\\displaystyle\\frac{\\sigma_{0:2}}{\\sigma_{0:1}}(x_{0:1}-\\mu_{0:1}),\\phantom{\\displaystyle\\int}\\\\\n   \\sigma_{0:2|1}^2 = \\sigma_{0:2}^2 -\\displaystyle\\frac{r^2_0\\sigma_{0:2}^2}{\\sigma_{0:1}^2},\\phantom{\\int}\n\\end{cases}\n\\] and \\(X_{1:2}\\) conditional to \\(X_{1:1}=T^\\star_1(x_{0:1})\\) in the second place, \\[\n\\begin{cases}\n   \\mu_{1:2|1} = \\mu_{1:2} +\\displaystyle\\frac{\\sigma_{1:2}}{\\sigma_{1:1}}\\big(T^\\star_1(x_{0:1})-\\mu_{1:1}\\big),\\phantom{\\int}\\\\\n   \\sigma_{1:2|1}^2= \\sigma_{1:2}^2 -\\displaystyle\\frac{r^2_1\\sigma_{1:2}^2}{\\sigma_{1:1}^2},\\phantom{\\int}\n\\end{cases}\n\\] thus \\[\nT_{2|1}(x) = F_{1:2|1}^{-1}\\big(F_{0:2|1}(x)\\big)=\\mu_{1:2|1} +\\displaystyle\\frac{\\sigma_{1:2|1}}{\\sigma_{0:2|1}}(x-\\mu_{0:2|1}),\n\\] which is \\[\n\\begin{eqnarray*}\n&&\\mu_{1:2}+\\displaystyle\\frac{r_1\\sigma_{1:2}}{\\sigma_{1:1}}\\big(\\mu_{1:1} +\\displaystyle\\frac{\\sigma_{1:1}}{\\sigma_{0:1}}(x_{0:1}-\\mu_{0:1})-\\mu_{1:1}\\big) \\\\&&+\\sqrt{\\frac{\\sigma_{0:1}^2(\\sigma_{1:2}^2{\\sigma_{1:1}^2}-{r_1^2\\sigma_{1:2}^2})}{(\\sigma_{0:2}^2{\\sigma_{0:1}^2}-{r_0^2\\sigma_{0:2}^2})\\sigma_{1:1}^2}}\\cdot\\big(x-\\mu_{0:2}-\\displaystyle\\frac{r_0\\sigma_{0:2}}{\\sigma_{0:1}}(x_{0:1}-\\mu_{0:1})\\big).    \n\\end{eqnarray*}\n\\]",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "optimal-transport.html#general-conditional-transport",
    "href": "optimal-transport.html#general-conditional-transport",
    "title": "1  Optimal Transport",
    "section": "1.6 General Conditional Transport",
    "text": "1.6 General Conditional Transport\nAn interesting property of Gaussian vectors is the stability under rotations. In dimension 2, instead of a sequential transport of \\(\\boldsymbol{x}\\) on \\(\\overrightarrow{e}_x\\) and then (conditionally) on $_y, one could consider a projection on any unit vector \\(\\overrightarrow{u}\\) (with angle \\(\\theta\\)), and then (conditionally) along the orthogonal direction \\(\\displaystyle \\overrightarrow{u}^\\perp\\). In Figure 1.1, we can visualize the set of all counterfactuals \\(\\boldsymbol{x}^\\star\\) when \\(\\theta\\in[0,2\\pi]\\). The (global) optimal transport is also considered (shown with a red square).\n\n\nCodes used to create the Figure.\nangle &lt;- function(theta,\n                  A = c(-2.2,-2)) {\n  \n  # Rotation\n  R &lt;- matrix(c(cos(theta), sin(theta), -sin(theta), cos(theta)), 2, 2)\n  # Mean and Variance\n  M1 &lt;- c(-1, -1)\n  M2 &lt;- c(1.5, 1.5)\n  S1 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\n  S2 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\n  \n  # After applying the rotation\n  M1 &lt;- as.vector(R %*% M1)\n  M2 &lt;- as.vector(R %*% M2)\n  S1 &lt;- t(R) %*% S1 %*% R\n  S2 &lt;- t(R) %*% S2 %*% R\n  A &lt;- as.vector(R %*% A)\n  \n  # Coordinates\n  a1 &lt;- A[1]\n  b1 &lt;- A[2]\n  a2 &lt;- qnorm(pnorm(a1, M1[1], sqrt(S1[1, 1])), M2[1], sqrt(S2[1, 1]))\n  mu1 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (a1 - M1[1])\n  sig1 &lt;- sqrt(S1[2, 2] - S1[2, 1]^2 / S1[2, 2])\n  mu2 &lt;- M2[2] + S2[1, 2] / S2[1, 1] * (a2 - M2[1])\n  sig2 &lt;- sqrt(S2[2, 2] - S2[2, 1]^2 / S2[2, 2])\n  p1 &lt;- pnorm(b1, mu1, sig1)\n  b2 &lt;- qnorm(p1, mu2, sig2)\n  B &lt;- c(a2, b2)\n  \n  c(\n    as.vector(t(R) %*% A),\n    as.vector(t(R) %*% B)\n  )\n}\n\n# Mean and variance\nM1 &lt;- c(-1, -1)\nM2 &lt;- c(1.5, 1.5)\nS1 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\nS2 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\n\nA &lt;- c(-2.2, -2)\n\npar(mfrow = c(1, 1), mar = c(.5, .5, 0, 0))\n\n# Bivariate Gaussian density\nlibrary(mvtnorm)\nvx0 &lt;- seq(-5, 5, length = 251)\ndata.grid &lt;- expand.grid(x = vx0, y = vx0)\ndgauss1 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M1, sigma = S1), length(vx0), length(vx0)\n)\ndgauss2 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M2, sigma = S2), length(vx0), length(vx0)\n)\n\n# Contour of the bivariate Gaussian density in source group\ncontour(\n  vx0, vx0, dgauss1, col = colors[\"A\"], \n  xlim = c(-5, 5), ylim = c(-5, 5), axes = FALSE\n)\n# Contour of the bivariate Gaussian density in target group\ncontour(vx0, vx0, dgauss2, col = colors[\"B\"], add = TRUE)\n\n# Horizontal and vertical line showing the coordinates of the point of interest\nsegments(A[1], -5, A[1], 100, col = colors[\"A\"])\nsegments(-5, A[2], 100, A[2], col = colors[\"A\"])\n# Drawing this point\npoints(A[1], A[2], pch = 19, col = \"darkblue\")\n\n# Add axes\naxis(1, at = c(0, 1, 2, 3, 4, 5) * 2 - 5, labels = NA)\naxis(2, at = c(0, 1, 2, 3, 4, 5) * 2 - 5, labels = NA)\n\n# Apply rotations\nMANGLE &lt;- Vectorize(angle)(seq(0, 2 * pi, length = 100))\n# Draw the transported points for each rotation\nlines(MANGLE[3, ], MANGLE[4, ])\n\n# Display specific point when transporting first along the x axis and then the\n# orthogonal axis, i.e., y\nm &lt;- angle(0, c(-2.2, -2))\npoints(m[3],m[4],pch=19)\n\n# Same but transporting first along the y axis and then on the orthogonal axis,\n# i.e., x\nm &lt;- angle(pi/2, c(-2.2, -2))\npoints(m[3], m[4], pch = 19)\n\n# Global optimal transport\nT &lt;- function(x) as.vector(M2 + AA %*% (x - M1))\nopt_transp &lt;- T(c(A[1], A[2]))\npoints(opt_transp[1], opt_transp[2], pch = 15, col = \"#C93312\")\n\n\n\n\n\nFigure 1.1: Gaussian conditional optimal transports. The process begins with a univariate transport along the direction \\(\\overrightarrow{u}\\) (using \\(\\displaystyle T^\\star_{\\overrightarrow{u}}\\)) followed by a transport along the orthogonal direction \\(\\displaystyle \\overrightarrow{u}^\\perp\\), on conditional distributions (using \\(\\displaystyle T^\\star_{\\overrightarrow{u}^\\perp|{\\overrightarrow{u}}}\\)). The blue point is the starting point. The curves in the upper right corner represent the set of all transport maps of the same point (bottom left corner) for all possible directions \\(\\displaystyle \\overrightarrow{u}\\), the black points correspond to classical \\(x\\) (horizontal) and \\(y\\) (vertical) directions. The red square shows the global optimal tranpport.\n\n\n\n\n\n\n\n\nWe can consider another starting point.\n\n\nCodes used to create the Figure.\n# Consider the following starting point\nA = c(-2.2, .5)\n\npar(mfrow = c(1, 1), mar = c(.5, .5, 0, 0))\n\n# Bivariate Gaussian density\nvx0 &lt;- seq(-5, 5, length = 251)\ndata.grid &lt;- expand.grid(x = vx0, y = vx0)\ndgauss1 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M1, sigma = S1), length(vx0), length(vx0)\n)\ndgauss2 &lt;- matrix(\n  mvtnorm::dmvnorm(data.grid, mean = M2, sigma = S2), length(vx0), length(vx0)\n)\n# Contour of the bivariate Gaussian density in source group\ncontour(\n  vx0, vx0, dgauss1, col = colors[\"A\"], \n  xlim = c(-5, 5), ylim = c(-5, 5), axes = FALSE\n)\n# Contour of the bivariate Gaussian density in target group\ncontour(vx0, vx0, dgauss2, col = colors[\"B\"], add = TRUE)\n\n# Vertical and horizontal lines showing the coordinates of the point\nsegments(A[1], -5, A[1], 100, col = colors[\"A\"])\nsegments(-5, A[2], 100, A[2], col = colors[\"A\"])\n# Drawing that starting point\npoints(A[1], A[2], pch = 19, col = \"darkblue\")\n\n# Showing axes\naxis(1, at = c(0,1,2,3,4,5) * 2 - 5, labels = NA)\naxis(2, at = c(0,1,2,3,4,5) * 2 - 5, labels = NA)\n\n# Apply rotations\nMANGLE &lt;- \n  Vectorize(function(x) angle(x, c(-2.2, .5)))(seq(0, 2 * pi, length = 100))\n# Draw the transported points for each rotation\nlines(MANGLE[3, ], MANGLE[4, ])\n\n# Display specific point when transporting first along the x axis and then the\n# orthogonal axis, i.e., y\nm &lt;- angle(0, c(-2.2, .5))\npoints(m[3], m[4], pch = 19)\n\n# Same but transporting first along the y axis and then on the orthogonal axis,\n# i.e., x\nm &lt;- angle(pi/2, c(-2.2, .5))\npoints(m[3], m[4], pch = 19)\n\n# Global optimal transport\nAA &lt;- sqrtm(S1) %*% S2 %*% (sqrtm(S1))\nAA &lt;- solve(sqrtm(S1)) %*% sqrtm(AA) %*% solve((sqrtm(S1)))\nT &lt;- function(x) as.vector(M2 + AA %*% (x - M1))\nopt_transp &lt;- T(c(A[1], A[2]))\npoints(opt_transp[1], opt_transp[2], pch = 15, col = \"#C93312\")\n\n\n\n\n\nFigure 1.2: Gaussian conditional optimal transports. The process begins with a univariate transport along the direction \\(\\overrightarrow{u}\\) (using \\(\\displaystyle T^\\star_{\\overrightarrow{u}}\\)) followed by a transport along the orthogonal direction \\(\\displaystyle \\overrightarrow{u}^\\perp\\), on conditional distributions (using \\(\\displaystyle T^\\star_{\\overrightarrow{u}^\\perp|{\\overrightarrow{u}}}\\)). The blue point is the starting point. The curves in the upper right corner represent the set of all transport maps of the same point (bottom left corner) for all possible directions \\(\\displaystyle \\overrightarrow{u}\\), the black points correspond to classical \\(x\\) (horizontal) and \\(y\\) (vertical) directions. The red square shows the global optimal tranpport.\n\n\n\n\n\n\n\n\n\n\n\n\nHigham, Nicholas J. 2008. Functions of Matrices: Theory and Computation. SIAM.\n\n\nTakatsu, Asuka. 2011. “Wasserstein Geometry of Gaussian Measures.” Osaka Journal of Mathematics 48 (4): 1005–26.",
    "crumbs": [
      "I. Optimal Transport",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Optimal Transport</span>"
    ]
  },
  {
    "objectID": "gaussian.html",
    "href": "gaussian.html",
    "title": "2  Gaussian Simulations",
    "section": "",
    "text": "2.1 Data\nWe start by drawing two bivariate Gaussian distributions, each reflecting one group from the sensitive attribute \\(S \\in \\left\\{0,1\\right\\}\\).\n# Number of observations per group\nn &lt;- 100\n\n# First bivariate Gaussian distribution: group S=0\nM0 &lt;- c(-1, -1)\nS0 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\nX0 &lt;- mnormt::rmnorm(n, M0, S0)\nD_SXY_0 &lt;- data.frame(\n  S = 0,\n  X1 = X0[, 1],\n  X2 = X0[, 2]\n)\n\n# Second bivariate Gaussian distribution: group S=1\nM1 &lt;- c(1.5,1.5)\nS1 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\nX1 &lt;- mnormt::rmnorm(n, M1, S1)\nD_SXY_1 &lt;- data.frame(\n  S = 1,\n  X1 = X1[, 1],\n  X2 = X1[, 2]\n)\nThen, we simulate a binary response variable with a logistic model depending of covariates \\((S,\\boldsymbol{X})\\).\n# Drawing random binary response variable Y with logistic model for each group\neta_0 &lt;- (D_SXY_0$X1 * 1.2 + D_SXY_0$X2 / 2 * .8) / 2\neta_1 &lt;- (D_SXY_1$X1 * .8 + D_SXY_1$X2 / 2 * 1.2) / 2\np_0 &lt;- exp(eta_0) / (1 + exp(eta_0))\np_1 &lt;- exp(eta_1) / (1 + exp(eta_1))\nD_SXY_0$Y &lt;- rbinom(n, size = 1, prob = p_0)\nD_SXY_1$Y &lt;- rbinom(n, size = 1, prob = p_1)\n\n# Final dataframe\nD_SXY &lt;- rbind(D_SXY_0, D_SXY_1)\nThe contour lines of both bivariate Gaussian densities (corresponding to groups \\(S=0\\) and \\(S=1\\)) are displayed in the following graph.\nCodes used to create the Figure.\nD_SXY0 &lt;- D_SXY[D_SXY$S == 0, ]\nD_SXY1 &lt;- D_SXY[D_SXY$S == 1, ]\n\n# Computation of smoothing parameters (bandwidth) for kernel density estimation\nH0 &lt;- Hpi(D_SXY0[, c(\"X1\", \"X2\")])\nH1 &lt;- Hpi(D_SXY1[, c(\"X1\", \"X2\")])\n\n# Calculating multivariate densities in each group S=0 and S=1\nf0_2d &lt;- kde(D_SXY0[, c(\"X1\", \"X2\")], H = H0, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d &lt;- kde(D_SXY1[, c(\"X1\", \"X2\")], H = H1, xmin = c(-5, -5), xmax = c(5, 5))\n\n# Plotting densities\npar(mar = c(2,2,0,0))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\"\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\n# Display one individual on the graph in group S=0\nA = c(-2, -1)\npoints(A[1], A[2], pch = 19)\n\n\n\n\nBivariate Gaussian densities within each group (\\(S=0\\) on the left and \\(S=1\\) on the right), estimated with a Gaussian kernel",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gaussian Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian.html#optimal-transport",
    "href": "gaussian.html#optimal-transport",
    "title": "2  Gaussian Simulations",
    "section": "2.2 Optimal Transport",
    "text": "2.2 Optimal Transport\nSince the covariates are Gaussian, we can use an explicit expression for the optimal transport: \\[\n\\boldsymbol{x}_{1} = T^\\star(\\boldsymbol{x}_{0})=\\boldsymbol{\\mu}_{1} + \\boldsymbol{A}(\\boldsymbol{x}_{0}-\\boldsymbol{\\mu}_{0}),\n\\] where \\(\\boldsymbol{A}\\) is a symmetric positive matrix that satisfies \\(\\boldsymbol{A}\\boldsymbol{\\Sigma}_{0}\\boldsymbol{A}=\\boldsymbol{\\Sigma}_{1}\\), which has a unique solution given by \\(\\boldsymbol{A}=\\boldsymbol{\\Sigma}_{0}^{-1/2}\\big(\\boldsymbol{\\Sigma}_{0}^{1/2}\\boldsymbol{\\Sigma}_{1}\\boldsymbol{\\Sigma}_{0}^{1/2}\\big)^{1/2}\\boldsymbol{\\Sigma}_{0}^{-1/2}\\), where \\(\\boldsymbol{M}^{1/2}\\) is the square root of the square (symmetric) positive matrix \\(\\boldsymbol{M}\\) based on the Schur decomposition (\\(\\boldsymbol{M}^{1/2}\\) is a positive symmetric matrix).\n\nAA &lt;- sqrtm(S0) %*% S1 %*% (sqrtm(S0))\nAA &lt;- solve(sqrtm(S0)) %*% sqrtm(AA) %*% solve((sqrtm(S0)))\nT &lt;- function(x) as.vector(M1 + AA %*% (x - M0))\nA_opt_transport &lt;- T(c(A[1], A[2]))\nA_opt_transport\n\n[1] 0.6353342 1.8903242\n\n\nWe can then display the transported individual on the same plot as before.\n\n\nCodes used to create the Figure.\n# Plotting densities\npar(mar = c(2,2,0,0))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\"\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\n# Display one individual on the graph in group S=0\nA = c(-2, -1)\npoints(A[1], A[2], pch = 19)\n# Display the transported individual\npoints(A_opt_transport[1], A_opt_transport[2], pch = 15, col = \"#C93312\")\n\n\n\n\nBivariate Gaussian densities within each group (\\(S=0\\) on the left and \\(S=1\\) on the right), estimated with a Gaussian kernel. The red square is the multivariate OT of the point.",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gaussian Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian.html#sequential-transport",
    "href": "gaussian.html#sequential-transport",
    "title": "2  Gaussian Simulations",
    "section": "2.3 Sequential Transport",
    "text": "2.3 Sequential Transport\nIn this part, we apply the sequential transport methodology by using Algorithm 1 from the article. We have two possible schemes for transport: \\(X_1\\) then \\(X_2|X_1\\), or \\(X_2\\) then \\(X_1|X_2\\). We will assume the first one:\n\n\n\n\n\nFigure 2.1: Causal network with two legitimate mitigating variables \\(x_1\\) and \\(x_2\\).\n\n\n\n\n\n\n\n\nTo obtain the counterfactuals based on the methodology presented in the article, i.e., on sequential transport using a causal graph, we can use Algorithm 2.1.\n\n\n\\begin{algorithm} \\caption{Sequential transport on causal graph} \\begin{algorithmic} \\Require graph \\(\\mathcal{G}\\) on \\((s,\\boldsymbol{x})\\), with adjacency matrix \\(\\boldsymbol{A}\\) \\Require dataset \\((s_i,\\boldsymbol{x}_i)\\) and one individual \\((s=0,\\boldsymbol{a})\\) \\Require bandwidths \\(\\boldsymbol{h}\\) and \\(\\boldsymbol{b}_j\\)'s \\State \\((s,\\boldsymbol{v})\\gets\\boldsymbol{A}\\) the topological ordering of vertices (DFS) \\State \\(T_s\\gets\\text{identity}\\) \\For{\\(j\\in \\boldsymbol{v}\\)} \\State \\(\\boldsymbol{p}(j) \\gets \\text{parents}(j)\\) \\State \\(T_j(\\boldsymbol{a}_{\\boldsymbol{p}(j)})\\gets (T_{\\boldsymbol{p}(j)_1}(\\boldsymbol{a}_{\\boldsymbol{p}(j)}),\\cdots,T_{\\boldsymbol{p}(j)_{k_j}}(\\boldsymbol{a}_{\\boldsymbol{p}(j)}))\\) \\State \\((x_{i,j|s},\\boldsymbol{x}_{i,\\boldsymbol{p}(j)|s})\\gets\\) subsets when \\(s\\in\\{0,1\\}\\) \\State \\(w_{i,j|0}\\gets \\phi(\\boldsymbol{x}_{i,\\boldsymbol{p}(j)|0};\\boldsymbol{a}_{\\boldsymbol{p}(j)},\\boldsymbol{b}_j)\\) (Gaussian kernel) \\State \\(w_{i,j|1}\\gets \\phi(\\boldsymbol{x}_{i,\\boldsymbol{p}(j)|1};T_j(\\boldsymbol{a}_{\\boldsymbol{p}(j)}),\\boldsymbol{b}_j)\\) \\State \\(\\hat{f}_{h_j|s}\\gets \\text{density estimator}\\) of \\(x_{\\cdot,j|s}\\), weights \\(w_{\\cdot,j|s}\\). \\State \\(\\hat{F}_{h_j|s}(\\cdot)\\gets\\displaystyle\\int^{~\\cdot}_{-\\infty}\\hat{f}_{h_j|s}(u)\\mathrm{d}u\\), c.d.f. \\State \\(\\hat{Q}_{h_j|s}\\gets \\hat{F}_{h_j|s}^{-1}\\), quantile \\State \\(\\hat{T}_{j}(\\cdot)\\gets\\hat{Q}_{h_j|1}\\circ \\hat{F}_{h_j|0}(\\cdot)\\) \\EndFor \\State \\(\\boldsymbol{a}^\\star\\gets (T_{1}(\\boldsymbol{a}_{1}),\\cdots,T_{d}(\\boldsymbol{a}_{d}))\\)\\\\ \\Return \\((s=1,\\boldsymbol{a}^\\star)\\), counterfactual of \\((s=0,\\boldsymbol{a})\\) \\end{algorithmic} \\end{algorithm}\n\n\n\n2.3.1 Transport of \\(X_1\\)\nFollowing Algorithm Algorithm 2.1 for Sequential Transport and the causal graph in Figure Figure 3.13, we begin by transporting \\(X_1\\) from subset \\(S=0\\) to subset \\(S=1\\). Since \\(X_1\\) is the first variable to be transported and has no parents, we use optimal transport for univariate distributions, applying the function estimated on \\(X_1\\) from the data, \\(\\hat{F}{1|0} \\circ \\hat{Q}{1|1}\\). Because \\(X_1\\) has no parents, we can compute the cdf’s and quantile functions directly on all subgroups without the need for conditioning, thus eliminating the need for Gaussian kernels in this step (we simply use uniform weights).\n\n# Uniform weights: density of X1 for subset S=0\nw0 &lt;- rep(1,length(D_SXY0[, \"X1\"])) / length(D_SXY0[, \"X1\"])\nd0x1 &lt;- function(x) {\n  dens &lt;- density(\n    D_SXY0[, \"X1\"],\n    bw = .2,\n    weights = w0,\n    from = x, to = x, n = 1\n  )\n  dens$y\n}\n# Uniform weights: density of X1 for subset S=1\nw1 &lt;- rep(1,length(D_SXY1[, \"X1\"])) / length(D_SXY1[, \"X1\"])\nd1x1 &lt;- function(x) {\n  dens &lt;- density(\n    D_SXY1[, \"X1\"],\n    bw = .2,\n    weights = w1,\n    from = x, to = x, n = 1\n  )\n  dens$y\n}\n\n# cdf of X1 for subset S=0\nFD0x1 &lt;- function(x, denom = NULL) {\n  x_val &lt;- seq(-10, x, by = .0025)\n  if (is.null(denom)) {\n    x_val_2 &lt;- seq(-10, 10, by = .0025)\n    denom &lt;- sum(map_dbl(x_val_2, d0x1))\n  }\n  sum(map_dbl(x_val, d0x1)) / denom\n}\nFD0x1_denom &lt;- map_dbl(seq(-10, 10, by = .0025), d0x1) |&gt; sum()\n\n# cdf of X1 for subset S=1\nFD1x1 &lt;- function(x, denom = NULL) {\n  x_val &lt;- seq(-10, x, by = .0025)\n  if (is.null(denom)) {\n    x_val_2 &lt;- seq(-10, 10, by = .0025)\n    denom &lt;- sum(map_dbl(x_val_2, d1x1))\n  }\n  sum(map_dbl(x_val, d1x1)) / denom\n}\nFD1x1_denom &lt;- map_dbl(seq(-10, 10, by = .0025), d1x1) |&gt; sum()\n\n# Definition of the inverse function\ninverse &lt;- function (f, lower = -100, upper = 100, denom = NULL) {\n  function (y) as.numeric(\n    uniroot((function (x) f(x, denom = denom) - y), lower = lower, upper = upper)[1]\n  )\n}\n# Quantile function of X1 for subset S=1\nQD1x1 &lt;- inverse(FD1x1, -10, 10, denom = FD1x1_denom)\n\n# Transport function for X1\nT_X1 &lt;- function(x) as.numeric(QD1x1(FD0x1(x, denom = FD0x1_denom)))\n\nWe start by applying function T_X1 above to transport only on the variable \\(X_1\\).\n\nx1_grid_t &lt;- seq(-3.5, 1.75, length = 101)\n\n\n# This code is not run in this document, it was run before\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\nclusterEvalQ(cl, {\n  library(purrr)\n}) |&gt;\n  invisible()\nclusterExport(cl, c(\"w0\" ,\"w1\", \"D_SXY0\", \"D_SXY1\", \"FD0x1_denom\", \"FD1x1_denom\"))\nclusterExport(cl, c(\"FD0x1\", \"FD1x1\", \"d0x1\", \"d1x1\", \"inverse\", \"QD1x1\"))\n\nx1_star_grid_t &lt;- \n  pblapply(x1_grid_t, T_X1, cl = cl) |&gt; \n  list_c()\n\nstopCluster(cl)\n\nsave(x1_star_grid_t, file = \"../data/x1_grid_transport.rda\")\n\nThe application of transport on \\(X_1\\) takes approximately 3 minutes to run. When creating this document, we load the pre-saved file to save time, so that we do not need to calculate T_X1 over the grid.\n\nload(\"../data/x1_grid_transport.rda\")\n\nWe will depict the resulting mapping for all observations. The densities of \\(X_1\\) given groups \\(S=0\\) and \\(S=1\\) are calculated especially for the graphs.\n\n# Calculation of densities with grid values for X1 \nx1_grid_d &lt;- seq(-5, 5, length = 251)\ndensity_x1_0 &lt;- map_dbl(x1_grid_d, d0x1)\nd_0 &lt;- data.frame(x = x1_grid_d, y = density_x1_0)\n# Density of X1 in subset 1\ndensity_x1_1 &lt;- map_dbl(x1_grid_d, d1x1)\nd_1 &lt;- data.frame(x = x1_grid_d, y = density_x1_1)\n\nIn the following graphs, the example of the transportation of one individual with \\(S=0\\) will be displayed:\n\n# Individual from subset S=0 to transport\nx1 &lt;- -2\nx2 &lt;- -1\n\nUsing the function T_X1 created earlier, we can transport the example individual from subset \\(S=0\\) to subset \\(S=1\\) along its first coordinate \\(x_1\\).\n\nx1_star &lt;- T_X1(x1)\n\nWe also calculate the indices of \\(X_1\\) grids that are below this individual (\\(x_1\\)) and its counterfactual (\\(x_1^*\\)) in order to plot the cdf’s of \\(X_1\\) in both subsets \\(S=0\\) and \\(S=1\\) in the following graphs:\n\n# Define indices of X1 grid \nidx1 &lt;- which(d_0$x &lt;= x1)\nidx1_star &lt;- which(d_0$x &lt;= x1_star)\n\nHere, we plot the optimal transport curve for \\(X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) with the densities corresponding to each subset. Additionnally, the result for the individual from above is displayed.\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2,2,0,0))\nlimA &lt;- c(-5, 5)\nlimB &lt;- c(-5, 5) \nlimY &lt;- c(0, .5)\nlab &lt;- c(\"A\", \"B\")\nsub &lt;- 6\n{\n  mat &lt;- matrix(c(1, 2, 0, 3), 2)\n  par(mfrow = c(2, 2))\n  layout(mat, c(3.5, 1), c(1, 3))\n  par(mar = c(0.5, 4.5, 0.5, 0.5))\n}\n\n# Plot density of X1 in subset S=0\nplot(\n  d_0$x, d_0$y, type = \"l\", col = colours[lab[1]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limA, ylim = limY\n)\npolygon(\n  c(min(d_0$x), d_0$x, max(d_0$x)), c(0, d_0$y, 0), \n  col = scales::alpha(colours[lab[1]], 0.1), border = NA\n)\n# Plot cdf of X1 in subset S=0\npolygon(\n  c(min(d_0$x), d_0$x[idx1], max(d_0$x[idx1])),\n  c(0, d_0$y[idx1], 0),\n  col = scales::alpha(colours[\"A\"], .2),\n  border = NA\n)\n# Add x-axis for density and cdf\naxis(\n  1, at = seq(limA[1], limA[2], length = sub), \n  label = c(NA, seq(limA[1], limA[2], length = sub)[-1])\n)\n\n# Plot transport line on X1 from S=0 to S=1\npar(mar = c(4.5, 4.5, 0.5, 0.5))\nplot(\n  x1_grid_t, x1_star_grid_t, col = colours[\"1\"], lwd = 2, \n  type = \"l\", xlab = \"\", ylab = \"\", xlim = limA, ylim = limB, \n  axes = FALSE\n)\n# Identity function line\nabline(a = 0, b = 1, col = colours[\"0\"], lty = 2)\n\n# Add x-axis and y-axis of the transport line\naxis(1)\naxis(2)\n# Legend\nmtext(\"distribution (group 0)\", side = 1, line = 3, col = \"black\")\nmtext(\"distribution (group 1)\", side = 2, line = 3, col = \"black\")\n\n# Plot individual from subset S=0\npoints(x1, x1_star, pch = 19, col = colours[\"1\"])\nsegments(x1, x1_star, x1, 10, lwd = .4, col = colours[\"1\"])\nsegments(x1, x1_star, 10, x1_star, lwd = .4, col = colours[\"1\"])\n\n# Plot density of X1 in subset S=1\npar(mar = c(4.5, 0.5, 0.5, 0.5))\nplot(\n  d_1$y, d_1$x, type = \"l\", col = colours[lab[2]], lwd = 2, \n  ylim = limB, xlim = limY, xlab = \"\", ylab = \"\", axes = FALSE\n)\npolygon(\n  c(0, d_1$y, 0), c(min(d_1$x), d_1$x, max(d_1$x)), \n  col = scales::alpha(colours[lab[2]], 0.1), border = NA\n)\n# Plot cdf of X1 in subset S=1\npolygon(\n  c(0, d_1$y[idx1_star], 0),\n  c(min(d_1$x), d_1$x[idx1_star], max(d_1$x[idx1_star])),\n  col = scales::alpha(colours[\"B\"], .2),\n  border = NA\n)\n# Add y-axis for density and cdf\naxis(\n  2, at = seq(limB[1], limB[2], length = sub), \n  label = c(NA, seq(limB[1], limB[2], length = sub)[-c(1, sub)], NA)\n)\n\n\n\n\n\nFigure 2.2: Illustration of Algorithm 2.1 for DAG in Figure 3.13 with simulated data. First step: transport of \\(X_1\\) from \\(S=0\\) to \\(S=1\\)\n\n\n\n\n\n\n\n\nThen we plot the counterfactual obtained from sequential transport on \\(X_1\\) (which corresponds to univariate optimal transport) for the individual, on the contour lines of both groups \\(S=0\\) and \\(S=1\\).\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2,2,0,0))\n\n# Contour line of bivariate Gaussian density for subset S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = scales::alpha(colours[\"A\"], .4),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Contour line of bivariate Gaussian density for subset S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = scales::alpha(colours[\"B\"], .4), add = TRUE\n)\n\n# Add x-axis and y-axis\naxis(1)\naxis(2)\n\n# Plot density of X1 for subset S=0\npolygon(\n  c(min(d_0$x), d_0$x, max(d_0$x)),  c(0, d_0$y, 0) * 5 - 5, \n  col = scales::alpha(colours[lab[1]], 0.4), \n  border = NA\n)\n# Add cdf of X1 for subset S=0\npolygon(\n  c(min(d_0$x), d_0$x[idx1], max(d_0$x[idx1])), c(0, d_0$y[idx1],0) * 5 - 5,\n  col = scales::alpha(colours[\"A\"], 0.4),\n  border = NA\n)\n\n# Plot density of X1 for subset S=1\npolygon(\n  c(min(d_1$x), d_1$x, max(d_1$x)),\n  c(0, d_1$y, 0) * 5 - 5, \n  col = scales::alpha(colours[lab[2]], 0.4), border = NA\n)\n# Add cdf of X1 for subset S=1\npolygon(\n  c(min(d_1$x), d_1$x[idx1_star], max(d_1$x[idx1_star])), \n  c(0, d_1$y[idx1_star],0) * 5 - 5,\n  col = scales::alpha(colours[\"B\"], .4),\n  border = NA\n)\n\n# Plot example individual from subset S=0\npoints(x1, x2, pch = 19)\nabline(v = x1, lwd = .4, col = colours[\"A\"])\nabline(v = x1_star, col = \"black\", lwd = .5)\n# Display the transported individual\npoints(A_opt_transport[1], A_opt_transport[2], pch = 15, col = \"#C93312\")\n\n\n\n\n\nFigure 2.3: Illustration of Algorithm 2.1 for DAG in Figure 3.13 with simulated data. First step: transport of \\(X_1\\) from \\(S=0\\) to \\(S=1\\). The green vertical line show the coordinate \\(x_1\\) of the individual. The yellow vertical line is the transported value in group \\(S=1\\). The red square is the multivariate OT of the point.\n\n\n\n\n\n\n\n\n\n\n2.3.2 Transport of \\(X_2|X_1\\)\nSecondly, according to Figure Figure 3.13, we transport \\(X_2\\) from subset \\(S=0\\) to subset \\(S=1\\), using conditional transport for univariate distribution \\(X_2|X_1\\) as \\(X_1\\) is the only parent of \\(X_2\\). Following Algorithm 2.1, we apply the following function estimated on \\(X_2\\) and \\(X_1\\) from data \\(\\hat{F}_{2|0} \\circ \\hat{Q}_{2|1}\\). Here the empirical cdf’s and quantile functions need to be estimated conditionally on \\(X_1\\). To do so, we first estimate densities of \\(X_2\\) in both subsets \\(S=0\\) and \\(S=1\\) with weights on \\(X_1\\) calculated with Gaussian kernels for each sensitive group. Here, we will only condition the distribution of \\(X_2\\) in subset \\(S=0\\) (resp. \\(S=1\\)) on the example value \\(x_1\\) (resp. \\(x_1^*\\)).\n\n# Bandwidth for Gaussian kernels\nh &lt;- 0.5\n# Weighted density of X2 for subset S=0\nw0 &lt;-  dnorm(D_SXY0[, \"X1\"], x1, h)\nw0 &lt;- w0 / sum(w0)\nd0x2cx1 &lt;- function(x) {\n  dens &lt;- density(\n    D_SXY0[, \"X2\"],\n    bw = .2,\n    weights = w0,\n    from = x, to = x, n = 1\n  )\n  dens$y\n}\n# Weighted density of X2 for subset S=1\nw1 &lt;- dnorm(D_SXY0[, \"X1\"], x1_star, h)\nw1 &lt;- w1/sum(w1)\nd1x2cx1 &lt;- function(x) {\n  dens &lt;- density(\n    D_SXY1[, \"X2\"],\n    bw = .2, \n    weights = w1, \n    from = x, to = x, n = 1\n  )\n  dens$y\n}\n# cdf of X2 for subset S=0\nFD0x2 &lt;- function(x, denom = NULL) {\n  x_val &lt;- seq(-10, x, by = .0025)\n  if (is.null(denom)) {\n    x_val_2 &lt;- seq(-10, 10, by = .0025)\n    denom &lt;- map_dbl(x_val_2, d0x2cx1) |&gt; sum()\n  }\n  sum(map_dbl(x_val, d0x2cx1)) / denom\n}\nFD0x2_denom &lt;- map_dbl(seq(-10, 10, by = .0025), d0x2cx1) |&gt; sum()\n\n# cdf of X2 for subset S=1\nFD1x2 &lt;- function(x, denom = NULL) {\n  x_val &lt;- seq(-10, x, by = .0025)\n  if (is.null(denom)) {\n    x_val_2 &lt;- seq(-10, 10, by = .0025)\n    denom &lt;- map_dbl(x_val_2, d1x2cx1) |&gt; sum()\n  }\n  sum(map_dbl(x_val, d1x2cx1)) / denom\n}\nFD1x2_denom &lt;- map_dbl(seq(-10, 10, by = .0025), d1x2cx1) |&gt; sum()\n\n# Definition of the inverse function\ninverse &lt;- function (f, lower = -100, upper = 100, denom) {\n  function (y) as.numeric(\n    uniroot((function (x) f(x, denom = denom) - y), lower = lower, upper = upper)[1]\n  )\n}\n# Quantile function of X2 for subset S=1\nQD1x2 &lt;- inverse(FD1x2, -10, 10, denom = FD1x2_denom)\n\n# Transport function for X2|X1=x1\nT_X2_c_x1 &lt;- function(x) as.numeric(QD1x2(FD0x2(x, denom = FD0x2_denom)))\n\nNext, we plot the optimal transport curve for \\(X_2|X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) with the densities corresponding to each subset. Additionnally, the result for the individual from above is displayed. We use the same graph parameters than above.\nWe start by applying function T_X2_c_x1 above to transport the variable \\(X_2|X_1=x_1\\).\n\nx2_grid_t &lt;- seq(-3.5, 1.75, length=101)\n\n\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(purrr)\n}) |&gt;\n  invisible()\n\nclusterExport(cl, c(\"w0\" ,\"w1\", \"D_SXY0\", \"D_SXY1\", \"FD0x2_denom\", \"FD1x2_denom\"))\nclusterExport(cl, c(\"d0x2cx1\", \"d1x2cx1\", \"FD0x2\", \"FD1x2\", \"QD1x2\", \"FD0x2\"))\n\nx2_star_grid_t &lt;- pblapply(x2_grid_t, T_X2_c_x1, cl = cl)\n\nstopCluster(cl)\n\nsave(x2_star_grid_t, file = \"../data/x2_grid_transport.rda\")\n\nOnce again, because the application of transport on \\(X_2|X_1\\) takes approximately 3 minutes, we will only load the file presaved and we don’t need to calculate T_X2_c_x1 over the grid.\n\nload(\"../data/x2_grid_transport.rda\")\n\nWe will depict the resulting mapping for all observations. The density of \\(X_2|X_1=x_1\\) (resp. \\(X_2|X_1=x_1^*\\)) for group \\(S=0\\) (reps. \\(S=1\\)) is calculated especially for the graphs.\n\n# Calculation of densities with grid values for X2 \ndensity_x2cx1_0 &lt;- map_dbl(d_0$x, d0x2cx1)\ndensity_x2cx1_1 &lt;- map_dbl(d_1$x, d1x2cx1)\n\nIn the following graphs, the example of the transportation of one individual with \\(S=0\\) will be displayed:\n\nx2_c_x1_star &lt;- T_X2_c_x1(x2)\n\nWe also calculate the indices of \\(X_2\\) grids that are below this individual (\\(x_2\\)) and its counterfactual (\\(x_2^*\\)) in order to plot the cdf’s of \\(X_2|X_1=x_1\\) in both subsets \\(S=0\\) and \\(S=1\\) in the following graphs:\n\n# Define indices of X1 grid \nidx2 &lt;- which(d_0$x &lt;= x2)\nidx2_star &lt;- which(d_0$x &lt;= x2_c_x1_star)\n\nHere, we plot the optimal transport curve for \\(X_2|X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) with the densities corresponding to each subset (calculated with Gaussian kernels). Additionnally, the result for the individual from above is displayed.\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2,2,0,0))\n{\n  mat &lt;- matrix(c(1, 2, 0, 3), 2)\n  par(mfrow = c(2, 2))\n  layout(mat, c(3.5, 1), c(1, 3))\n  par(mar = c(0.5, 4.5, 0.5, 0.5))\n}\n\n# Plot density of X2|X1 in subset S=0 with weights w0\nplot(\n  d_0$x, density_x2cx1_0, type = \"l\", col = colours[lab[1]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limA, ylim = limY\n)\npolygon(\n  c(min(d_0$x), d_0$x, max(d_0$x)), c(0, density_x2cx1_0, 0), \n  col = scales::alpha(colours[lab[1]], 0.1), border = NA\n)\n# Plot cdf of X1 in subset S=0 with weights w0\npolygon(\n  c(min(d_0$x), d_0$x[idx2], max(d_0$x[idx2])), c(0, density_x2cx1_0[idx2], 0),\n  col = scales::alpha(colours[\"A\"], .2),\n  border = NA\n)\n# Add x-axis for cdf and density\naxis(\n  1, at = seq(limA[1], limA[2], length = sub), \n  label = c(NA, seq(limA[1], limA[2], length = sub)[-1])\n)\n\n# Plot transport line for X2|X1 from subset S=0 to S=1\npar(mar = c(4.5, 4.5, 0.5, 0.5))\nplot(\n  x2_grid_t, x2_star_grid_t, col = colours[\"1\"], lwd = 2,\n  type = \"l\", xlab = \"\", ylab = \"\", xlim = limA, ylim = limB,\n  axes = FALSE\n)\nabline(a = 0, b = 1, col = colours[\"0\"], lty = 2)\n\n# Add x-axis and y-axis\naxis(1)\naxis(2)\n\n# Legend\nmtext(\"distribution (group 0)\", side = 1, line = 3, col = \"black\")\nmtext(\"distribution (group 1)\", side = 2, line = 3, col = \"black\")\n\n# Plot example individual on the transport line\npoints(x2, x2_c_x1_star, pch = 19, col = colours[\"1\"])\nsegments(x2, x2_c_x1_star, x2, 10, lwd = .4, col = colours[\"1\"])\nsegments(x2, x2_c_x1_star, 10, x2_c_x1_star, lwd = .4, col = colours[\"1\"])\n\n# Plot density of X2|X1 in subset S=1 with weights w1\npar(mar = c(4.5, 0.5, 0.5, 0.5))\nplot(\n  density_x2cx1_1, d_1$x, type = \"l\", col = colours[lab[2]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limY, ylim = limB\n)\npolygon(\n  c(0, density_x2cx1_1, 0), c(min(d_1$x), d_1$x, max(d_1$x)),\n  col = scales::alpha(colours[lab[2]], 0.1), \n  border = NA\n)\n# Plot cdf of X1 in subset S=1 with weights w1\npolygon(\n  c(0, density_x2cx1_1[idx2_star], 0), \n  c(min(d_1$x), d_1$x[idx2_star], max(d_1$x[idx2_star])),\n  col = scales::alpha(colours[\"B\"], .2),\n  border = NA\n)\n# Add y-axis for cdf and density\naxis(\n  2, at = seq(limB[1], limB[2], length = sub), \n  label = c(NA, seq(limB[1], limB[2], length = sub)[-c(1, sub)], NA)\n)\n\n\n\n\n\nFigure 2.4: Illustration of Algorithm 2.1 for DAG in Figure 3.13 with simulated data. Second step: transport of \\(X_1|X_2\\) from \\(S=0\\) to \\(S=1\\)\n\n\n\n\n\n\n\n\nThen we plot the counterfactual obtained from sequential transport on \\(X_2|X_1\\) (which corresponds to univariate conditional transport) for the individual, on the contour lines of both groups \\(S=0\\) and \\(S=1\\).\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2, 2, 0, 0))\n\n# Contour lines for bivariate density of gaussian distribution in subset S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = scales::alpha(colours[\"A\"], .4), axes = FALSE, xlab = \"\", ylab = \"\"\n)\n\n# x-axis and y-axis\naxis(1)\naxis(2)\n\n# Contour lines for bivariate density of gaussian distribution in subset S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = scales::alpha(colours[\"B\"], .4), add = TRUE\n)\n\n# Plot the density of X2|X1 in subset S=0 with weights w0\npolygon(\n  c(0, density_x2cx1_0, 0)*5-2, c(-5, d_0$x, 5), \n  col = scales::alpha(colours[lab[1]], 0.4), \n  border = NA\n)\n# Plot the cdf of X2|X1 in subset S=0\npolygon(\n  c(0, density_x2cx1_0[idx2], 0) * 5 - 2,\n  c(min(d_0$x), d_0$x[idx2], max(d_0$x[idx2])),\n  col = scales::alpha(colours[\"A\"], .4),\n  border = NA\n)\n# Plot crossing lines (X1, X2) at example individual from subset S=0\nabline(v = x1, col = colours[\"A\"], lwd = .5)\nabline(h = x2, col = colours[lab[1]], lwd = .5)\npoints(x1, x2, pch=19)\n\n# Plot the density of X2|X1 in subset S=1 with weights w1\npolygon(\n  c(0, density_x2cx1_1, 0) * 5 + x1_star, c(-5, d_1$x, 5), \n  col = scales::alpha(colours[lab[2]], 0.4), \n  border = NA\n)\n# Plot the cdf of X2|X1 in subset S=1\npolygon(\n  c(0, density_x2cx1_1[idx2_star], 0) * 5 + x1_star,\n  c(min(d_1$x), d_1$x[idx2_star], max(d_1$x[idx2_star])),\n  col = scales::alpha(colours[\"B\"], .4),\n  border = NA\n)\n# Plot crossing lines (X1, X2) at example individual when transported to subset S=1\nabline(v = x1_star, col = colours[lab[2]], lwd = .5)\nabline(h = x2_c_x1_star, col = \"black\", lwd = .5)\npoints(x1_star, x2_c_x1_star, pch=19)\n# Display the transported individual\npoints(A_opt_transport[1], A_opt_transport[2], pch = 15, col = \"#C93312\")\n\n\n\n\nIllustration of Algorithm 2.1 for DAG in Figure 3.13 with simulated data. Second step: transport of \\(X_2|X_1\\) from \\(S=0\\) to \\(S=1\\). The green horizontal line show the coordinate \\(x_2\\) of the individual. The yellow horizontal line is the transported value in group \\(S=1\\). The red square is the multivariate OT of the point.",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gaussian Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian.html#faster-sequential-transport",
    "href": "gaussian.html#faster-sequential-transport",
    "title": "2  Gaussian Simulations",
    "section": "2.4 Faster Sequential Transport",
    "text": "2.4 Faster Sequential Transport\nIn this part, we establish grids for \\(X_1\\) and \\(X_2\\) to calculate and store the cdf’s and quantile functions of the variables \\(X_1\\), \\(X_2\\), \\(X_2|X_1\\) and \\(X_1|X_2\\) for both subsets \\(S=0\\) and \\(S=1\\). This approach allows us to apply these functions to individuals based on their positions within the grids, rather than having to compute them each time. Instead of first calculating the cdf at \\(X_1=x_1\\) and then transporting it, we directly apply the cdf and quantile functions at the corresponding \\(X_1\\) grid position near \\(x_1\\). Then, for transporting \\(X_2|X_1\\), we start by storing the relevant cdf’s and quantile functions in a matrix, with rows corresponding to grid values for \\(X_1\\) and columns to grid values for \\(X_2\\). To apply the conditional cdf and quantile function to an individual \\((s=0,x_1,x_2)\\) i.e., sequential transport, rather than relying on Gaussian weights to define a neighborhood around \\(x_1\\), we define a window of width h around the midpoints of the grid cells for \\(X_1\\) and calculate cdf of \\(X_2\\) on this space.\nIn Algorithm 2.2 if \\(j\\) has no parents, \\(\\mathrm{parents}(j)=\\varnothing\\), \\(d_j=0\\) and then \\(F_{j|s}\\) and \\(Q_{j|s}\\) are vectors (of length \\(k\\)). In Algorithm 2.3, in that case, \\(\\boldsymbol{i}_0=\\boldsymbol{i}_1=\\varnothing\\).\n\n\n\\begin{algorithm} \\caption{Faster sequential transport on causal graph (1)} \\begin{algorithmic} \\Require graph on \\((s,\\boldsymbol{x})\\), with adjacency matrix \\(\\boldsymbol{A}\\) \\Require dataset \\((s_i,\\boldsymbol{x}_i)\\) and \\(k\\in\\mathbb{N}\\) some grid size, \\Require grids \\(\\boldsymbol{g}_{j|s}=({g}_{j,1|s},\\cdots,{g}_{j,k|s})\\), for all variable \\(j\\) \\Require grid \\(\\boldsymbol{u}=(1,\\cdots,k)/(k+1)\\), for all \\(j\\) \\State \\((s,\\boldsymbol{v})\\gets\\boldsymbol{A}\\) the topological ordering of vertices (DFS) \\For{\\(j\\in \\boldsymbol{v}\\)} \\State \\(\\boldsymbol{p}(j) \\gets \\text{parents}(j)\\), dimension \\(d_j\\) \\State \\(\\mathcal{G}_{j|s}\\gets\\) grid \\(\\boldsymbol{g}_{\\boldsymbol{p}(j)_1|s}\\times\\cdots\\times\\boldsymbol{g}_{\\boldsymbol{p}(j)_{d_j}|s}\\) \\State \\(F_{j|s}\\gets\\) tensors \\(k\\times k^{d_j}\\), taking values in \\(\\boldsymbol{u}\\) \\State \\(Q_{j|s}\\gets\\) tensors \\(k\\times k^{d_j}\\), taking values in \\(\\boldsymbol{g}_{j|s}\\) \\For{\\(\\boldsymbol{i}=(i_1,\\cdots,i_{d_j})\\in\\{1,\\cdots,k\\}^{d_j}\\)} \\State \\(F_{j|s}[\\cdot,\\boldsymbol{i}]\\gets\\) c.d.f. of \\(X_j|\\boldsymbol{X}_{\\boldsymbol{p}(j)}=\\boldsymbol{g}_{\\boldsymbol{i}|s},S=s\\) \\State \\(Q_{j|s}[\\cdot,\\boldsymbol{i}]\\gets\\) quantile of \\(X_j|\\boldsymbol{X}_{\\boldsymbol{p}(j)}=\\boldsymbol{g}_{\\boldsymbol{i}|s},S=s\\) \\EndFor \\EndFor \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\\begin{algorithm} \\caption{Counterfactual calculation on causal graph (2)} \\begin{algorithmic} \\Require \\(F_{1|s},\\cdots,F_{d|s}\\) and \\(Q_{d|s},\\cdots,Q_{d|s}\\) \\Require grids \\(\\boldsymbol{g}_{1|s},\\cdots,\\boldsymbol{g}_{d|s}\\), \\(\\mathcal{G}_{1|s},\\cdots,\\mathcal{G}_{d|s}\\) and \\(\\boldsymbol{u}\\) \\Require features \\(\\boldsymbol{a}\\in\\mathbb{R}^d\\) (group 0) \\State \\(\\boldsymbol{b}\\gets \\boldsymbol{a}\\) \\For{\\(j\\in \\boldsymbol{v}\\)} \\State \\(\\boldsymbol{i}_0\\gets \\boldsymbol{a}_{\\boldsymbol{p}(j)}\\) on grid \\(\\mathcal{G}_{j|0}\\) \\State \\(k_0\\gets a_j\\) on grid \\(\\boldsymbol{g}_{j|0}\\) \\State \\(p\\gets F_{j|0}[k_0,\\boldsymbol{i}_0]\\) \\State \\(\\boldsymbol{i}_1\\gets \\boldsymbol{b}_{\\boldsymbol{p}(j)}\\) on grid \\(\\mathcal{G}_{j|1}\\) \\State \\(k_1\\gets p\\) on grid \\(\\boldsymbol{u}\\) \\State \\(b_j\\gets Q_{j|1}[k_1,\\boldsymbol{i}_1]\\) \\EndFor \\Return \\(\\boldsymbol{b}\\) (counterfactual in group 1) \\end{algorithmic} \\end{algorithm}\n\n\nHere, we redefine the outputs of sequential transport function in order to plot the different grids and associated cdf’s for \\(X_2\\) and \\(X_1\\) in both subsets \\(S=0\\) and \\(S=1\\).\n\n#' Sequential transport\n#'\n#' @param data dataset with three columns:\n#'  - S: sensitive attribute, transport from S_0 to the other group\n#'  - X1: first predictor, assumed to be causally linked to S\n#'  - X2: second predictor, assumed to be causally linked to S and X1\n#' @param S_0 Modality called group 0 to (source distribution)\n#' @param number of cells in each dimension (default to 15)\n#' @param h small value added to extend the area covered by the grid (default\n#'  to .2)\n#' @param d neighborhood weight when conditioning by x1 (default to .5)\ntransport_function_2 &lt;- function(data,\n                                 S_0,\n                                 n_grid = 15,\n                                 h = .2,\n                                 d = .5) {\n\n  # Subset of the data: 0 for Black, 1 for White\n  D_SXY_0 &lt;- data[data$S == S_0, ]\n  D_SXY_1 &lt;- data[data$S != S_0, ]\n\n  # Coordinates of the cells of the grid on subset of 0 (Black)\n  vx1_0 &lt;- seq(min(D_SXY_0$X1) - h, max(D_SXY_0$X1) + h, length = n_grid + 1)\n  vx2_0 &lt;- seq(min(D_SXY_0$X2) - h, max(D_SXY_0$X2) + h, length = n_grid + 1)\n  # and middle point of the cells\n  vx1_0_mid &lt;- (vx1_0[2:(1+n_grid)]+vx1_0[1:(n_grid)]) / 2\n  vx2_0_mid &lt;- (vx2_0[2:(1+n_grid)]+vx2_0[1:(n_grid)]) / 2\n\n  # Coordinates of the cells of the grid on subset of 1 (White)\n  vx1_1 &lt;- seq(min(D_SXY_1$X1) -h, max(D_SXY_1$X1) + h, length = n_grid + 1)\n  vx1_1_mid &lt;- (vx1_1[2:(1 + n_grid)] + vx1_1[1:(n_grid)]) / 2\n  # and middle point of the cells\n  vx2_1 &lt;- seq(min(D_SXY_1$X2) - h, max(D_SXY_1$X2) + h, length = n_grid + 1)\n  vx2_1_mid &lt;- (vx2_1[2:(1 + n_grid)] + vx2_1[1:(n_grid)]) / 2\n\n  # Creation of the grids for the CDF and Quantile function\n  # init with NA values\n  # One grid for X1 and X2, on both subsets of the data (Black/White)\n  F1_0 &lt;- F2_0 &lt;- F1_1 &lt;- F2_1 &lt;- matrix(NA, n_grid, n_grid)\n  Q1_0 &lt;- Q2_0 &lt;- Q1_1 &lt;- Q2_1 &lt;- matrix(NA, n_grid, n_grid)\n\n  # Empirical CDF for X1 on subset of Black\n  FdR1_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X1 &lt;= x))\n  f1_0 &lt;- FdR1_0(vx1_0_mid)\n  # Empirical CDF for X2 on subset of Black\n  FdR2_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X2 &lt;= x))\n  f2_0 &lt;- FdR2_0(vx2_0_mid)\n  # Empirical CDF for X1 on subset of White\n  FdR1_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X1 &lt;= x))\n  f1_1 &lt;- FdR1_1(vx1_1_mid)\n  # Empirical CDF for X2 on subset of White\n  FdR2_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X2 &lt;= x))\n  f2_1 &lt;- FdR2_1(vx2_1_mid)\n\n  u &lt;- (1:n_grid) / (n_grid + 1)\n  # Empirical quantiles for X1 on subset of Black\n  Qtl1_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X1, x))\n  q1_0 &lt;- Qtl1_0(u)\n  # Empirical quantiles for X2 on subset of Black\n  Qtl2_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X2, x))\n  q2_0 &lt;- Qtl2_0(u)\n  # Empirical quantiles for X1 on subset of White\n  Qtl1_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X1, x))\n  q1_1 &lt;- Qtl1_1(u)\n  # Empirical quantiles for X2 on subset of White\n  Qtl2_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X2, x))\n  q2_1 &lt;- Qtl2_1(u)\n\n  for (i in 1:n_grid) {\n    # Subset of Black individuals\n    idx1_0 &lt;- which(abs(D_SXY_0$X1 - vx1_0_mid[i]) &lt; d)\n    FdR2_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X2[idx1_0] &lt;= x))\n    F2_0[, i] &lt;- FdR2_0(vx2_0_mid)\n    Qtl2_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X2[idx1_0], x))\n    Q2_0[, i] &lt;- Qtl2_0(u)\n\n    idx2_0 &lt;- which(abs(D_SXY_0$X2 - vx2_0_mid[i]) &lt; d)\n    FdR1_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X1[idx2_0] &lt;= x))\n    F1_0[, i] &lt;- FdR1_0(vx1_0_mid)\n    Qtl1_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X1[idx2_0], x))\n    Q1_0[, i] &lt;- Qtl1_0(u)\n\n    # Subset of White individuals\n    idx1_1 &lt;- which(abs(D_SXY_1$X1 - vx1_1_mid[i]) &lt; d)\n    FdR2_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X2[idx1_1] &lt;= x))\n    F2_1[, i] &lt;- FdR2_1(vx2_1_mid)\n    Qtl2_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X2[idx1_1], x))\n    Q2_1[, i] &lt;- Qtl2_1(u)\n\n    idx2_1 &lt;- which(abs(D_SXY_1$X2-vx2_1_mid[i])&lt;d)\n    FdR1_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X1[idx2_1] &lt;= x))\n    F1_1[, i] &lt;- FdR1_1(vx1_1_mid)\n    Qtl1_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X1[idx2_1], x))\n    Q1_1[, i] &lt;- Qtl1_1(u)\n  }\n\n  # Transport for X2\n  T2 &lt;- function(x2) {\n    i &lt;- which.min(abs(vx2_0_mid - x2))\n    p &lt;- f2_0[i]\n    i &lt;- which.min(abs(u - p))\n    x2star &lt;- q2_1[i]\n    x2star\n  }\n\n  # Transport for X1\n  T1 &lt;- function(x1) {\n    i &lt;- which.min(abs(vx1_0_mid - x1))\n    p &lt;- f1_0[i]\n    i &lt;- which.min(abs(u - p))\n    x1star &lt;- q1_1[i]\n    x1star\n  }\n\n  # Transport for X2 conditional on X1\n  T2_cond_x1 &lt;- function(x2, x1) {\n    k0 &lt;- which.min(abs(vx1_0_mid - x1))\n    k1 &lt;- which.min(abs(vx1_1_mid - T1(x1)))\n    i &lt;- which.min(abs(vx2_0_mid - x2))\n    p &lt;- F2_0[i, k0]\n    i &lt;- which.min(abs(u - p))\n    x2star &lt;- Q2_1[i, k1]\n    x2star\n  }\n\n  # Transport for X1 conditional on X2\n  T1_cond_x2 &lt;- function(x1, x2) {\n    k0 &lt;- which.min(abs(vx2_0_mid - x2))\n    k1 &lt;- which.min(abs(vx2_1_mid - T2(x2)))\n    i &lt;- which.min(abs(vx1_0_mid - x1))\n    p &lt;- F1_0[i, k0]\n    i &lt;- which.min(abs(u - p))\n    x1star &lt;- Q1_1[i, k1]\n    x1star\n  }\n\n  list(\n    Transport_x1 = T1,\n    Transport_x2 = T2,\n    Transport_x1_cond_x2 = T1_cond_x2,\n    Transport_x2_cond_x1 = T2_cond_x1,\n    vx1_0 = vx1_0,\n    vx1_0_mid = vx1_0_mid,\n    vx1_1 = vx1_1,\n    vx1_1_mid = vx1_1_mid,\n    vx2_0 = vx2_0,\n    vx2_1 = vx2_1,\n    f1_0 = f1_0,\n    f1_1 = f1_1,\n    F2_0 = F2_0,\n    F2_1 = F2_1\n  )\n}\n\n# Application on the Gaussian database\nn_grid &lt;- 15\nS_0 &lt;- 0\nseq_functions_grids &lt;- transport_function_2(D_SXY, S_0 = S_0, n_grid = n_grid)\n\nWe first depict the grid for \\(X_1\\), computed on our Gaussian database, with the associated cdf’s in subsets \\(S=0\\) and \\(S=1\\).\n\n# Grid for X1 in subset S=0\nvx1_0 &lt;- seq_functions_grids$vx1_0\n# Midpoints of the cells\nvx1_0_mid &lt;- seq_functions_grids$vx1_0_mid\n# cdf (marginal) of X1 in subset S=0\nf1_0 &lt;- seq_functions_grids$f1_0\n\n# Grid for X1 in subset S=1\nvx1_1 &lt;- seq_functions_grids$vx1_1\n# Midpoints of the cells\nvx1_1_mid &lt;- seq_functions_grids$vx1_1_mid\n# cdf (marginal) of X1 in subset S=1\nf1_1 &lt;- seq_functions_grids$f1_1\n\n# Add x-axis\npar(mar = c(2,2,0,0))\nplot(\n  d_0$x, d_0$x*0, xlab = \"\", ylab = \"\", \n  axes = FALSE, col = NA, ylim = c(.5, 2.5)\n)\naxis(1)\n# Plot the cdf of X1 in subset S=0 with color scale\nfor (i in 1:n_grid) {\n  rect(vx1_0[i], .7, vx1_0[i+1], 0.6, \n       col = scales::alpha(colours[\"A\"], f1_0[i]),\n       border = \"grey\"\n  )\n}\n# Plot the cdf of X1 in subset S=1 with color scale\nfor (i in 1:n_grid) {\n  rect(\n    vx1_1[i], .8, vx1_1[i+1], .9,\n    col = scales::alpha(colours[\"B\"], f1_1[i]),\n    border = \"grey\"\n  )\n}\n\n\n\n\nFigure 2.5: Grid for \\(X_1\\)\n\n\n\n\n\n\n\n\nNext we display the matrices of cdf’s for \\(X_2|X_1\\) in both subsets \\(S=0\\) and \\(S=1\\):\n\n# Grid for X2 in subset S=0\nvx2_0 &lt;- seq_functions_grids$vx2_0\n# cdf (conditional) of X2|X1 in subset S=0 (matrix)\nF2_0 &lt;- seq_functions_grids$F2_0\n\n# Grid for X2 in subset S=1\nvx2_1 &lt;- seq_functions_grids$vx2_1\n# cdf (conditional) of X2|X1 in subset S=1 (matrix)\nF2_1 &lt;- seq_functions_grids$F2_1\n\nFirst, we plot the matrix for subset \\(S=0\\) and highlight the column corresponding to the cdf of \\(X_2|X_1=x_1\\) for our example individual:\n\n\nCodes used to create the Figure.\n# Add x-axis and y-axis (for the matrices with cdf's)\npar(mar = c(2,2,0,0))\nplot(d_0$x, d_0$x, xlab = \"\", ylab = \"\", axes = FALSE, col = NA)\naxis(1)\naxis(2)\n\n# Add grid matrix of cdf's for X2|X1 in subset S=0\nfor (i in 1:n_grid) {\n  for(j in 1:n_grid) {\n    rect(vx1_0[i], vx2_0[j], vx1_0[i+1], vx2_0[j+1], border=\"grey\")\n  }\n}\n# Column corresponding to X1=x1\ni &lt;- which.min(abs(vx1_0_mid-x1))\nfor (j in 1:n_grid) {\n  rect(\n    vx1_0[i], vx2_0[j], vx1_0[i+1], vx2_0[j+1], \n    col = scales::alpha(colours[\"A\"], F2_0[j,i]),\n    border=\"grey\"\n  )\n}\n\n\n\n\n\nFigure 2.6: Matrix $F_{2|0}, with \\(k=15\\). The vertical vector is \\(F_{2|0}[\\cdot, i]\\)\n\n\n\n\n\n\n\n\nNext, we plot the matrix for subset \\(S=1\\) and highlight the column corresponding to the cdf of \\(X_2|X_1=x_1^*\\) for our example individual:\n\n\nCodes used to create the Figure.\n# Add x-axis and y-axis (for the matrices with cdf's)\npar(mar = c(2,2,0,0))\nplot(d_1$x, d_1$x, xlab = \"\", ylab = \"\", axes = FALSE, col = NA)\naxis(1)\naxis(2)\n\n# Add grid matrix of cdf's for X2|X1 in subset S=1\nfor (i in 1:n_grid) {\n  for (j in 1:n_grid) {\n    rect(vx1_1[i], vx2_1[j], vx1_1[i + 1], vx2_1[j + 1], border = \"grey\")\n  }\n}\n# Column corresponding to X1=x1_star (i.e., x1 transported)\ni &lt;- which.min(abs(vx1_1_mid - x1_star))\nfor (j in 1:n_grid) {\n  rect(\n    vx1_1[i], vx2_1[j], vx1_1[i+1], vx2_1[j+1],\n    col = scales::alpha(colours[\"B\"], F2_1[j,i]),\n    border = \"grey\"\n  )\n}\n\n\n\n\n\nFigure 2.7: Matrix $F_{2|1}, with \\(k=15\\). The vertical vector is \\(F_{2|1}[\\cdot, j]\\)\n\n\n\n\n\n\n\n\nFollowing Algorithm 2.2 for Sequential Transport and the causal graph in Figure Figure 3.13, we begin by transporting \\(X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) xxx\n\nT_X1 &lt;- seq_functions_grids$Transport_x1\n\nWe start by applying function T_X1 above to transport only on the variable \\(X_1\\). We use more points in the grid than with Algorithm 2.1 because it is faster.\n\n# Calculation of transport line for different values of X1 (grid)\nx1_grid_t &lt;- seq(-3.5, 1.75, length = 251)\nx1_star_grid_t &lt;- Vectorize(T_X1)(x1_grid_t)\n\nUsing the function T_X1 created earlier, we can transport the example individual from subset \\(S=0\\) to subset \\(S=1\\) along its first coordinate \\(x_1\\).\n\nx1_star &lt;- T_X1(x1)\n\nWe also calculate the indices of \\(X_1\\) grids that are below this individual (\\(x_1\\)) and its counterfactual (\\(x_1^*\\)) in order to plot the cdf’s of \\(X_1\\) in both subsets \\(S=0\\) and \\(S=1\\) in the following graphs:\n\n# Define indices of X1 grid \nidx1 &lt;- which(d_0$x &lt;= x1)\nidx1_star &lt;- which(d_0$x &lt;= x1_star)\n\nHere, we plot the optimal transport curve for \\(X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) with the densities corresponding to each subset. Additionnally, the result for the individual from above is displayed.\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2,2,0,0))\nlimA &lt;- c(-5, 5)\nlimB &lt;- c(-5, 5) \nlimY &lt;- c(0, .5)\nlab &lt;- c(\"A\", \"B\")\nsub &lt;- 6\n{\n  mat &lt;- matrix(c(1, 2, 0, 3), 2)\n  par(mfrow = c(2, 2))\n  layout(mat, c(3.5, 1), c(1, 3))\n  par(mar = c(0.5, 4.5, 0.5, 0.5))\n}\n\n# Plot density of X1 in subset S=0\nplot(\n  d_0$x, d_0$y, type = \"l\", col = colours[lab[1]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limA, ylim = limY\n)\npolygon(\n  c(min(d_0$x), d_0$x, max(d_0$x)), c(0, d_0$y, 0), \n  col = scales::alpha(colours[lab[1]], 0.1), border = NA\n)\n# Plot cdf of X1 in subset S=0\npolygon(\n  c(min(d_0$x), d_0$x[idx1], max(d_0$x[idx1])),\n  c(0,d_0$y[idx1],0),\n  col = scales::alpha(colours[\"A\"], .2),\n  border = NA\n)\n# Add x-axis for density and cdf\naxis(\n  1, at = seq(limA[1], limA[2], length = sub), \n  label = c(NA, seq(limA[1], limA[2], length = sub)[-1])\n)\n\n# Plot transport line on X1 from S=0 to S=1\npar(mar = c(4.5, 4.5, 0.5, 0.5))\nu_grid &lt;- seq(0, 1, length=261)\nu_grid &lt;- u_grid[2:260]\nplot(\n  x1_grid_t, x1_star_grid_t, col = colours[\"1\"], lwd = 2, \n  type = \"l\", xlab = \"\", ylab = \"\", xlim = limA, ylim = limB, \n  axes = FALSE\n)\n# Identity function line\nabline(a = 0, b = 1, col = colours[\"0\"], lty = 2)\n\n# Add x-axis and y-axis of the transport line\naxis(1)\naxis(2)\n# Legend\nmtext(\"distribution (group 0)\", side = 1, line = 3, col = \"black\")\nmtext(\"distribution (group 1)\", side = 2, line = 3, col = \"black\")\n\n# Plot individual from subset S=0\npoints(x1, x1_star, pch = 19, col = colours[\"1\"])\nsegments(x1, x1_star, x1, 10, lwd = .4, col = colours[\"1\"])\nsegments(x1, x1_star, 10, x1_star, lwd = .4, col = colours[\"1\"])\n\n# Plot density of X1 in subset S=1\npar(mar = c(4.5, 0.5, 0.5, 0.5))\nplot(\n  d_1$y, d_1$x, type = \"l\", col = colours[lab[2]], lwd = 2, \n  ylim = limB, xlim = limY, xlab = \"\", ylab = \"\", axes = FALSE\n)\npolygon(\n  c(0, d_1$y, 0), c(min(d_1$x), d_1$x, max(d_1$x)), \n  col = scales::alpha(colours[lab[2]], 0.1), border = NA\n)\n# Plot cdf of X1 in subset S=1\npolygon(\n  c(0, d_1$y[idx1_star], 0),\n  c(min(d_1$x), d_1$x[idx1_star], max(d_1$x[idx1_star])),\n  col = scales::alpha(colours[\"B\"], .2),\n  border = NA\n)\n# Add y-axis for density and cdf\naxis(\n  2, at = seq(limB[1], limB[2], length = sub), \n  label = c(NA, seq(limB[1], limB[2], length = sub)[-c(1, sub)], NA)\n)\n\n\n\n\n\nFigure 2.8: Illustration of Algorithm 2.2 for DAG in Figure 3.13 with simulated data. First step: transport of \\(X_1\\) from \\(S=0\\) to \\(S=1\\)\n\n\n\n\n\n\n\n\nThen we plot the counterfactual obtained from sequential transport on \\(X_1\\) (which corresponds to univariate optimal transport) for the individual, on the contour lines of both groups \\(S=0\\) and \\(S=1\\).\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2,2,0,0))\n\n# Contour line of bivariate Gaussian density for subset S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]],\n  f0_2d$estimate, col = scales::alpha(colours[\"A\"],.4),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Contour line of bivariate Gaussian density for subset S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = scales::alpha(colours[\"B\"], .4), \n  add = TRUE\n)\n\n# Add x-axis and y-axis\naxis(1)\naxis(2)\n\n# Plot density of X1 for subset S=0\npolygon(\n  c(min(d_0$x), d_0$x, max(d_0$x)), \n  c(0, d_0$y, 0)*5-5, \n  col = scales::alpha(colours[lab[1]], 0.4), \n  border = NA\n)\n# Add cdf of X1 for subset S=0\npolygon(\n  c(min(d_0$x), d_0$x[idx1], max(d_0$x[idx1])),\n  c(0, d_0$y[idx1],0) * 5 - 5,\n  col = scales::alpha(colours[\"A\"], 0.4),\n  border = NA\n)\n\n# Plot density of X1 for subset S=1\npolygon(\n  c(min(d_1$x), d_1$x, max(d_1$x)),\n  c(0, d_1$y, 0)*5-5, \n  col = scales::alpha(colours[lab[2]], 0.4), border = NA\n)\n# Add cdf of X1 for subset S=1\npolygon(\n  c(min(d_1$x), d_1$x[idx1_star], max(d_1$x[idx1_star])),\n  c(0, d_1$y[idx1_star],0) * 5 - 5,\n  col = scales::alpha(colours[\"B\"], .4),\n  border = NA\n)\n\n# Plot example individual from subset S=0\npoints(x1, x2, pch = 19)\nabline(v = x1, lwd = .4, col = colours[\"A\"])\nabline(v = x1_star, col = \"black\", lwd = .5)\n# Display the transported individual\npoints(A_opt_transport[1], A_opt_transport[2], pch = 15, col = \"#C93312\")\n\n\n\n\n\nFigure 2.9: Illustration of Algorithm 2.2 for DAG in Figure 3.13 with simulated data. First step: transport of \\(X_1\\) from \\(S=0\\) to \\(S=1\\). The green vertical line show the coordinate \\(x_1\\) of the individual. The yellow vertical line is the transported value in group \\(S=1\\). The red square is the multivariate OT of the point.\n\n\n\n\n\n\n\n\nSecondly, according to Figure Figure 3.13, we transport \\(X_2\\) from subset \\(S=0\\) to subset \\(S=1\\), using conditional transport for univariate distribution \\(X_2|X_1\\) as \\(X_1\\) is the only parent of \\(X_2\\). Following Algorithm 2.1, we apply the following function estimated on \\(X_2\\) and \\(X_1\\) from data \\(\\hat{F}_{2|0} \\circ \\hat{Q}_{2|1}\\). Here the empirical cdf’s and quantile functions need to be estimated conditionally on \\(X_1\\). To do so, we first estimate densities of \\(X_2\\) in both subsets \\(S=0\\) and \\(S=1\\) with weights on \\(X_1\\) calculated with Gaussian kernels for each sensitive group. Here, we will only condition the distribution of \\(X_2\\) in subset \\(S=0\\) (resp. \\(S=1\\)) on the example value \\(x_1\\) (resp. \\(x_1^*\\)).\n\n# Transport function for X2|X1=x1\nT_X2_c_x1 &lt;- T_X1 &lt;- seq_functions_grids$Transport_x2_cond_x1\n\nNext, we plot the optimal transport curve for \\(X_2|X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) with the densities corresponding to each subset. Additionnally, the result for the individual from above is displayed. We use the same graph parameters than above.\nWe start by applying function T_X2_c_x1 above to transport the variable \\(X_2|X_1=x_1\\). We still use more points in the grid because faster\n\n# Calculation of transport line for different values of X2|X1=x1 (grid)\nx2_grid_t &lt;- seq(-3.5, 1.75, length = 251)\nx2_star_grid_t &lt;- Vectorize(function(x) T_X2_c_x1(x, x1))(x2_grid_t)\n\nIn the following graphs, the example of the transportation of one individual with \\(S=0\\) will be displayed:\n\nx2_c_x1_star &lt;- T_X2_c_x1(x2, x1)\n\nWe also calculate the indices of \\(X_2\\) grids that are below this individual (\\(x_2\\)) and its counterfactual (\\(x_2^*\\)) in order to plot the cdf’s of \\(X_2|X_1=x_1\\) in both subsets \\(S=0\\) and \\(S=1\\) in the following graphs:\n\n# Define indices of X1 grid \nidx2 &lt;- which(d_0$x &lt;= x2)\nidx2_star &lt;- which(d_0$x &lt;= x2_c_x1_star)\n\nHere, we plot the optimal transport curve for \\(X_2|X_1\\) from subset \\(S=0\\) to subset \\(S=1\\) with the densities corresponding to each subset (calculated with Gaussian kernels). Additionnally, the result for the individual from above is displayed.\n\n\nCodes used to create the Figure.\n# Graph parameters\n{\n  mat &lt;- matrix(c(1, 2, 0, 3), 2)\n  par(mfrow = c(2, 2))\n  layout(mat, c(3.5, 1), c(1, 3))\n  par(mar = c(0.5, 4.5, 0.5, 0.5))\n}\n\n# Plot density of X2|X1 in subset S=0 with weights w0\nplot(\n  d_0$x, density_x2cx1_0, type = \"l\", col = colours[lab[1]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limA, ylim = limY\n)\npolygon(\n  c(min(d_0$x), d_0$x, max(d_0$x)), c(0, density_x2cx1_0, 0), \n  col = scales::alpha(colours[lab[1]], 0.1), border = NA\n)\n# Plot cdf of X1 in subset S=0 with weights w0\npolygon(\n  c(min(d_0$x), d_0$x[idx2], max(d_0$x[idx2])),\n  c(0, density_x2cx1_0[idx2], 0),\n  col = scales::alpha(colours[\"A\"], .2),\n  border = NA\n)\n# Add x-axis for cdf and density\naxis(\n  1, at = seq(limA[1], limA[2], length = sub), \n  label = c(NA, seq(limA[1], limA[2], length = sub)[-1])\n)\n\n# Plot transport line for X2|X1 from subset S=0 to S=1\npar(mar = c(4.5, 4.5, 0.5, 0.5))\nplot(\n  x2_grid_t, x2_star_grid_t, col = colours[\"1\"], lwd = 2,\n  type = \"l\", xlab = \"\", ylab = \"\", xlim = limA, ylim = limB,\n  axes = FALSE\n)\nabline(a = 0, b = 1, col = colours[\"0\"], lty = 2)\n\n# Add x-axis and y-axis\naxis(1)\naxis(2)\n\n# Legend\nmtext(\"distribution (group 0)\", side = 1, line = 3, col = \"black\")\nmtext(\"distribution (group 1)\", side = 2, line = 3, col = \"black\")\n\n# Plot example individual on the transport line\npoints(x2, x2_c_x1_star, pch = 19, col = colours[\"1\"])\nsegments(x2, x2_c_x1_star, x2, 10, lwd = .4, col = colours[\"1\"])\nsegments(x2, x2_c_x1_star, 10, x2_c_x1_star, lwd = .4, col = colours[\"1\"])\n\n# Plot density of X2|X1 in subset S=1 with weights w1\npar(mar = c(4.5, 0.5, 0.5, 0.5))\nplot(\n  density_x2cx1_1, d_1$x, type = \"l\", col = colours[lab[2]], lwd = 2,\n  axes = FALSE, xlab = \"\", ylab = \"\", xlim = limY, ylim = limB\n)\npolygon(\n  c(0, density_x2cx1_1, 0), c(min(d_1$x), d_1$x, max(d_1$x)),\n  col = scales::alpha(colours[lab[2]], 0.1), \n  border = NA\n)\n# Plot cdf of X1 in subset S=1 with weights w1\npolygon(\n  c(0, density_x2cx1_1[idx2_star], 0), \n  c(min(d_1$x), d_1$x[idx2_star], max(d_1$x[idx2_star])),\n  col = scales::alpha(colours[\"B\"], .2),\n  border = NA\n)\n# Add y-axis for cdf and density\naxis(\n  2, at = seq(limB[1], limB[2], length = sub), \n  label = c(NA, seq(limB[1], limB[2], length = sub)[-c(1, sub)], NA)\n)\n\n\n\n\n\nFigure 2.10: Illustration of Algorithm 2.2 for DAG in Figure 3.13 with simulated data. Second step: transport of \\(X_1|X_2\\) from \\(S=0\\) to \\(S=1\\)\n\n\n\n\n\n\n\n\nThen we plot the counterfactual obtained from sequential transport on \\(X_2|X_1\\) (which corresponds to univariate conditional transport) for the individual, on the contour lines of both groups \\(S=0\\) and \\(S=1\\).\n\n\nCodes used to create the Figure.\n# Graph parameters\npar(mar = c(2, 2, 0, 0))\n\n# Contour lines for bivariate density of gaussian distribution in subset S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = scales::alpha(colours[\"A\"],.4),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n\n# x-axis and y-axis\naxis(1)\naxis(2)\n\n# Contour lines for bivariate density of gaussian distribution in subset S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = scales::alpha(colours[\"B\"],.4), add = TRUE\n)\n\n# Plot the density of X2|X1 in subset S=0 with weights w0\npolygon(\n  c(0, density_x2cx1_0, 0)*5-2, c(-5, d_0$x, 5), \n  col = scales::alpha(colours[lab[1]], 0.4), \n  border = NA\n)\n# Plot the cdf of X2|X1 in subset S=0\npolygon(\n  c(0, density_x2cx1_0[idx2], 0)*5-2,\n  c(min(d_0$x), d_0$x[idx2], max(d_0$x[idx2])),\n  col = scales::alpha(colours[\"A\"],.4),\n  border = NA\n)\n# Plot crossing lines (X1, X2) at example individual from subset S=0\nabline(v = x1, col = colours[\"A\"], lwd = .5)\nabline(h = x2, col = colours[lab[1]], lwd = .5)\npoints(x1, x2, pch=19)\n\n# Plot the density of X2|X1 in subset S=1 with weights w1\npolygon(\n  c(0, density_x2cx1_1, 0) * 5 + x1_star, c(-5, d_1$x, 5), \n  col = scales::alpha(colours[lab[2]], 0.4), \n  border = NA\n)\n# Plot the cdf of X2|X1 in subset S=1\npolygon(\n  c(0, density_x2cx1_1[idx2_star], 0) * 5 + x1_star,\n  c(min(d_1$x), d_1$x[idx2_star], max(d_1$x[idx2_star])),\n  col = scales::alpha(colours[\"B\"],.4),\n  border = NA\n)\n# Plot crossing lines (X1, X2) at example individual when transported to subset S=1\nabline(v = x1_star, col = colours[lab[2]], lwd = .5)\nabline(h = x2_c_x1_star, col = \"black\", lwd = .5)\npoints(x1_star, x2_c_x1_star, pch=19)\n# Display the transported individual\npoints(A_opt_transport[1], A_opt_transport[2], pch = 15, col = \"#C93312\")\n\n\n\n\n\nFigure 2.11: Illustration of Algorithm 2.2 for DAG in Figure 3.13 with simulated data. Second step: transport of \\(X_2|X_1\\) from \\(S=0\\) to \\(S=1\\). The green horizontal line show the coordinate \\(x_2\\) of the individual. The yellow horizontal line is the transported value in group \\(S=1\\). The red square is the multivariate OT of the point.",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Gaussian Simulations</span>"
    ]
  },
  {
    "objectID": "transport-fast-grid.html",
    "href": "transport-fast-grid.html",
    "title": "3  Fast Transport on a Grid with Numerical Covariates",
    "section": "",
    "text": "3.1 Data Generation\nConsider a causal structural model with a sensitive attribute \\(s\\) with no parents, two legitimate features \\(x_1\\) and \\(x_2\\), and an outcome \\(y\\).\nLet us draw 100 observation per group. For group 0, we draw values from a multivariate Gaussian distribution with mean -1 and the following variance-covariance matrix: \\(\\Sigma_0 = \\begin{bmatrix}1.2^2 & \\frac{1.2^2}{2}\\\\ \\frac{1.2^2}{2} & 1.2^2\\end{bmatrix}\\). For group 1, we draw values from a multivariate Gaussian distribution with mean 1.5 and with the following variance-covariance matrix: \\(\\Sigma_0 = \\begin{bmatrix}.9^2 & -\\frac{4\\times .9^2}{10}\\\\ -\\frac{4 \\times .9^2}{2} & .9^2\\end{bmatrix}\\).\n# Number of observations per group\nset.seed(123) # set the seed for reproductible results\nn &lt;- 100\n\n# First bivariate Gaussian distribution: group s=0\nM0 &lt;- c(-1, -1)\nS0 &lt;- matrix(c(1, .5, .5,1) * 1.2^2, 2, 2)\nX0 &lt;- mnormt::rmnorm(n, M0, S0)\nD_SXY_0 &lt;- data.frame(\n  S = 0,\n  X1 = X0[, 1],\n  X2 = X0[, 2]\n)\n\n# Second bivariate Gaussian distribution: group s=1\nM1 &lt;- c(1.5, 1.5)\nS1 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\nX1 &lt;- mnormt::rmnorm(n, M1, S1)\nD_SXY_1 &lt;- data.frame(\n  S = 1,\n  X1 = X1[,1],\n  X2 = X1[,2]\n)\nAssume the response variable, \\(Y\\), to be a binary variable that depends on the covariates of each group. More specifically, assume that it is drawn from a Bernoulli distribution with probability of occurrence being linked through a logistic function to \\(x_1\\) and \\(x_2\\), i.e., \\(Y \\sim \\mathcal{B}(p(S))\\), where \\(p(S)\\) differs among groups: \\[\np(S) = \\begin{cases}\n\\frac{\\exp{(\\eta_0})}{1+\\exp{(\\eta_0)}}, & \\text{if } S = 0,\\\\\n\\frac{\\exp{(\\eta_1})}{1+\\exp{(\\eta_1)}}, & \\text{if } S = 1,\n\\end{cases}\n\\] where \\[\n\\begin{cases}\n\\eta_0 = \\frac{1.2 x_1 + 1.6x2}{2}\\\\\n\\eta_1 = \\frac{.8 x_1 + 2.4x2}{2}.\n\\end{cases}\n\\]\n# Drawing random binary response variable Y with logistic model for each group\neta_0 &lt;- (D_SXY_0$X1 * 1.2 + D_SXY_0$X2 / 2 * .8) / 2\neta_1 &lt;- (D_SXY_1$X1 * .8 + D_SXY_1$X2 / 2 * 1.2) / 2\np_0 &lt;- exp(eta_0) / (1 + exp(eta_0))\np_1 &lt;- exp(eta_1) / (1 + exp(eta_1))\nD_SXY_0$Y &lt;- rbinom(n, size = 1, prob = p_0)\nD_SXY_1$Y &lt;- rbinom(n, size = 1, prob = p_1)\nWe merge the two datasets in a single one\nD_SXY &lt;- rbind(D_SXY_0, D_SXY_1)\nAnd we create two datasets that contain individuals from group 0 only, and individuals from group 1 only:\n# Dataset with individuals in group 0 only\nD_SXY0 &lt;- D_SXY[D_SXY$S == 0, ]\n# Dataset with individuals in group 1 only\nD_SXY1 &lt;- D_SXY[D_SXY$S == 1,]\nFor illustration, we would like to display the contour of the density in each group on the graphs. To do so, we rely on a kernel density estimation:\n# Computation of smoothing parameters (bandwidth) for kernel density estimation\nH0 &lt;- Hpi(D_SXY0[, c(\"X1\",\"X2\")])\nH1 &lt;- Hpi(D_SXY1[, c(\"X1\",\"X2\")])\n\n# Calculating multivariate densities in each group\nf0_2d &lt;- kde(D_SXY0[, c(\"X1\",\"X2\")], H = H0, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d &lt;- kde(D_SXY1[, c(\"X1\",\"X2\")], H = H1, xmin = c(-5, -5), xmax = c(5, 5))",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fast Transport on a Grid with Numerical Covariates</span>"
    ]
  },
  {
    "objectID": "transport-fast-grid.html#sec-regression-model",
    "href": "transport-fast-grid.html#sec-regression-model",
    "title": "3  Fast Transport on a Grid with Numerical Covariates",
    "section": "3.2 Hypothetical Model",
    "text": "3.2 Hypothetical Model\nAssume the scores obtained from a logistic regression write: \\[\nm(x_1,x_2,s)=\\big(1+\\exp\\big[-\\big((x_1+x_2)/2 + \\boldsymbol{1}(s=1)\\big)\\big]\\big)^{-1}.\n\\]\n\n#' Logistic regression\n#' \n#' @param x1 first numerical predictor\n#' @param x2 second numerical predictor\n#' @param s sensitive attribute (0/1)\nlogistique_reg &lt;- function(x1, x2, s) {\n  eta &lt;- (x1 + x2) / 2 - s\n  exp(eta) / (1 + exp(eta))\n}",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fast Transport on a Grid with Numerical Covariates</span>"
    ]
  },
  {
    "objectID": "transport-fast-grid.html#sec-regression-algo-example",
    "href": "transport-fast-grid.html#sec-regression-algo-example",
    "title": "3  Fast Transport on a Grid with Numerical Covariates",
    "section": "3.3 Illustrative example: small grid",
    "text": "3.3 Illustrative example: small grid\nWe have two features \\(x_1\\) and \\(x_2\\) (i.e., \\(\\boldsymbol{v} = \\{x_1, x_2\\}\\)) that need to be transported from group \\(s=0\\) to group \\(s=1\\). We will therefore use a grid in dimension 2 to apply (alg-3?). Recall that we assume that \\(x_1\\) depends on \\(s\\) only, and that \\(x_2\\) depends on both \\(x_1\\) and \\(s\\). Hence, to transport \\(x_2\\), we need to transport \\(x_1\\) before.\n\n3.3.1 Transport of \\(x_1\\)\nWe transport the first dimension. In the notations of (alg-3?), \\(j = x_1\\).\nFor now, we define \\(k=10\\) cells in each dimension (we will use 500 after), to obtain \\(\\boldsymbol{g}_{x_1|s}\\) To define the coordinates of the grid, we expand the domain of observed values in each value by a value \\(h\\) that we set to .2 here.\n\nn_grid_example &lt;- 10\nh &lt;- .2\n\nThe coordinates of the cells \\(\\boldsymbol{g}_{x_1|s=0}\\)\n\nvx1_example_0 &lt;- seq(\n  min(D_SXY_0$X1) - h, \n  max(D_SXY_0$X1) + h, \n  length = n_grid_example + 1\n)\nvx1_example_0 # coordinates for the cells in dimension 1 for group 0\n\n [1] -3.6638967 -3.1150270 -2.5661574 -2.0172878 -1.4684182 -0.9195485\n [7] -0.3706789  0.1781907  0.7270603  1.2759300  1.8247996\n\n\nThe coordinates of the cells \\(\\boldsymbol{g}_{x_1|s=1}\\)\n\nvx1_example_1 &lt;- seq(\n  min(D_SXY_1$X1) - h, \n  max(D_SXY_1$X1) + h, \n  length = n_grid_example + 1\n)\nvx1_example_1 # coordinates for the cells in dimension 1 for group 1\n\n [1] -0.9193084 -0.4398679  0.0395725  0.5190129  0.9984534  1.4778938\n [7]  1.9573343  2.4367747  2.9162151  3.3956556  3.8750960\n\n\nAnd we extract the middle of the cells:\n\nvx1_example_0_mid &lt;- \n  (vx1_example_0[2:(1 + n_grid_example)] + vx1_example_0[1:(n_grid_example)]) / 2\nvx1_example_1_mid &lt;- \n  (vx1_example_1[2:(1 + n_grid_example)] + vx1_example_1[1:(n_grid_example)]) / 2\n\nvx1_example_0_mid # middle cells in dimension 1 for group 0\n\n [1] -3.3894619 -2.8405922 -2.2917226 -1.7428530 -1.1939833 -0.6451137\n [7] -0.0962441  0.4526255  1.0014952  1.5503648\n\nvx1_example_1_mid # middle cells in dimension 1 for group 1\n\n [1] -0.6795882 -0.2001477  0.2792927  0.7587332  1.2381736  1.7176140\n [7]  2.1970545  2.6764949  3.1559354  3.6353758\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx1_example_0*0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 4), ylim = c(.5, 1.7)\n)\naxis(1)\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_0[i], .5, vx1_example_0[i+1], 1, border=\"grey\")\n}\npoints(D_SXY_0$X1, y = rep(.6, nrow(D_SXY_0)), col = alpha(colours[\"A\"], .3), pch = 19, cex = .2)\npoints(vx1_example_0_mid, y = rep(.75, n_grid_example), col = colours[\"A\"], pch = 4, cex = 1.5)\n\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_1[i], 1.1, vx1_example_1[i+1], 1.6, border=\"grey\")\n}\n\npoints(D_SXY_1$X1, y = rep(1.2, nrow(D_SXY_1)), col = alpha(colours[\"B\"], .3), pch = 19, cex = .2)\npoints(vx1_example_1_mid, y = rep(1.35, n_grid_example), col = colours[\"B\"], pch = 4, cex = 1.5)\n\n\n\n\n\nFigure 3.1: Example with a grid with 10 cells created in each group (0 in green and 1 in yellow). The observed values are represented by the dots. The crosses represent the millde of the cells.\n\n\n\n\n\n\n\n\nImagine that we want to transport the following individual:\n\nid_indiv &lt;- 2\nindiv &lt;- D_SXY_0[id_indiv, ]\nindiv\n\n  S      X1          X2 Y\n2 0 0.87045 0.008499458 1\n\n\nInstead of being in group \\(s=0\\), we would like it to be in group \\(s=1\\). Assume here that we want to transport its \\(x_1\\) characteristic.\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx1_example_0*0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 4), ylim = c(.5, 1.7)\n)\naxis(1)\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_0[i], .5, vx1_example_0[i+1], 1, border=\"grey\")\n}\npoints(D_SXY_0$X1, y = rep(.6, nrow(D_SXY_0)), col = alpha(colours[\"A\"], .3), pch = 19, cex = .2)\npoints(vx1_example_0_mid, y = rep(.75, n_grid_example), col = colours[\"A\"], pch = 4, cex = 1.5)\n\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_1[i], 1.1, vx1_example_1[i+1], 1.6, border=\"grey\")\n}\n\npoints(D_SXY_1$X1, y = rep(1.2, nrow(D_SXY_1)), col = alpha(colours[\"B\"], .3), pch = 19, cex = .2)\npoints(vx1_example_1_mid, y = rep(1.35, n_grid_example), col = colours[\"B\"], pch = 4, cex = 1.5)\n\npoints(D_SXY_0[id_indiv, \"X1\"], .6, col = \"red\", pch = 19, cex = 1.5)\n\n\n\n\n\nFigure 3.2: The individual from group \\(s=0\\) for which we want to get a counterfactual\n\n\n\n\n\n\n\n\nWe identify in which cell of the grid that individual belongs, indexed \\(i_0\\):\n\nx1 &lt;- D_SXY_0[id_indiv, \"X1\"]\n(i_0 &lt;- which.min(abs(vx1_example_0_mid - x1)))\n\n[1] 9\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx1_example_0*0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 4), ylim = c(.5, 1.7)\n)\naxis(1)\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_0[i], .5, vx1_example_0[i+1], 1, border=\"grey\")\n}\npoints(D_SXY_0$X1, y = rep(.6, nrow(D_SXY_0)), col = alpha(colours[\"A\"], .3), pch = 19, cex = .2)\npoints(vx1_example_0_mid, y = rep(.75, n_grid_example), col = colours[\"A\"], pch = 4, cex = 1.5)\n\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_1[i], 1.1, vx1_example_1[i+1], 1.6, border=\"grey\")\n}\n\npoints(D_SXY_1$X1, y = rep(1.2, nrow(D_SXY_1)), col = alpha(colours[\"B\"], .3), pch = 19, cex = .2)\npoints(vx1_example_1_mid, y = rep(1.35, n_grid_example), col = colours[\"B\"], pch = 4, cex = 1.5)\n\n# Individual of interest\npoints(D_SXY_0[id_indiv, \"X1\"], .6, col = \"red\", pch = 19, cex = 1.5)\n\n# Cell in which the individual belongs to\nrect(vx1_example_0[i_0], .5, vx1_example_0[i_0+1], 1, border=\"red\")\n\n\n\n\n\nFigure 3.3: The cell for the \\(x_1\\) dimension in which that individual belongs to\n\n\n\n\n\n\n\n\nWe need to find the corresponding cell in the grid of the other group, \\(\\boldsymbol{g}_{x_1|s=1}\\). The correspondence is based on quantiles. First, we compute the c.d.f. at each coordinate of the grid: \\(F_{x_1|s=0}\\).\n\nFdR1_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X1 &lt;= x))\nf1_0_example &lt;- FdR1_0(vx1_example_0)\nf1_0_example\n\n [1] 0.00 0.01 0.08 0.18 0.33 0.52 0.72 0.86 0.94 0.97 1.00\n\n\nThe c.d.f. in the identified cell, \\(F_{x_1|s=0}[i_0]\\), is:\n\n(p &lt;- f1_0_example[i_0])\n\n[1] 0.94\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx1_example_0*0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 4), ylim = c(.5, 1.7)\n)\naxis(1)\nfor(i in 1:n_grid_example) {\n  rect(\n    vx1_example_0[i], .5, vx1_example_0[i+1], 1, border=\"grey\",\n    # Add colours depending on c.d.f.\n    col = scales::alpha(colours[\"A\"], f1_0_example[i])\n  )\n}\npoints(D_SXY_0$X1, y = rep(.6, nrow(D_SXY_0)), col = alpha(colours[\"A\"], .3), pch = 19, cex = .2)\npoints(vx1_example_0_mid, y = rep(.75, n_grid_example), col = colours[\"A\"], pch = 4, cex = 1.5)\n\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_1[i], 1.1, vx1_example_1[i+1], 1.6, border=\"grey\")\n}\n\npoints(D_SXY_1$X1, y = rep(1.2, nrow(D_SXY_1)), col = alpha(colours[\"B\"], .3), pch = 19, cex = .2)\npoints(vx1_example_1_mid, y = rep(1.35, n_grid_example), col = colours[\"B\"], pch = 4, cex = 1.5)\n\n# Point of interest\nx1 &lt;- D_SXY_0[id_indiv, \"X1\"]\npoints(D_SXY_0[id_indiv, \"X1\"], .6, col = \"red\", pch = 19, cex = 1.5)\n\n# Cell in which the individual belongs to\nrect(vx1_example_0[i_0], .5, vx1_example_0[i_0+1], 1, border=\"red\")\n\n\n\n\n\nFigure 3.4: The colour of the cells depend on the cumulative distribution for the point in the middle of the grid\n\n\n\n\n\n\n\n\nWe need to find the quantile level \\(u\\) that is the closest to the probability computed previously (p). The quantile levels are the following:\n\n(u &lt;- (1:n_grid_example) / (n_grid_example + 1))\n\n [1] 0.09090909 0.18181818 0.27272727 0.36363636 0.45454545 0.54545455\n [7] 0.63636364 0.72727273 0.81818182 0.90909091\n\n\nAnd the closest quantile level is:\n\n(i_1 &lt;- which.min(abs(u - p)))\n\n[1] 10\n\n\nWe need to find the quantile for that level in the distribution of the other group. To that end, we compute the quantiles of \\(x_1\\) in group \\(s=1\\), i.e., \\(Q_{x_1|s=1}\\):\n\nQtl1_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X1, x))\n(q1_1_example &lt;- Qtl1_1(u))\n\n9.090909% 18.18182% 27.27273% 36.36364% 45.45455% 54.54545% 63.63636% 72.72727% \n0.6067436 0.8658632 1.1029531 1.1904745 1.4091226 1.6073207 1.8403510 2.2358935 \n81.81818% 90.90909% \n2.4727195 2.9386579 \n\n\nThe transported value for \\(x_1\\), \\(x_1^* = T_1^*(x_1)\\), is thus:\n\n(x1star &lt;- q1_1_example[i_1])\n\n90.90909% \n 2.938658 \n\n\nAnd that point belongs in the following cell \\(\\boldsymbol{g}_{x_1, k_1|s=0}\\):\n\n(k1 &lt;- which.min(abs(vx1_example_1_mid - x1star)))\n\n[1] 9\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx1_example_0*0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 4), ylim = c(.5, 1.7)\n)\naxis(1)\nfor(i in 1:n_grid_example) {\n  rect(\n    vx1_example_0[i], .5, vx1_example_0[i+1], 1, border=\"grey\",\n    col = scales::alpha(colours[\"A\"], f1_0_example[i])\n  )\n}\npoints(D_SXY_0$X1, y = rep(.6, nrow(D_SXY_0)), col = alpha(colours[\"A\"], .3), pch = 19, cex = .2)\npoints(vx1_example_0_mid, y = rep(.75, n_grid_example), col = colours[\"A\"], pch = 4, cex = 1.5)\n\nfor(i in 1:n_grid_example) {\n  rect(vx1_example_1[i], 1.1, vx1_example_1[i+1], 1.6, border=\"grey\",\n       col = scales::alpha(colours[\"B\"], u[i])\n  )\n}\n\npoints(D_SXY_1$X1, y = rep(1.2, nrow(D_SXY_1)), col = alpha(colours[\"B\"], .3), pch = 19, cex = .2)\npoints(vx1_example_1_mid, y = rep(1.35, n_grid_example), col = colours[\"B\"], pch = 4, cex = 1.5)\n\n# Individual of interest\nx1 &lt;- D_SXY_0[id_indiv, \"X1\"]\npoints(D_SXY_0[id_indiv, \"X1\"], .6, col = \"red\", pch = 19, cex = 1.5)\n\n# Cell in which the individual belongs to\nrect(vx1_example_0[i_0], .5, vx1_example_0[i_0+1], 1, border=\"red\")\n\n# Corresponding cell in other group, based on quantile\nrect(vx1_example_1[k1], 1.1, vx1_example_1[k1+1], 1.6, border=\"blue\")\n\npoints(x1star, y = 1.35, col = \"black\", pch = 19, cex = 1.5)\n\n\n\n\n\nFigure 3.5: The matched cell in the other group, and the transport of \\(x_1\\) from \\(s=0\\) to \\(s=1\\)\n\n\n\n\n\n\n\n\n\n\n3.3.2 Transport of \\(x_2\\)\nNow that we have transported \\(x_1\\) for our individual, we need to transport \\(x_2\\), to obtain \\(x_2^* = T_2^*(x_2 | x_1)\\).\nAs before, we define coordinates for a grid in the second dimension, beginning with \\(\\boldsymbol{g}_{x_2 | s = 0}\\)\n\nvx2_example_0 &lt;- seq(\n  min(D_SXY_0$X2) - h, \n  max(D_SXY_0$X2) + h, \n  length = n_grid_example + 1\n)\nvx2_example_0 # coordinates for the cells in dimension 2 for group 0\n\n [1] -3.8943774 -3.2944261 -2.6944748 -2.0945235 -1.4945722 -0.8946210\n [7] -0.2946697  0.3052816  0.9052329  1.5051842  2.1051355\n\n\nand then \\(\\boldsymbol{g}_{x_2 | s = 1}\\):\n\nvx2_example_1 &lt;- seq(\n  min(D_SXY_1$X2) - h, \n  max(D_SXY_1$X2) + h, \n  length = n_grid_example + 1\n)\nvx2_example_1 # coordinates for the cells in dimension 2 for group 1\n\n [1] -0.9319286 -0.3678532  0.1962223  0.7602977  1.3243731  1.8884485\n [7]  2.4525239  3.0165994  3.5806748  4.1447502  4.7088256\n\n\nThe grids can be drawn, and we can display the contour:\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx2_example_0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 5), ylim = c(-4, 5)\n)\naxis(1)\naxis(2)\n# Grid for Group 0\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_0[i], ybottom = vx2_example_0[j], \n      xright = vx1_example_0[i+1], ytop = vx2_example_0[j+1],\n      border = alpha(colours[\"A\"], .4)\n    )\n}\n# Observed values\npoints(D_SXY_0$X1, D_SXY_0$X2, col = alpha(colours[\"A\"], .4), pch = 19, cex = .1)\n# Estimated density\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  add = TRUE\n)\n# Grid for Group 1\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_1[i], ybottom = vx2_example_1[j], \n      xright = vx1_example_1[i+1], ytop = vx2_example_1[j+1],\n      border = alpha(colours[\"B\"], .4)\n    )\n}\npoints(D_SXY_1$X1, D_SXY_1$X2, col = alpha(colours[\"B\"], .4), pch = 19, cex = .1)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,col=scales::alpha(colours[\"B\"], 1),\n  add = TRUE\n)\n# Point of interest\npoints(indiv$X1, indiv$X2, col = \"red\", pch = 19)\n\n\n\n\n\nFigure 3.6: The individual of interest with its two coordinates, and the two estimated densities (one for \\(s=0\\) and one for \\(s=1\\))\n\n\n\n\n\n\n\n\nThe cell in the dimension \\(x_1\\) in which the point of interest belongs to has not changed:\n\n# identify closest cell in s=0 for x1 coordinate\n(k0 &lt;- which.min(abs(vx1_example_0_mid - x1)))\n\n[1] 9\n\n\nAnd we need to find the cell in the other dimension this point belongs to. Let us define the midpoints in the second dimension in group \\(s=1\\):\n\nvx2_example_1_mid &lt;- \n  (vx2_example_1[2:(1 + n_grid_example)] + vx2_example_1[1:(n_grid_example)]) / 2\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx2_example_0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 5), ylim = c(-4, 5)\n)\naxis(1)\naxis(2)\n# Grid for Group 0\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_0[i], ybottom = vx2_example_0[j], \n      xright = vx1_example_0[i+1], ytop = vx2_example_0[j+1],\n      border = alpha(colours[\"A\"], .4)\n    )\n}\n# Observed values\npoints(D_SXY_0$X1, D_SXY_0$X2, col = alpha(colours[\"A\"], .4), pch = 19, cex = .1)\n# Estimated density\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  add = TRUE\n)\n# Grid for Group 1\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_1[i], ybottom = vx2_example_1[j], \n      xright = vx1_example_1[i+1], ytop = vx2_example_1[j+1],\n      border = alpha(colours[\"B\"], .4)\n    )\n}\npoints(D_SXY_1$X1, D_SXY_1$X2, col = alpha(colours[\"B\"], .4), pch = 19, cex = .1)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,col=scales::alpha(colours[\"B\"], 1),\n  add = TRUE\n)\n# Point of interest\npoints(indiv$X1, indiv$X2, col = \"red\", pch = 19)\n# identified cells in the dimension x1, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[1], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[n_grid_example+1],\n  border=\"red\"\n)\n# corresponding cells in the same dimension, in group 1\nrect(\n  xleft = vx1_example_1[k0], ybottom = vx2_example_1[1], \n  xright = vx1_example_1[k0+1], ytop = vx2_example_1[n_grid_example+1],\n  border=\"blue\"\n)\n# midpoints of these cells\npoints(\n  rep(vx1_example_1_mid[k0],n_grid_example), vx2_example_1_mid, \n  col = colours[\"B\"], pch = 4\n)\n\n\n\n\n\nFigure 3.7: The transported point from \\(s=0\\) to \\(s=1\\) when sequentially transporting by \\(x_1\\) and then by \\(x_2 | x_1\\) will be in the blue rectangle\n\n\n\n\n\n\n\n\nThe coordinate \\(x_2\\) of the individuals is:\n\n(x2 &lt;- indiv$X2)\n\n[1] 0.008499458\n\n\nAnd the cell in which this point belongs to in the grid for that dimension (\\(\\boldsymbol{g}_{x_2|s=0}\\)) needs to be identified. To do so, we look at how close the point is from each middle point of the grid from the second coordinate in group \\(s=0\\):\n\nvx2_example_0_mid &lt;- \n  (vx2_example_0[2:(1 + n_grid_example)] + vx2_example_0[1:(n_grid_example)]) / 2\n# identify closest cell in s=0 for x2 coordinate\n(i_0 &lt;- which.min(abs(vx2_example_0_mid - x2)))\n\n[1] 7\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx2_example_0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 5), ylim = c(-4, 5)\n)\naxis(1)\naxis(2)\n# Grid for Group 0\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_0[i], ybottom = vx2_example_0[j], \n      xright = vx1_example_0[i+1], ytop = vx2_example_0[j+1],\n      border = alpha(colours[\"A\"], .4)\n    )\n}\n# Observed values\npoints(D_SXY_0$X1, D_SXY_0$X2, col = alpha(colours[\"A\"], .4), pch = 19, cex = .1)\n# Estimated density\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  add = TRUE\n)\n# Grid for Group 1\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_1[i], ybottom = vx2_example_1[j], \n      xright = vx1_example_1[i+1], ytop = vx2_example_1[j+1],\n      border = alpha(colours[\"B\"], .4)\n    )\n}\npoints(D_SXY_1$X1, D_SXY_1$X2, col = alpha(colours[\"B\"], .4), pch = 19, cex = .1)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,col=scales::alpha(colours[\"B\"], 1),\n  add = TRUE\n)\n# Point of interest\npoints(indiv$X1, indiv$X2, col = \"red\", pch = 19)\n# identified cells in the dimension x1, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[1], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[n_grid_example+1],\n  border=\"red\"\n)\n# Identified cell in the dimension x2, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[i_0], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[i_0+1],\n  border = \"red\", lwd = 2\n)\n# corresponding cells in the same dimension, in group 1\nrect(\n  xleft = vx1_example_1[k0], ybottom = vx2_example_1[1], \n  xright = vx1_example_1[k0+1], ytop = vx2_example_1[n_grid_example+1],\n  border=\"blue\"\n)\n# midpoints of these cells\npoints(\n  rep(vx1_example_1_mid[k0],n_grid_example), vx2_example_1_mid, \n  col = colours[\"B\"], pch = 4\n)\n\n\n\n\n\nFigure 3.8: The cell in which the inddividual belongs to in the second coordinate is identified\n\n\n\n\n\n\n\n\nTo transport \\(x_2\\) conditionally on \\(x_1\\), we need to compute the c.d.f. of \\(x_2\\) in group 0 conditional on \\(x_1\\), i.e., \\(F_{x_2|s=0}[\\cdot, \\boldsymbol{i}]\\) (where \\(\\boldsymbol{i}=\\{1, \\ldots, 10\\}\\) here, since \\(x_2\\) only has one parent among \\(\\boldsymbol{v}\\)). To do so, we use an iterative process: we loop over the grid in the dimension of \\(x_1\\) (the parent), and then, for each cell, we identify the points in the neighborhood with respect to their \\(x_1\\) coordinates, and then, we can compute the c.d.f. at each point of the grid in the second dimension.\nDuring the iteration process, we also compute the quantiles of \\(x_2\\) conditional on \\(x_1\\), but in the group \\(s=1\\), i.e., \\(Q_{x_2|s=1}[\\cdot,\\boldsymbol{i}]\\).\n\n# setting a neighborhood\nd &lt;- .5\nF2_0 &lt;- matrix(NA, n_grid_example, n_grid_example)\nQ2_1 &lt;- matrix(NA, n_grid_example, n_grid_example)\n\nfor (i in 1:n_grid_example) {\n  # Identify points in group 0 close to the coordinate x1 of the midpoint of\n  # the current cell\n  idx1_0 &lt;- which(abs(D_SXY_0$X1 - vx1_example_0_mid[i]) &lt; d)\n  # c.d.f.\n  FdR2_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X2[idx1_0] &lt;= x))\n  F2_0[,i] &lt;- FdR2_0(vx2_example_0_mid)\n  # Identify points in group 1 close to the coordinate x1 of the midpoint of\n  # the current cell\n  idx1_1 &lt;- which(abs(D_SXY_1$X1 - vx1_example_1_mid[i]) &lt; d)\n  Qtl2_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X2[idx1_1], x))\n  Q2_1[,i] = Qtl2_1(u)\n}\n\nLet us visualize the estimated c.d.f. in each cell of the complete grid in group 0:\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx2_example_0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 5), ylim = c(-4, 5)\n)\naxis(1)\naxis(2)\n# Grid for Group 0\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_0[i], ybottom = vx2_example_0[j], \n      xright = vx1_example_0[i+1], ytop = vx2_example_0[j+1],\n      border = alpha(colours[\"A\"], .4),\n      col = alpha(colours[\"A\"],  F2_0[i,j]/2)\n    )\n}\n# Observed values\npoints(D_SXY_0$X1, D_SXY_0$X2, col = alpha(colours[\"A\"], .4), pch = 19, cex = .1)\n# Estimated density\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  add = TRUE\n)\n# Grid for Group 1\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_1[i], ybottom = vx2_example_1[j], \n      xright = vx1_example_1[i+1], ytop = vx2_example_1[j+1],\n      border = alpha(colours[\"B\"], .4)\n    )\n}\npoints(D_SXY_1$X1, D_SXY_1$X2, col = alpha(colours[\"B\"], .4), pch = 19, cex = .1)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,col=scales::alpha(colours[\"B\"], 1),\n  add = TRUE\n)\n# Point of interest\npoints(indiv$X1, indiv$X2, col = \"red\", pch = 19)\n# identified cells in the dimension x1, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[1], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[n_grid_example+1],\n  border=\"red\"\n)\n# Identified cell in the dimension x2, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[i_0], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[i_0+1],\n  border = \"red\", lwd = 2\n)\n# corresponding cells in the same dimension, in group 1\nrect(\n  xleft = vx1_example_1[k0], ybottom = vx2_example_1[1], \n  xright = vx1_example_1[k0+1], ytop = vx2_example_1[n_grid_example+1],\n  border=\"blue\"\n)\n# midpoints of these cells\npoints(\n  rep(vx1_example_1_mid[k0],n_grid_example), vx2_example_1_mid, \n  col = colours[\"B\"], pch = 4\n)\n\n\n\n\n\nFigure 3.9: The conditional c.d.f of \\(x_2 | x_1\\) in group \\(s=0\\).\n\n\n\n\n\n\n\n\nAnd the estimated conditional quantiles of \\(x_2 | x_1\\) in the group \\(s=1\\), \\(Q_{x_2|s=1[\\cdot, \\boldsymbol{i}]}\\):\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx2_example_0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 5), ylim = c(-4, 5)\n)\naxis(1)\naxis(2)\n# Grid for Group 0\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_0[i], ybottom = vx2_example_0[j], \n      xright = vx1_example_0[i+1], ytop = vx2_example_0[j+1],\n      border = alpha(colours[\"A\"], .4),\n      col = alpha(colours[\"A\"],  F2_0[i,j]/3)\n    )\n}\n# Observed values\npoints(D_SXY_0$X1, D_SXY_0$X2, col = alpha(colours[\"A\"], .4), pch = 19, cex = .1)\n# Estimated density\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  add = TRUE\n)\n# Grid for Group 1\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_1[i], ybottom = vx2_example_1[j], \n      xright = vx1_example_1[i+1], ytop = vx2_example_1[j+1],\n      border = alpha(colours[\"B\"], .4),\n      col = alpha(colours[\"B\"],  Q2_1[i,j]/3)\n    )\n}\npoints(D_SXY_1$X1, D_SXY_1$X2, col = alpha(colours[\"B\"], .4), pch = 19, cex = .1)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,col=scales::alpha(colours[\"B\"], 1),\n  add = TRUE\n)\n# Point of interest\npoints(indiv$X1, indiv$X2, col = \"red\", pch = 19)\n# identified cells in the dimension x1, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[1], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[n_grid_example+1],\n  border=\"red\"\n)\n# Identified cell in the dimension x2, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[i_0], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[i_0+1],\n  border = \"red\", lwd = 2\n)\n# corresponding cells in the same dimension, in group 1\nrect(\n  xleft = vx1_example_1[k0], ybottom = vx2_example_1[1], \n  xright = vx1_example_1[k0+1], ytop = vx2_example_1[n_grid_example+1],\n  border=\"blue\"\n)\n\n\n\n\n\nFigure 3.10: The conditional quantiles of \\(x_2 | x_1\\) in group \\(s=1\\).\n\n\n\n\n\n\n\n\nLastly, we can identify the c.d.f. in the identified cell:\n\n# c.d.f. for the closest cell in s=0 for x2 coordinates\n(p &lt;- F2_0[i_0, k0])\n\n[1] 0.6\n\n\nThe corresponding quantile level:\n\n(i_1 &lt;- which.min(abs(u - p)))\n\n[1] 7\n\n\nAnd the quantile in group \\(s=1\\), which is therefore the transported value of \\(x_2 | x_1\\), \\(T_2^*(x_2 | x_1)\\):\n\n(x2star &lt;-  Q2_1[i_1, k1])\n\n[1] 1.025227\n\n\nThe corresponding cell in group \\(s=1\\) for dimension \\(x_2\\):\n\n(k2 &lt;- which.min(abs(vx2_example_1 - x2star)))\n\n[1] 4\n\n\n\nindiv # factual\n\n  S      X1          X2 Y\n2 0 0.87045 0.008499458 1\n\ntibble(S = 1, X1 = x1star, X2 = x2star) # counterfactual\n\n# A tibble: 1 × 3\n      S    X1    X2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1  2.94  1.03\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\nplot(\n  vx1_example_0, vx2_example_0, \n  xlab = \"\", ylab = \"\", axes = FALSE, col = NA, \n  xlim = c(-4, 5), ylim = c(-4, 5)\n)\naxis(1)\naxis(2)\n# Grid for Group 0\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_0[i], ybottom = vx2_example_0[j], \n      xright = vx1_example_0[i+1], ytop = vx2_example_0[j+1],\n      border = alpha(colours[\"A\"], .4),\n      col = alpha(colours[\"A\"],  F2_0[i,j]/3)\n    )\n}\n# Observed values\npoints(D_SXY_0$X1, D_SXY_0$X2, col = alpha(colours[\"A\"], .4), pch = 19, cex = .1)\n# Estimated density\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  add = TRUE\n)\n# Grid for Group 1\nfor (i in 1:n_grid_example) {\n  for (j in 1:n_grid_example)\n    rect(\n      xleft = vx1_example_1[i], ybottom = vx2_example_1[j], \n      xright = vx1_example_1[i+1], ytop = vx2_example_1[j+1],\n      border = alpha(colours[\"B\"], .4),\n      col = alpha(colours[\"B\"],  Q2_1[i,j]/3)\n    )\n}\npoints(D_SXY_1$X1, D_SXY_1$X2, col = alpha(colours[\"B\"], .4), pch = 19, cex = .1)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,col=scales::alpha(colours[\"B\"], 1),\n  add = TRUE\n)\n# Point of interest\npoints(indiv$X1, indiv$X2, col = \"red\", pch = 19)\n# identified cells in the dimension x1, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[1], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[n_grid_example+1],\n  border=\"red\"\n)\n# Identified cell in the dimension x2, in group 0\nrect(\n  xleft = vx1_example_0[k0], ybottom = vx2_example_0[i_0], \n  xright = vx1_example_0[k0+1], ytop = vx2_example_0[i_0+1],\n  border = \"red\", lwd = 2\n)\n# corresponding cells in the same dimension, in group 1\nrect(\n  xleft = vx1_example_1[k0], ybottom = vx2_example_1[1], \n  xright = vx1_example_1[k0+1], ytop = vx2_example_1[n_grid_example+1],\n  border=\"blue\"\n)\nrect(\n  xleft = vx1_example_1[k0], ybottom = vx2_example_1[k2], \n  xright = vx1_example_1[k0+1], ytop = vx2_example_1[k2+1],\n  border = \"blue\", lwd = 2\n)\npoints(x1star, x2star, col = \"black\", pch = 19)\n\n\n\n\nTransported value of (\\(s=0, x_1, x_2\\)) in group 0 to (\\(s=1, x_1^* = T_1*(x_1), x_2^* = T_2^*(x_2 | x_1)\\))",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fast Transport on a Grid with Numerical Covariates</span>"
    ]
  },
  {
    "objectID": "transport-fast-grid.html#larger-grid",
    "href": "transport-fast-grid.html#larger-grid",
    "title": "3  Fast Transport on a Grid with Numerical Covariates",
    "section": "3.4 Larger grid",
    "text": "3.4 Larger grid\nLet us now consider a much larger grid of \\(500\\times 500\\) instead of \\(10\\times 10\\).\n\nn_grid &lt;- 500\nh &lt;- .2\n\nWe can then compute the coordinates of each cell in each dimension, \\(g_{j|s}\\) for all variable \\(j \\in \\{x_1,x2\\}\\). As the bounds of the feature space might differ between each group (0 and 1), we make different grids for each group.\n\n# Group 0\n## First dimension (x1)\nvx1_0 &lt;- seq(\n  min(D_SXY_0$X1) - h, \n  max(D_SXY_0$X1) + h, \n  length = n_grid + 1\n)\n## Second dimension (x2)\nvx2_0 &lt;- seq(\n  min(D_SXY_0$X2) - h, \n  max(D_SXY_0$X2) + h, \n  length = n_grid + 1\n)\n# Group 1\n## First dimension (x1)\nvx1_1 &lt;- seq(\n  min(D_SXY_1$X1) - h, \n  max(D_SXY_1$X1) + h, \n  length = n_grid + 1\n)\n## Second dimension (x2)\nvx2_1 &lt;- seq(\n  min(D_SXY_1$X2) - h, \n  max(D_SXY_1$X2) + h, \n  length = n_grid + 1\n)\n\nLet us get the middle of each cell:\n\n# Group 1\nvx1_0_mid &lt;- (vx1_0[2:(1 + n_grid)] + vx1_0[1:(n_grid)]) / 2\nvx1_1_mid &lt;- (vx1_1[2:(1 + n_grid)] + vx1_1[1:(n_grid)]) / 2\n# Group 2\nvx2_0_mid &lt;- (vx2_0[2:(1 + n_grid)] + vx2_0[1:(n_grid)]) / 2\nvx2_1_mid &lt;- (vx2_1[2:(1 + n_grid)] + vx2_1[1:(n_grid)]) / 2\n\nWe compute the c.d.f. \\(F_{j|s}\\) and quantile functions \\(Q_{j|s}\\):\n\nF1_0 &lt;- F2_0 &lt;- F1_1 &lt;- F2_1 &lt;- matrix(NA, n_grid, n_grid)\nQ1_0 &lt;- Q2_0 &lt;- Q1_1 &lt;- Q2_1 &lt;- matrix(NA, n_grid, n_grid)\n\nu &lt;- (1:n_grid) / (n_grid + 1)\n\nFdR1_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X1 &lt;= x))\nf1_0 &lt;- FdR1_0(vx1_0_mid)\nFdR2_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X2 &lt;= x))\nf2_0 &lt;- FdR2_0(vx2_0_mid)\nFdR1_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X1 &lt;= x))\nf1_1 &lt;- FdR1_1(vx1_1_mid)\nFdR2_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X2&lt;=x))\nf2_1 &lt;- FdR2_1(vx2_1_mid)\n\nQtl1_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X1, x))\nq1_0 &lt;- Qtl1_0(u)\nQtl2_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X2, x))\nq2_0 &lt;- Qtl1_0(u)\nQtl1_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X1, x))\nq1_1 &lt;- Qtl1_1(u)\nQtl2_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X2, x))\nq2_1 &lt;- Qtl2_1(u)\n\nThen we loop on the cells of the grid of \\(x_1\\) to compute the conditional c.d.f. in group 0 and 1, and the quantiles in group 0 and 1.\n\nfor (i in 1:n_grid) {\n  idx1_0 &lt;- which(abs(D_SXY_0$X1 - vx1_0_mid[i]) &lt; d)\n  FdR2_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X2[idx1_0] &lt;= x))\n  F2_0[, i] &lt;- FdR2_0(vx2_0_mid)\n  Qtl2_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X2[idx1_0], x))\n  Q2_0[, i] &lt;- Qtl2_0(u)\n  idx2_0 &lt;- which(abs(D_SXY_0$X2 - vx2_0_mid[i]) &lt; d)\n  FdR1_0 &lt;- Vectorize(function(x) mean(D_SXY_0$X1[idx2_0] &lt;= x))\n  F1_0[, i] &lt;- FdR1_0(vx1_0_mid)\n  Qtl1_0 &lt;- Vectorize(function(x) quantile(D_SXY_0$X1[idx2_0], x))\n  Q1_0[, i] &lt;- Qtl1_0(u)\n  idx1_1 &lt;- which(abs(D_SXY_1$X1 - vx1_1_mid[i]) &lt; d)\n  FdR2_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X2[idx1_1] &lt;= x))\n  F2_1[, i] &lt;- FdR2_1(vx2_1_mid)\n  Qtl2_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X2[idx1_1], x))\n  Q2_1[, i] &lt;- Qtl2_1(u)\n  idx2_1 &lt;- which(abs(D_SXY_1$X2 - vx2_1_mid[i]) &lt; d)\n  FdR1_1 &lt;- Vectorize(function(x) mean(D_SXY_1$X1[idx2_1] &lt;= x))\n  F1_1[, i] &lt;- FdR1_1(vx1_1_mid)\n  Qtl1_1 &lt;- Vectorize(function(x) quantile(D_SXY_1$X1[idx2_1], x))\n  Q1_1[, i] &lt;- Qtl1_1(u) \n}\n\nLet us make predictions with the model presented in Section 4.6.3 on a grid:\n\nvx0 &lt;- seq(-5, 5, length = 251)\ndata_grid &lt;- expand.grid(x = vx0, y = vx0)\nL0 &lt;- logistique_reg(x1 = data_grid$x, x2 = data_grid$y, s = 0)\nL1 &lt;- logistique_reg(x1 = data_grid$x, x2 = data_grid$y, s = 1)\n\n# as a grid:\ndlogistique0 &lt;- matrix(L0, length(vx0), length(vx0))\ndlogistique1 &lt;- matrix(L1, length(vx0), length(vx0))\n\n\n3.4.1 Functions for Sequential Transport\nLet us define a function to perform the transport of \\(x_0\\) from \\(s=0\\) to \\(s_1\\), i.e., \\(T_1^*(x_1)\\)\n\n#' Transport of x1 from s=0 to s=1\n#' \n#' @param x2 vector of x2's values\n#' @descriptions\n#'  - vx1_0_mid: coordinates of center of cells (axis x1, s=0)\n#'  - f1_0: c.d.f. values for x1 in group s=0\n#'  - u: quantile levels\n#'  - q1_1: quantile values for x1 in group s=1\ntransport_x1 &lt;- function(x1) {\n  # identify closest cell of the grid to the coordinates of x1 in group s=0\n  i &lt;- which.min(abs(vx1_0_mid - x1))\n  # c.d.f. for that cell, in group s=0\n  p &lt;- f1_0[i]\n  # identify closest quantile level\n  i &lt;- which.min(abs(u - p))\n  # corresponding quantile in group s=1\n  x1star &lt;- q1_1[i]\n  x1star\n}\n\nAnother function to transport \\(x_2\\) from \\(s=0\\) to \\(s=1\\), i.e., \\(T_2^*(x_2)\\):\n\n#' Transport of x2 from s=0 to s=1\n#' \n#' @param x2 vector of x2's values\n#' @descriptions\n#'  - vx2_0_mid: coordinates of center of cells (axis x2, s=0)\n#'  - f2_0: c.d.f. values for x2 in group s=0\n#'  - u: quantile levels\n#'  - q2_1: quantile values of x2 in group s=1\ntransport_x2 &lt;- function(x2) {\n  # identify closest cell of the grid to the coordinates of x2 in group s=0\n  i &lt;- which.min(abs(vx2_0_mid - x2))\n  # c.d.f. for that cell, in group s=0\n  p &lt;- f2_0[i]\n  # identify closest quantile level\n  i &lt;- which.min(abs(u - p))\n  # corresponding quantile in group s=1\n  x2star &lt;- q2_1[i]\n  x2star\n}\n\nA function to transport \\(x_1\\) conditionally on \\(x_2\\), i.e., \\(T_1^*(x_1 | x_2)\\):\n\n#' Transport for x1 conditional on x2, from s=0 to s=1\n#' \n#' @param x1 numerical vector with x1's values\n#' @param x2 numerical vector with x2's values\n#' @description\n#'  - vx2_0_mid: coordinates of center of cells (axis x2, s=0)\n#'  - vx2_1_mid: coordinates of center of cells (axis x2, s=1)\n#'  - vx1_0_mid: coordinates of center of cells (axis x1, s=0)\ntransport_x1_cond_x2 &lt;- function(x1, x2) {\n  # identify closest cell in s=0 for x2 coordinate\n  k0 &lt;- which.min(abs(vx2_0_mid - x2))\n  # identify closest cell in s=1 for transported x2 coordinate\n  k1 &lt;- which.min(abs(vx2_1_mid - transport_x2(x2)))\n  # identify closest cell in s=0 for x1 coordinate\n  i_0 &lt;- which.min(abs(vx1_0_mid - x1))\n  # c.d.f. for the closest cell in s=0 for x1 coordinates\n  p &lt;- F1_0[i_0, k0]\n  # identify closest quantile level\n  i_1 &lt;- which.min(abs(u - p))\n  # corresponding quantile in group s=1\n  x1star &lt;- Q1_1[i_1, k1]\n  x1star\n}\n\nAnd a last function to transport \\(x_2\\) conditionally on \\(x_1\\), i.e., \\(T_2^*(x_2 |x_1)\\):\n\n#' Transport for x2 conditional on x1, from s=0 to s=1\n#' \n#' @param x2 numerical vector with x2's values\n#' @param x1 numerical vector with x1's values\n#' @description\n#'  - vx1_0_mid: coordinates of center of cells (axis x1, s=0)\n#'  - vx1_1_mid: coordinates of center of cells (axis x1, s=1)\n#'  - vx2_0_mid: coordinates of center of cells (axis x2, s=0)\ntransport_x2_cond_x1 &lt;-  function(x2, x1){\n  # identify closest cell in s=0 for x1 coordinate\n  k0 &lt;- which.min(abs(vx1_0_mid - x1))\n  # identify closest cell in s=1 for transported x1 coordinate\n  k1 &lt;- which.min(abs(vx1_1_mid - transport_x1(x1)))\n  # identify closest cell in s=0 for x2 coordinate\n  i_0 &lt;- which.min(abs(vx2_0_mid - x2))\n  # c.d.f. for the closest cell in s=0 for x2 coordinates\n  p &lt;- F2_0[i_0, k0]\n  # identify closest quantile level\n  i_1 &lt;- which.min(abs(u - p))\n  # corresponding quantile in group s=1\n  x2star &lt;-  Q2_1[i_1, k1]\n  x2star\n}\n\n\n\nCodes used to create the Figure.\npar(mar = c(2,2,0,0))\n# Group 0\n## Estimated density: level curves for (x1, x2) -&gt; m(0, x1, x2)\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,col=scales::alpha(colours[\"A\"], 1),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Contour of estimates by the model\ncontour(\n  vx0,\n  vx0,\n  dlogistique0,\n  levels = (1:9) / 10,\n  col = scl, lwd = 1.6,\n  add = TRUE\n)\naxis(1)\naxis(2)\n\n\n\n\n\nFigure 3.11: Level curves for \\((x_1, x_2) \\rightarrow m(0, x_1, x_2)\\) In the background, estimated density of \\((s=0, x_1, x_2)\\) (level curves).\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\n# Group 1\n## Estimated density: level curves for (x1, x2) -&gt; m(1, x1, x2)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,\n  col = scales::alpha(colours[\"B\"], 1),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Contour of estimates by the model\ncontour(\n  vx0,\n  vx0,\n  dlogistique1, \n  col = scl,\n  add = TRUE,\n  levels = (1:9) / 10,\n  lwd = 1.6\n)\naxis(1)\naxis(2)\n\n\n\n\n\nFigure 3.12: Level curves for \\((x_1, x_2) \\rightarrow m(1, x_1, x_2)\\) In the background, estimated density of \\((s=1, x_1, x_2)\\) (level curves).\n\n\n\n\n\n\n\n\nLet us focus on individual \\((s, -2, 1)\\).\n\nxystart &lt;- c(-2,-1)\n\nLet us make multiple predictions for that individual, given the assumed structural model.\n\n\n\n\n\nFigure 3.13: Causal network with two legitimate mitigating variables \\(x_1\\) and \\(x_2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.14: Causal network with two legitimate mitigating variables \\(x_1\\) and \\(x_2\\).\n\n\n\n\n\n\n\n\n\nx2_then_x1: \\(T_1^*(x1 | x2), T_2^*(x2)\\), the transported value when assuming the structural model shown in Figure 3.14\nx1_then_x2: \\(T_1^*(x1), T_2^*(x2|x_1)\\), the transported value when assuming the structural model shown in Figure 3.13\nx1_intermediaire: \\((T_1^*(x1), x2)\\), the transported value for \\(x_1\\) only\nx2_intermediaire: \\((x1, T_2^*(x2))\\), the transported value for \\(x_2\\) only.\n\n\ncoords &lt;- data.frame(\n  # 1. (x1, x2)\n  start = xystart,\n  # 2. (T_1(x1 | x2), T_2(x2))\n  x2_then_x1 = c(\n    transport_x1_cond_x2(x1 = xystart[1], x2 = xystart[2]),\n    transport_x2(xystart[2])\n  ),\n  # 3. (T_1(x1), T_2(x2 | x1))\n  x1_then_x2 = c(\n    transport_x1(xystart[1]), \n    transport_x2_cond_x1(x2 = xystart[1], x1 = xystart[2])\n  ),\n  # 4. (T_1(x1), x2)\n  x1_intermediaire = c(transport_x1(x1 = xystart[1]), xystart[2]),\n  # 5. (x1, T_2(x2))\n  x2_intermediaire = c(xystart[1], transport_x2(xystart[2]))\n)\n\nThen, we make predictions for all these points using the model.\n\nlibrary(plotrix)\nv &lt;- c(\n  # 1. Prediction at initial values (S=0, x1, x2)\n  logistique_reg(x1 = coords$start[1], x2 = coords$start[2], s = 0),\n  # 2. Prediction if (S=1, x1, x2)\n  logistique_reg(coords$start[1], coords$start[2], 1),\n  # 3. Prediction if (S = 1, T_1(x1), T_2(x2 | x1))\n  logistique_reg(coords$x1_then_x2[1], coords$x1_then_x2[2], 1),\n  # 4. Prediction if (S = 1, T_1(x1 | x2), T_2(x2))\n  logistique_reg(coords$x2_then_x1[1], coords$x2_then_x1[2], 1),\n  # 5. Prediction if (S = 1, T_1(x1), x2)\n  logistique_reg(coords$x1_intermediaire[1], coords$x1_intermediaire[2], 1),\n  # 6. Prediction if (S = 1, x1, T_2(x2))\n  logistique_reg(coords$x2_intermediaire[1], coords$x2_intermediaire[2], 1)\n)\nv\n\n[1] 0.18242552 0.07585818 0.40945028 0.54065719 0.25576437 0.23658466\n\n\nLet us first explore the mutatis mutandis difference \\(m(s=1, x_1^*, x_2^*) - m(s = 0, x1, x_2)\\). If we assume the causal structure as in Figure 3.13, it is equal to:\n\nv[3] - v[1]\n\n[1] 0.2270248\n\n\nThis can be decomposed as follows:\n\nthe change du to the impact of \\(s\\) only, \\(m(s=1,x_1,x_2) - m(s=0,x_1,x_2)\\) (i.e., the ceteris paribus impact):\n\n\nv[2] - v[1]\n\n[1] -0.1065673\n\n\n\nthe change due to the impact of \\(s\\) on \\(x_1\\), i.e., \\(m(s=1,x^\\star_1,x_2) - m(s=1,x_1,x_2)\\):\n\n\nv[5] - v[2]\n\n[1] 0.1799062\n\n\n\nthe change due to the impact of both \\(s\\) and \\(x_1\\) on \\(x_2\\), i.e., \\(m(s=1,x^\\star_1,x^\\star_2) - m(s=1,x^\\star_1,x_2)\\):\n\n\nv[3] - v[5]\n\n[1] 0.1536859\n\n\nIf, instead, we assume the causal structure as in Figure 3.14, the mutatis mutandis effect, \\(m(s=1, x_1^*, x_2^*) - m(s = 0, x1, x_2)\\), would be:\n\nv[4] - v[1]\n\n[1] 0.3582317\n\n\nThis can be decomposed as follows:\n\nthe change du to the impact of \\(s\\) only, \\(m(s=1,x_1,x_2) - m(s=0,x_1,x_2)\\) (i.e., the ceteris paribus impact):\n\n\nv[2] - v[1]\n\n[1] -0.1065673\n\n\n\nthe change due to the impact of \\(s\\) on \\(x_2\\), i.e., \\(m(s=1,x_1,x_2^*) - m(s=1,x_1,x_2)\\):\n\n\nv[6] - v[2]\n\n[1] 0.1607265\n\n\n\nthe change due to the impact of both \\(s\\) and \\(x_2\\) on \\(x_1\\), i.e., \\(m(s=1,x^\\star_1,x^\\star_2) - m(s=1,x_1,x_2^*)\\):\n\n\nv[4] - v[6]\n\n[1] 0.3040725\n\n\nLet us visualize this! We begin with the predicted value by the model.\n\npar(mar = c(2, 2, 0, 0))\n# Group 0\n## Estimated density: level curves for (x1, x2) -&gt; m(0, x1, x2)\nCeX &lt;- 1\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,\n  col = scales::alpha(colours[\"A\"], .3),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Group 1\n## Estimated density: level curves for (x1, x2) -&gt; m(1, x1, x2)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,\n  col = scales::alpha(colours[\"B\"], .3), add = TRUE\n)\ncontour(\n  vx0, vx0, dlogistique0,\n  levels = (1:9)/10,\n  col = scl,\n  add = TRUE,lwd = 2\n)\naxis(1)\naxis(2)\n\n###\n# Individual (S=0, x1=-2, x2=-1)\n###\npoints(coords$start[1], coords$start[2], pch = 19, cex = CeX)\n## Predicted value for the individual, based on factuals\ntext(\n  coords$start[1], coords$start[2],\n  paste(round(v[1] * 100, 1), \"%\", sep = \"\"), \n  pos = 1, cex = CeX, col = \"darkblue\"\n)\n\n\n\n\nFigure 3.15: The predicted value by the model, \\(m(s=0, x_1, x_2)\\)\n\n\n\n\n\n\n\n\nAnd then we can show the the predictions made on the counterfactuals depending on the causal assumption.\n\npar(mar = c(2, 2, 0, 0))\n# Group 0\n## Estimated density: level curves for (x1, x2) -&gt; m(0, x1, x2)\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,\n  col = scales::alpha(colours[\"A\"], .3),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Group 1\n## Estimated density: level curves for (x1, x2) -&gt; m(1, x1, x2)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,\n  col = scales::alpha(colours[\"B\"], .3), add = TRUE\n)\n\n# Contour of estimates by the model for s=1\ncontour(\n  vx0, vx0, dlogistique1,\n  levels = (1:9) / 10,\n  col = scl, lwd=2,\n  add = TRUE\n)\naxis(1)\naxis(2)\n\n###\n# Individual (s=0, x1=-2, x2=-1)\n###\npoints(coords$start[1], coords$start[2], pch = 19, cex = CeX)\n## Predicted value for the individual, based on factuals\ntext(\n  coords$start[1] - .3, coords$start[2] - .42 - .3,\n  paste(round(v[1] * 100, 1), \"%\", sep = \"\"), \n  pos = 1, cex = CeX, col = \"darkblue\"\n)\n\n###\n# Transported individual when transporting x1 and then x2, i.e.,\n# (do(s=1), T_1^*(x1), T_2^*(x_2 | x_1))\n###\npoints(coords$x1_then_x2[1],coords$x1_then_x2[2], pch = 19, cex = CeX)\nsegments(\n  x0 = coords$start[1], y0 = coords$start[2], \n  x1 = coords$x1_then_x2[1], y1 = coords$start[2], \n  lwd = .8\n)\nsegments(\n  x0 = coords$x1_then_x2[1], y0 = coords$x1_then_x2[2],\n  x1 = coords$x1_then_x2[1], y1 = coords$start[2], \n  lwd = .8\n)\n## Intermediate point\npoints(coords$x1_then_x2[1], coords$start[2], pch = 19, col = \"white\", cex = CeX)\npoints(coords$x1_then_x2[1], coords$start[2], pch = 1, cex = CeX)\ntext(\n  coords$x1_then_x2[1], coords$start[2] - .42,\n  paste(round(v[5] * 100, 1), \"%\", sep = \"\"), pos = 4, cex = CeX\n)\n# New predicted value for # (do(s=1), T_1^*(x1), T_2^*(x_2 | x_1))\ntext(\n  coords$x1_then_x2[1], coords$x1_then_x2[2],\n  paste(round(v[3]*100,1),\"%\",sep=\"\"), pos = 3, cex = CeX\n)\n\n###\n# Transported individual when transporting x2 and then x1, i.e.,\n# (do(s=1), T_1^*(x1 | x2), T_2^*(x_2))\n###\npoints(coords$x2_then_x1[1],coords$x2_then_x1[2],pch=19,cex=CeX)\nsegments(\n  x0 = coords$start[1], y0 = coords$start[2],\n  x1 = coords$start[1], y1 = coords$x2_then_x1[2],\n  lwd = .8\n)\nsegments(\n  x0 = coords$x2_then_x1[1], y0 = coords$x2_then_x1[2],\n  x1 = coords$start[1], y1 = coords$x2_then_x1[2],\n  lwd = .8\n)\n## Intermediate point\npoints(coords$start[1], coords$x2_then_x1[2], pch = 19, col = \"white\", cex = CeX)\npoints(coords$start[1], coords$x2_then_x1[2], pch = 1, cex = CeX)\ntext(\n  coords$start[1], coords$x2_then_x1[2],\n     paste(round(v[6] * 100, 1), \"%\", sep = \"\"), pos = 2, cex = CeX\n)\n## New predicted value for (do(s=1), T_1^*(x1 | x2), T_2^*(x_2))\ntext(\n  coords$x2_then_x1[1], coords$x2_then_x1[2],\n  paste(round(v[4] * 100, 1), \"%\", sep = \"\"), pos = 3, cex = CeX\n)\n\n\n###\n# New predicted value for (do(s=1), x1, x2), no transport\n###\nry &lt;- .2\ndraw.circle(\n  x = coords$start[1] - ry, y = coords$start[2] - ry, \n  radius = ry * sqrt(2)\n)\ntext(\n  coords$start[1], coords$start[2] + .42,\n  paste(round(v[2] * 100, 1), \"%\", sep = \"\"), pos = 4, cex = CeX\n)\n\n\n\n\nFigure 3.16: Two counterfactuals, based on either the causal assumption from Figure 3.13 (bottom right path) or on the causal assumption from Figure 3.14 (top left path)",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fast Transport on a Grid with Numerical Covariates</span>"
    ]
  },
  {
    "objectID": "algorithm-3.html",
    "href": "algorithm-3.html",
    "title": "4  Faster Algorithm",
    "section": "",
    "text": "4.1 Data Generation\nConsider a causal structural model with a sensitive attribute \\(s\\) with no parents, two legitimate features \\(x_1\\) and \\(x_2\\), and an outcome \\(y\\).\nLet us draw 100 observation per group. For group 0, we draw values from a multivariate Gaussian distribution with mean -1 and the following variance-covariance matrix: \\(\\Sigma_0 = \\begin{bmatrix}1.2^2 & \\frac{1.2^2}{2}\\\\ \\frac{1.2^2}{2} & 1.2^2\\end{bmatrix}\\). For group 1, we draw values from a multivariate Gaussian distribution with mean 1.5 and with the following variance-covariance matrix: \\(\\Sigma_0 = \\begin{bmatrix}.9^2 & -\\frac{4\\times .9^2}{10}\\\\ -\\frac{4 \\times .9^2}{2} & .9^2\\end{bmatrix}\\).\n# Number of observations per group\nset.seed(123) # set the seed for reproductible results\nn0 &lt;- 200\n\n# First bivariate Gaussian distribution: group s=0\nM0 &lt;- c(-1, -1)\nS0 &lt;- matrix(c(1, .5, .5,1) * 1.2^2, 2, 2)\nX0 &lt;- mnormt::rmnorm(n0, M0, S0)\nD_SXY_0 &lt;- data.frame(\n  S = 0,\n  X1 = X0[, 1],\n  X2 = X0[, 2]\n)\n\n# Second bivariate Gaussian distribution: group s=1\nn1 &lt;- 400\nM1 &lt;- c(1.5, 1.5)\nS1 &lt;- matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\nX1 &lt;- mnormt::rmnorm(n1, M1, S1)\nD_SXY_1 &lt;- data.frame(\n  S = 1,\n  X1 = X1[,1],\n  X2 = X1[,2]\n)\nAssume the response variable, \\(Y\\), to be a binary variable that depends on the covariates of each group. More specifically, assume that it is drawn from a Bernoulli distribution with probability of occurrence being linked through a logistic function to \\(x_1\\) and \\(x_2\\), i.e., \\(Y \\sim \\mathcal{B}(p(S))\\), where \\(p(S)\\) differs among groups: \\[\np(S) = \\begin{cases}\n\\frac{\\exp{(\\eta_0})}{1+\\exp{(\\eta_0)}}, & \\text{if } S = 0,\\\\\n\\frac{\\exp{(\\eta_1})}{1+\\exp{(\\eta_1)}}, & \\text{if } S = 1,\n\\end{cases}\n\\] where \\[\n\\begin{cases}\n\\eta_0 = \\frac{1.2 x_1 + 1.6x2}{2}\\\\\n\\eta_1 = \\frac{.8 x_1 + 2.4x2}{2}.\n\\end{cases}\n\\]\n# Drawing random binary response variable Y with logistic model for each group\neta_0 &lt;- (D_SXY_0$X1 * 1.2 + D_SXY_0$X2 / 2 * .8) / 2\neta_1 &lt;- (D_SXY_1$X1 * .8 + D_SXY_1$X2 / 2 * 1.2) / 2\np_0 &lt;- exp(eta_0) / (1 + exp(eta_0))\np_1 &lt;- exp(eta_1) / (1 + exp(eta_1))\nD_SXY_0$Y &lt;- rbinom(n0, size = 1, prob = p_0)\nD_SXY_1$Y &lt;- rbinom(n1, size = 1, prob = p_1)\nWe merge the two datasets in a single one\nD_SXY &lt;- rbind(D_SXY_0, D_SXY_1)\nAnd we create two datasets that contain individuals from group 0 only, and individuals from group 1 only:\n# Dataset with individuals in group 0 only\nD_SXY0 &lt;- D_SXY[D_SXY$S == 0, ]\n# Dataset with individuals in group 1 only\nD_SXY1 &lt;- D_SXY[D_SXY$S == 1,]\nFor illustration, we would like to display the contour of the density in each group on the graphs. To do so, we rely on a kernel density estimation:\n# Computation of smoothing parameters (bandwidth) for kernel density estimation\nH0 &lt;- Hpi(D_SXY0[, c(\"X1\",\"X2\")])\nH1 &lt;- Hpi(D_SXY1[, c(\"X1\",\"X2\")])\n\n# Calculating multivariate densities in each group\nf0_2d &lt;- kde(D_SXY0[, c(\"X1\",\"X2\")], H = H0, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d &lt;- kde(D_SXY1[, c(\"X1\",\"X2\")], H = H1, xmin = c(-5, -5), xmax = c(5, 5))",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Faster Algorithm</span>"
    ]
  },
  {
    "objectID": "algorithm-3.html#optimal-transport",
    "href": "algorithm-3.html#optimal-transport",
    "title": "4  Faster Algorithm",
    "section": "4.2 Optimal Transport",
    "text": "4.2 Optimal Transport\nFirst, for comparison purposes, since \\(X_1\\) and \\(X_2\\) are drawn from a multivariate Gaussian distribution, we can compute the transported values using the closed form formula.\n\nAA &lt;- sqrtm(S0) %*% S1 %*% (sqrtm(S0))\nAA &lt;- solve(sqrtm(S0)) %*% sqrtm(AA) %*% solve((sqrtm(S0)))\nOT &lt;- function(x) as.vector(M1 + AA %*% (x - M0))\ntransport_ot &lt;- t(apply(D_SXY_0[, c(\"X1\", \"X2\")], 1, OT))\nhead(transport_ot)\n\n          [,1]      [,2]\n[1,] 1.1430798 1.2649116\n[2,] 2.7236725 1.6419332\n[3,] 0.9081769 3.0476527\n[4,] 2.3834575 0.3864673\n[5,] 1.1289562 1.0649093\n[6,] 2.3374791 1.8850306",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Faster Algorithm</span>"
    ]
  },
  {
    "objectID": "algorithm-3.html#sequential-transport-step-by-step-example",
    "href": "algorithm-3.html#sequential-transport-step-by-step-example",
    "title": "4  Faster Algorithm",
    "section": "4.3 Sequential Transport: Step by Step Example",
    "text": "4.3 Sequential Transport: Step by Step Example\n\n4.3.1 Topological Ordering\nWe first need to assume a causal structure. We define the adjacency matrix of the graph.\n\nvariables &lt;- c(\"S\", \"X1\", \"X2\", \"Y\")\n\nadj &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1,# S\n    0, 0, 1, 1,# X1\n    0, 0, 0, 1,# X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\nThe causal graph can be plotted:\n\ncausal_graph &lt;- fairadapt::graphModel(adj)\nplot(causal_graph)\n\n\n\n\nFigure 4.1: Assumed Causal Graph\n\n\n\n\n\n\n\n\nLet us set the sensitive name s and its value in the source distribution S_0. We also set the outcome name, y.\n\ndata &lt;- D_SXY\ns &lt;-  \"S\"\nS_0 &lt;-  0\ny &lt;- \"Y\"\n\nThanks to the topologicalOrdering() function from {fairadapt}, we can get a topological ordering from the adjacency matrix. We redefine this function here.\n\n#' Topological Ordering\n#'\n#' @source This function comes from the fairadapt package. Drago Plecko,\n#'         Nicolai Meinshausen (2020). Fair data adaptation with quantile\n#'         preservation Journal of Machine Learning Research, 21.242, 1-44.\n#'         URL https://www.jmlr.org/papers/v21/19-966.html.\n#' @param adj_mat Adjacency matrix with names of the variables for both rows and\n#'        columns.\n#' @return A character vector (names of the variables) providing a topological\n#'         ordering.\n#' @export\ntopological_ordering &lt;- function(adj_mat) {\n  nrw &lt;- nrow(adj_mat)\n  num_walks &lt;- adj_mat\n  for (i in seq_len(nrw + 1L)) {\n    num_walks &lt;- adj_mat + num_walks %*% adj_mat\n  }\n  comparison_matrix &lt;- num_walks &gt; 0\n  top_order &lt;- colnames(adj_mat)\n  for (i in seq_len(nrw - 1L)) {\n    for (j in seq.int(i + 1L, nrw)) {\n      if (comparison_matrix[top_order[j], top_order[i]]) {\n        top_order &lt;- swap(top_order, i, j)\n      }\n    }\n  }\n  top_order\n}\n\n#' Swap Two Elements in a Matrix.\n#'\n#' @source This function comes from the fairadapt package. Drago Plecko,\n#'         Nicolai Meinshausen (2020). Fair data adaptation with quantile\n#'         preservation Journal of Machine Learning Research, 21.242, 1-44.\n#'         URL https://www.jmlr.org/papers/v21/19-966.html.\n#' @param x A matrix.\n#' @param i Index of the first element to swap.\n#' @param j Index of the second element to swap.\n#' @return The matrix x where the i-th and j-th elements have been swapped.\n#' @noRd\nswap &lt;- function(x, i, j) {\n  keep &lt;- x[i]\n  x[i] &lt;- x[j]\n  x[j] &lt;- keep\n  x\n}\n\n\ntop_order &lt;- topological_ordering(adj)\ntop_order\n\n[1] \"S\"  \"X1\" \"X2\" \"Y\" \n\n\n\n\n4.3.2 Transport of the First Variable\nLet us extract the names of the variables that will be transported:\n\nvariables &lt;- top_order[!top_order %in% c(s, y)]\nvariables\n\n[1] \"X1\" \"X2\"\n\n\nWe will therefore begin with transporting the first variable from this ordering, X1.\n\nx_name &lt;- \"X1\"\n\nWe will need to know whether this variable is numerical or not. Depending on this, we need to apply a different methodology to transport an observation \\(x_1\\) from group \\(S=0\\) to \\(S=1\\):\n\nIf \\(X_1\\) is a numerical variable, we will first compute the empirical quantile of that observation in group \\(S=0\\), i.e., \\(F_{X_1|S=0}(x_1)\\). Then, in the other group, \\(S=1\\), we will compute the sample quantile corresponding to a probability of \\(F_{X_1|S=0}(x)\\), i.e., \\(x_1^* = T(x_1) = Q_{X_1 | S=1}\\left( F_{X_1|S=0}(x_1) \\right)\\).\nIf \\(X_1\\) is a categorical variable, we will simply draw a class from the empirical distribution of \\(X_1 | S=1\\) and consider it to be the counterfactual value of \\(x_1\\).\n\nThe individuals to transport are those from group \\(S=0\\):\n\n# Observations in group S_0\nindividuals &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n\nThe value of the variable that will be transported;\n\nindiv_x &lt;- individuals |&gt; pull(!!x_name)\nhead(indiv_x)\n\n[1] -1.6725708  0.8704500 -0.8448547 -0.4469006 -1.8242234  0.4688982\n\n\nWe check whether it is numerical:\n\nis_x_num &lt;- is.numeric(indiv_x)\nis_x_num\n\n[1] TRUE\n\n\nSince the variable is numerical, we compute the empirical cumulative distribution function in group \\(S=0\\)\n\n# Data in group S=0\ndata_0 &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n# Observation of the variable to transport in that group\nx_S0 &lt;- data_0 |&gt; pull(!!x_name)\n# Empirical cumulative distribution function\nF_X_S0 &lt;- ecdf(x_S0)\n\nThen, we can use this ecdf to compute the empirical quantile of all observations from group \\(S=0\\):\n\nf &lt;- F_X_S0(indiv_x)\nhead(f)\n\n[1] 0.260 0.930 0.560 0.685 0.215 0.890\n\n\nThe transported value for each observation is simply the empirical quantile corresponding to a probability f in group \\(S=1\\):\n\n# Data in group S=1\ndata_1 &lt;- data |&gt; filter(!!sym(s) != !!S_0)\n# Values of the variable of interest in group S=1\nx_S1 &lt;- data_1 |&gt; pull(!!x_name)\ntransported &lt;- as.numeric(quantile(x_S1, probs = f))\nhead(transported)\n\n[1] 0.9432205 2.9180187 1.7502764 1.9797669 0.8352953 2.6139733\n\n\nHad the variable \\(X_1\\) been qualitative, we would have had drawn a class from the values of \\(X_1\\) in group \\(S=1\\).\n\n# Do not run\ntransported &lt;- sample(x_S1, size = length(x_S0), replace = TRUE)\n\nWe store these values in a list for later use:\n\nlist_transported &lt;- list()\nlist_transported[[x_name]] &lt;- transported\n\n\n\n4.3.3 Transport of the Second Variable\nNow that we have transported \\(X_1\\), we need to transport \\(X_2\\) which also depends on \\(S\\), but also on \\(S_1\\). Again, we will need to consider two cases, depending on the type of \\(X_2\\).\nLet us redefine the name of the variable of interest:\n\nx_name &lt;- \"X2\"\n\nWe get the names of the parents:\n\nparents &lt;- colnames(adj)[adj[, x_name] == 1]\nparents\n\n[1] \"S\"  \"X1\"\n\n\nThe values of the current variable in group group:\n\nx_S0 &lt;- data_0 |&gt; pull(!!x_name)\nx_S1 &lt;- data_1 |&gt; pull(!!x_name)\n\nWe check its type:\n\nis_x_num &lt;- is.numeric(x_S0)\nis_x_num\n\n[1] TRUE\n\n\nThe characteristics of the parent variables:\n\nparents_characteristics &lt;- data_0 |&gt; select(!!parents, -!!s)\nhead(parents_characteristics)\n\n          X1\n1 -1.6725708\n2  0.8704500\n3 -0.8448547\n4 -0.4469006\n5 -1.8242234\n6  0.4688982\n\n\nWe isolate the characteristics of the parents in each group:\n\ndata_0_parents &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\ndata_1_parents &lt;- data_1 |&gt; select(!!parents) |&gt; select(-!!s)\n\nThen, for each observation in group \\(S=0\\), we compute its distance to all other observations withing the same group. We use the Gower’s distance which allows to handle mixed variables. The distance \\(D(i,j)\\) between two observations \\(i\\) and \\(j\\) each represented by a vector of \\(p\\) characteristics (\\(p\\) features) is computed as: \\[D(i,j) = \\frac{\\sum_{k=1}^{p}\\omega_k d_k(i,j)}{\\sum_{k=1}^{p} \\omega_k},\\] where \\(\\omega_k\\) are possible weights attributed to variable \\(k\\) and \\(d_k(i,j)\\) is the distance between the \\(k\\)-th characteristic, which depends on its type. If the \\(k\\)-th characteristic is numerical: \\(d_k(i,j) = \\frac{|x_{ik} - x_{jk}|}{R_k}\\), where \\(R_k = \\max(x_k) - \\min(x_k)\\). If the \\(k\\)-th characteristic is categorical, the distance is simply equal to 1 if the two observations \\(i\\) and \\(j\\) share the same characteristic, and 0 otherwise: \\(d_k(i,j) = \\begin{cases}1, x_{ik} = x_{jk}\\\\ 0, x_{ik} \\ne x_{jk}\\end{cases}\\).\nThe distances will be used as weights to compute the CDF.\nLet us compute these distances for each observation from group \\(S=0\\):\n\nweights_S0 &lt;- as.matrix(daisy(data_0_parents, metric = \"gower\"))\nweights_S0 &lt;- weights_S0\ndim(weights_S0)\n\n[1] 200 200\n\n\nThe row \\(i\\) of weights_S0 contains the distance of observation \\(i\\) to all other observations from \\(S=0\\) using the characteristics of the parents. For each observation, let us also compute the sum of these distances.\n\ntot_weights_S0 &lt;- apply(weights_S0, MARGIN = 1, sum)\nlength(tot_weights_S0)\n\n[1] 200\n\n\nNow, let us prepare a table with the values of the characteristics of the parents where variables that were influenced by \\(S\\) have previously been transported. In this example, \\(X_1\\) is a parent of \\(X_2\\) and has been transported in the first step.\n\ndata_0_parents_t &lt;- data_0_parents #init\nfor (parent in parents) {\n  # does the parent depend on the sensitive variable\n  if (parent %in% names(list_transported)) {\n    data_0_parents_t &lt;-\n      data_0_parents_t |&gt;\n      mutate(!!sym(parent) := list_transported[[parent]])\n  }\n}\nhead(data_0_parents_t)\n\n         X1\n1 0.9432205\n2 2.9180187\n3 1.7502764\n4 1.9797669\n5 0.8352953\n6 2.6139733\n\n\nNow, we can compute the distance between the parents from group \\(S=0\\) (where some parent characteristics may have been transported previously) to each observation in group \\(S=1\\). Note that here, the daisy() function from {cluster} does not allow to compute the distances of each observation from one matrix to each observation of another matrix; we need to stack the two matrices and compute the distance from each observation to all the others. This is absolutely not optimal, since we will compute a lots of unrequired distances.\n\ncombined &lt;- rbind(data_0_parents_t, data_1_parents)\ngower_dist &lt;- daisy(combined, metric = \"gower\")\ngower_matrix &lt;- as.matrix(gower_dist)\ngower_matrix &lt;- 1 - gower_matrix\ndim(gower_matrix)\n\n[1] 600 600\n\n\nWe only need to extract the distances of all observation from group \\(S=0\\) to observations in group \\(S=1\\).\n\nn_0 &lt;- nrow(data_0_parents_t)\nn_1 &lt;- nrow(data_1_parents)\nweights_S1 &lt;- gower_matrix[1:n_0, (n_0 + 1):(n_0 + n_1), drop = FALSE]\nweights_S1 &lt;- weights_S1 + 1e-8\nweights_S1 &lt;- 1 / (weights_S1)^2\ndim(weights_S1)\n\n[1] 200 400\n\n\nThe \\(i\\)-th row of weights_S1 gives the distances of the \\(i\\)-th (transported) observation from group \\(S=0\\) to all the observations in group \\(S=1\\). Let us also compute the sum of distances for each of these observations.\n\ntot_weights_S1 &lt;- apply(weights_S1, MARGIN = 1, sum)\nlength(tot_weights_S1)\n\n[1] 200\n\n\nThen, to transport \\(X_2\\), we need to adopt a different strategy depending on its type (numeric or factor).\n\n4.3.3.1 Case of a Numeric Variable\nIf the variable we need to transport is numerical, we can compute the empirical distribution function. For each observation in \\(S=0\\), we compute :\n\\[F_{X_2 | X_1^*, S=0}(x) = \\frac{\\sum_{i=1}^{n_0} D(x, x_{2,i}) \\times \\mathrm{I}(x_{2,i} \\leq x)}{\\sum_{i=1}^{n_0} D(x, x_{2,i})}.\\]\n\n# Empirical distribution function\nf &lt;- rep(NA, length(x_S0))\nfor (i in 1:length(x_S0)) {\n  f[i] &lt;- weights_S0[i, ] %*% (x_S0 &lt;= x_S0[i]) / tot_weights_S0[i]\n}\n# To avoid making the `weighted.quantile()` function to crash:\nf[f==1] &lt;- 1-(1e-8)\n\nThen, we can compute the weighted quantiles in group \\(S=1\\) at the obtained probabilities. We only keep the closest observations: here we keep only the 5th closest points and set the weight of other points to 0.\n\nnum_neighbors &lt;- 5\ntransported &lt;- rep(NA, length(x_S0))\nfor (i in 1:length(x_S0)) {\n  wts &lt;- weights_S1[i, ]\n  wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n  transported[i] &lt;- Hmisc::wtd.quantile(\n    x = x_S1, weights = wts, probs = f[i]\n  )\n}\n\nWarning in Hmisc::wtd.quantile(x = x_S1, weights = wts, probs = f[i]): probable\ncomplete loss of accuracy in modulus\n\nlength(transported)\n\n[1] 200\n\n\n\n\n4.3.3.2 Case of a Factor Variable\nIf the variable to transport is a factor variable, we first fit a multinomial model to predict the class of that variable in group \\(S=1\\).\n\n# Not run here\nfit_indix_x &lt;- nnet::multinom(\n  class ~ .,\n  data = data_1_parents |&gt; mutate(class = x_S1)\n)\n\nThen, we use that model to predict the values using the parents characteristics from group \\(S=0\\), where the previously transported characteristics were transported:\n\n# Not run here\npred_probs &lt;- predict(fit_indix_x, type = \"probs\", newdata = data_0_parents_t)\n\nFor each prediction, we obtain a vector with estimated probabilities to belong in each category of the factor variable. We draw a class randomly using these probabilities as weights.\n\n# Not run here\ndrawn_class &lt;- apply(\n  pred_probs, 1, function(x) sample(1:ncol(pred_probs), prob = x, size = 1)\n)\n\nThen, we just format the obtained class.\n\n# Not run here\ntransported &lt;- colnames(pred_probs)[drawn_class]\nif (is.factor(x_S1)) {\n  transported &lt;- factor(transported, levels = levels(x_S1))\n}\n\nThe transported value can be stored.\n\n# Not run here\nlist_transported[[x_name]] &lt;- transported\n\n\n\n\n4.3.4 Transport of the Subsequent Variables\nIf there are more variables in the graph, we can continue using the same procedure as in the transport of the second variable.",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Faster Algorithm</span>"
    ]
  },
  {
    "objectID": "algorithm-3.html#wrapping-up-the-sequential-transport-function",
    "href": "algorithm-3.html#wrapping-up-the-sequential-transport-function",
    "title": "4  Faster Algorithm",
    "section": "4.4 Wrapping up: The Sequential Transport Function",
    "text": "4.4 Wrapping up: The Sequential Transport Function\nLet us wrap up the previous steps in a function.\n\n\nR codes for the seq_trans() function.\n#' Sequential Transport Using a Pre-Defined Causal Graph\n#'\n#' The sensitive attribute, S, is assumed to be a binary variable with value\n#' $S_0$ in the source distribution and $S_1$ in the target distribution.\n#'\n#' @param data Data frame with the observations.\n#' @param adj Adjacency matrix for the causal graph.\n#' @param s Name of the sensitive attribute column in the data.\n#' @param S_0 Label of the sensitive attribute in the source distribution.\n#' @param y Name of the outcome variable in the data.\n#' @param num_neighbors Number of neighbors to use in the weighted quantile\n#'        estimation. Default to 5.\n#' @param silent If `TRUE`, the messages showing progress in the estimation are\n#'        not shown. Default to `silent=FALSE`.\n#'\n#' @returns A list with the following elements:\n#' * `transported`: A named list with the transported values. The names are those of the variables.\n#' * `weights`: A list with the weights of each observation in the two groups.\n#' * `ecdf`: A list with empirical distribution functions for numerical variables.\n#' * `ecdf_values`: A list with the values of the ecdf evaluated for each observation in the source distribution.\n#' * `fit_for_categ`: A list with the estimated multinomial models to predict categories using parents characteristics\n#' * `params`: A list with some parameters used to transport observations:\n#'     * `adj`: Adjacency matrix.\n#'     * `top_order`: Topological ordering.\n#'     * `s`: Name of the sensitive attribute.\n#'     * `S_0`: Label of the sensitive attribute in the source distribution.\n#'     * `y`: Name of the outcome variable in the data.\n#'     * `num_neighbors`: Number of neighbors used when computing quantiles.\n#' @md\n#' @export\n#'\n#' @importFrom stats predict ecdf quantile\n#' @importFrom dplyr across filter mutate pull select\n#' @importFrom tidyselect where\n#' @importFrom rlang sym !! := is_character\n#' @importFrom cluster daisy\n#' @importFrom Hmisc wtd.quantile\n#' @importFrom nnet multinom\nseq_trans &lt;- function(data,\n                      adj,\n                      s,\n                      S_0,\n                      y,\n                      num_neighbors = 5,\n                      silent = FALSE) {\n  # Make sure character variables are encoded as factors\n  data &lt;-\n    data |&gt;\n    mutate(across(where(is_character), ~as.factor(.x)))\n\n  # Topological ordering\n  top_order &lt;- topological_ordering(adj)\n  variables &lt;- top_order[!top_order %in% c(s, y)]\n  # Observations in group S_0\n  data_0 &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n  data_1 &lt;- data |&gt; filter(!!sym(s) != !!S_0)\n\n  # Lists where results will be stored\n  list_transported &lt;- list()  # Transported values\n  list_weights &lt;- list()      # Weights\n  list_ecdf &lt;- list()         # Empirical dist. function\n  list_ecdf_values &lt;- list()  # Evaluated values of the ecdf\n  fit_for_categ &lt;- list()     # Fitted multinomial models for categ. variables\n\n  for (x_name in variables) {\n    if (silent == FALSE) cat(\"Transporting \", x_name, \"\\n\")\n    # Names of the parent variables\n    parents &lt;- colnames(adj)[adj[, x_name] == 1]\n    # values of current x in each group\n    x_S0 &lt;- data_0 |&gt; pull(!!x_name)\n    x_S1 &lt;- data_1 |&gt; pull(!!x_name)\n    # Check whether X is numeric\n    is_x_num &lt;- is.numeric(x_S0)\n    # Characteristics of the parent variables (if any)\n    parents_characteristics &lt;- data_0 |&gt; select(!!parents, -!!s)\n\n    if (length(parents_characteristics) &gt; 0) {\n      data_0_parents &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\n      data_1_parents &lt;- data_1 |&gt; select(!!parents) |&gt; select(-!!s)\n      # Weights in S_0\n      weights_S0 &lt;- as.matrix(daisy(data_0_parents, metric = \"gower\"))\n      tot_weights_S0 &lt;- apply(weights_S0, MARGIN = 1, sum)\n      # Weights in S_1\n      # First, we need to get the transported values for the parents, if necessary\n      data_0_parents_t &lt;- data_0_parents #init\n      for (parent in parents) {\n        # does the parent depend on the sensitive variable\n        if (parent %in% names(list_transported)) {\n          data_0_parents_t &lt;-\n            data_0_parents_t |&gt;\n            mutate(!!sym(parent) := list_transported[[parent]])\n        }\n      }\n      # Unfortunately, we will compute a lot of distances not needed\n      combined &lt;- rbind(data_0_parents_t, data_1_parents)\n      gower_dist &lt;- daisy(combined, metric = \"gower\")\n      gower_matrix &lt;- as.matrix(gower_dist)\n      n_0 &lt;- nrow(data_0_parents_t)\n      n_1 &lt;- nrow(data_1_parents)\n      weights_S1 &lt;- gower_matrix[1:n_0, (n_0 + 1):(n_0 + n_1), drop = FALSE]\n      weights_S1 &lt;- weights_S1 + 1e-8\n      weights_S1 &lt;- 1 / (weights_S1)^2\n      tot_weights_S1 &lt;- apply(weights_S1, MARGIN = 1, sum)\n\n      if (is_x_num == TRUE) {\n        # Numerical variable to transport\n\n        # Empirical distribution function\n        f &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          f[i] &lt;- weights_S0[i, ] %*% (x_S0 &lt;= x_S0[i]) / tot_weights_S0[i]\n        }\n        list_ecdf_values[[x_name]] &lt;- f\n        f[f==1] &lt;- 1-(1e-8)\n\n        # Transported values\n        transported &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          wts &lt;- weights_S1[i, ]\n          wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n          transported[i] &lt;- Hmisc::wtd.quantile(\n            x = x_S1, weights = weights_S1[i, ], probs = f[i]\n          )\n        }\n      } else {\n        # X is non numeric and has parents\n\n        # Fit a model to predict the categorical variables given the\n        # characteristics of the parents in group to transport into\n        fit_indix_x &lt;- nnet::multinom(\n          x_S0 ~ .,\n          data = data_1_parents |&gt; mutate(x_S0 = x_S1)\n        )\n        # Predictions with that model for transported parents\n        pred_probs &lt;- predict(fit_indix_x, type = \"probs\", newdata = data_0_parents_t)\n        # For each observation, random draw of the class, using the pred probs\n        # as weights\n        drawn_class &lt;- apply(\n          pred_probs, 1,\n          function(x) sample(1:ncol(pred_probs), prob = x, size = 1)\n        )\n        transported &lt;- colnames(pred_probs)[drawn_class]\n        if (is.factor(x_S1)) {\n          transported &lt;- factor(transported, levels = levels(x_S1))\n        }\n        fit_for_categ[[x_name]] &lt;- fit_indix_x\n      }\n      list_transported[[x_name]] &lt;- transported\n\n      # Store weights for possible later use\n      list_weights[[x_name]] &lt;- list(\n        w_S0 = list(weights = weights_S0, tot_weights = tot_weights_S0),\n        w_S1 = list(weights = weights_S1, tot_weights = tot_weights_S1)\n      )\n    } else {\n      # No parents\n      if (is_x_num == TRUE) {\n        # X is numerical and has no parents\n        F_X_S0 &lt;- ecdf(x_S0)\n        list_ecdf[[x_name]] &lt;- F_X_S0\n        f &lt;- F_X_S0(x_S0)\n        list_ecdf_values[[x_name]] &lt;- f\n        transported &lt;- as.numeric(quantile(x_S1, probs = f))\n      } else {\n        # X is not numerical and has no parents\n        transported &lt;- sample(x_S1, size = length(x_S0), replace = TRUE)\n        if (is.factor(x_S1)) {\n          transported &lt;- factor(transported, levels = levels(x_S1))\n        } else {\n          transported &lt;- as.factor(transported)\n        }\n      }\n      list_transported[[x_name]] &lt;- transported\n    }\n  }\n\n  return(\n    list(\n      transported = list_transported,\n      weights = list_weights,\n      ecdf = list_ecdf,\n      ecdf_values = list_ecdf_values,\n      fit_for_categ = fit_for_categ,\n      params = list(\n        adj = adj,\n        top_order = top_order,\n        s = s,\n        S_0 = S_0,\n        y = y,\n        num_neighbors = num_neighbors\n      )\n    )\n  )\n}\n\n\nWe can then call this function to transport our data in a single call of that function.\n\ntransported &lt;- seq_trans(data = D_SXY, adj = adj, s = \"S\", S_0 = 0, y = \"Y\")\n\nTransporting  X1 \nTransporting  X2 \n\n\nWarning in Hmisc::wtd.quantile(x = x_S1, weights = weights_S1[i, ], probs =\nf[i]): probable complete loss of accuracy in modulus\n\n\nWarning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):\ncollapsing to unique 'x' values",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Faster Algorithm</span>"
    ]
  },
  {
    "objectID": "algorithm-3.html#comparison-sequential-transport-and-multivariate-optimal-transport",
    "href": "algorithm-3.html#comparison-sequential-transport-and-multivariate-optimal-transport",
    "title": "4  Faster Algorithm",
    "section": "4.5 Comparison: Sequential Transport and Multivariate Optimal Transport",
    "text": "4.5 Comparison: Sequential Transport and Multivariate Optimal Transport\nLet us compare the transported values obtained with this algorithm to those obtained with optimal transport.\n\ntb_results &lt;-\n  as_tibble(transport_ot) |&gt; set_names(\"X1\", \"X2\") |&gt;\n  mutate(id = row_number(), type = \"OT\") |&gt;\n  bind_rows(\n    tibble(\n      X1 = transported$transported$X1,\n      X2 = transported$transported$X2,\n      X3 = transported$transported$X3,\n      type = \"seq_t\"\n    ) |&gt;\n      mutate(id = row_number())\n  )\n\ntb_results_col &lt;- \n  tb_results |&gt; \n  pivot_wider(names_from = type, values_from = c(\"X1\", \"X2\"))\n\nIn Figure 4.2, we plot observations from the initial group in green Then we add the transported values with sequential transport assuming that \\(x_2\\) is influenced by \\(x_2\\), in black. Lastly, we plot the transported values using optimal multivariate transport and represent them in red.\n\n\nCode\nplot(\n  D_SXY_0$X1, D_SXY_0$X2, \n  col = \"#0B775E\", pch = 19, cex = .5,\n  xlim = range(c(tb_results$X1, D_SXY_0$X1)),\n  ylim = range(c(tb_results$X2, D_SXY_0$X2), na.rm=TRUE),\n  xlab = \"X1\", ylab = \"X2\"\n)\nlines(\n  tb_results_col$X1_OT, \n  tb_results_col$X2_OT, \n  type = \"p\", pch = 19, cex = .5, col = \"#C93312\"\n)\npoints(\n  tb_results_col$X1_seq_t, tb_results_col$X2_seq_t, \n  pch = 19, cex = .5, col = \"black\"\n)\nsegments(\n  x0 = D_SXY_0$X1,\n  y0 = D_SXY_0$X2,\n  x1 = tb_results_col$X1_OT,\n  y1 = tb_results_col$X2_OT, col = alpha(\"#C93312\", .2))\nsegments(\n  x0 = D_SXY_0$X1,\n  y0 = D_SXY_0$X2,\n  x1 = tb_results_col$X1_seq_t,\n  y1 = tb_results_col$X2_seq_t, col = alpha(\"black\", .2))\nsegments(\n  x0 = tb_results_col$X1_OT,\n  y0 = tb_results_col$X2_OT,\n  x1 = tb_results_col$X1_seq_t,\n  y1 = tb_results_col$X2_seq_t, col = alpha(\"gray\", .3))\nlegend(\n  \"topleft\", legend = c(\"Obs\", \"OT\", \"Seq. T.\"),\n  pch = 19,\n  col = c(\"#0B775E\", \"#C93312\", \"black\"), bty=\"n\"\n)\n\n\n\n\n\nFigure 4.2: Optimal transport and sequential transport with algorithm 3\n\n\n\n\n\n\n\n\nWe can visualize the distance of each transported individual depending on the method used to create them.\n\n\nCode\nplot(\n  tb_results_col$X1_OT, tb_results_col$X2_OT, \n  col = \"#C93312\", pch = 19, cex = .5,\n  xlim = range(c(tb_results$X1, D_SXY_0$X1)),\n  ylim = range(c(tb_results$X2, D_SXY_0$X2), na.rm=TRUE),\n  xlab = \"X1\", ylab = \"X2\"\n)\npoints(\n  tb_results_col$X1_seq_t, tb_results_col$X2_seq_t, \n  pch = 19, cex = .5, col = \"black\"\n)\nsegments(\n  x0 = tb_results_col$X1_OT,\n  y0 = tb_results_col$X2_OT,\n  x1 = tb_results_col$X1_seq_t,\n  y1 = tb_results_col$X2_seq_t, col = alpha(\"black\", .3)\n)\nlegend(\n  \"topleft\", legend = c(\"OT\", \"Seq. T.\"),\n  pch = 19,\n  col = c(\"#C93312\", \"black\"), bty=\"n\")\n\n\n\n\n\nFigure 4.3: Comparison of Optimal transport and sequential transport\n\n\n\n\n\n\n\n\nLet us compare the bivariate estimated densities.\n\n\nCode\n# Computation of smoothing parameters (bandwidth) for kernel density estimation\nH0 &lt;- Hpi(D_SXY0[, c(\"X1\", \"X2\")])\nH1 &lt;- Hpi(D_SXY1[, c(\"X1\", \"X2\")])\n\nH1_OT &lt;- Hpi(transport_ot)\n\ntransport_seq &lt;- tibble(\n  X1 = transported$transported$X1,\n  X2 = transported$transported$X2\n)\nH1_SEQ &lt;- Hpi(transport_seq)\n\n# Calculating multivariate densities in each group S=0 and S=1\nf0_2d &lt;- kde(D_SXY0[, c(\"X1\", \"X2\")], H = H0, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d &lt;- kde(D_SXY1[, c(\"X1\", \"X2\")], H = H1, xmin = c(-5, -5), xmax = c(5, 5))\n\nf1_2d_OT &lt;- kde(transport_ot, H = H1_OT, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d_SEQ &lt;- kde(transport_seq, H = H1_SEQ, xmin = c(-5, -5), xmax = c(5, 5))\n\n# Plotting densities\npar(mar = c(2,2,0,0))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\"\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\n\n# Group S=1, Optimal transport\ncontour(\n  f1_2d_OT$eval.point[[1]], f1_2d_OT$eval.point[[2]], f1_2d_OT$estimate, \n  col = \"#C93312\", add = TRUE\n)\n\n# Group S=1, Sequential transport\ncontour(\n  f1_2d_SEQ$eval.point[[1]], f1_2d_SEQ$eval.point[[2]], f1_2d_SEQ$estimate, \n  col = \"black\", add = TRUE\n)\nlegend(\n  \"topleft\", legend = c(\"Obs S=0\", \"Obs S=1\", \"OT\", \"Seq. T.\"),\n  lty=1,\n  col = c(colours[\"A\"], colours[\"B\"], \"#C93312\", \"black\"), bty=\"n\"\n)\n\n\n\n\n\nFigure 4.4: Estimated densities in both groups, and in the target group using counterfactuals obtained with either optimal transport or sequential transport (moving first \\(x_1\\), then \\(x_2\\)).",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Faster Algorithm</span>"
    ]
  },
  {
    "objectID": "algorithm-3.html#transport-of-a-new-individual",
    "href": "algorithm-3.html#transport-of-a-new-individual",
    "title": "4  Faster Algorithm",
    "section": "4.6 Transport of a New Individual",
    "text": "4.6 Transport of a New Individual\nTo transport a new individual, to avoid estimating again all the empirical cumulative distribution functions, we adopt a simple strategy. To move the \\(j\\)-th coordinate of an individual from the source group to the target group, we use the estimated value of the ecdf of the individual in the initial dataset (only in the source group) which is the closest (with respect to the Euclidean distance). If the \\(j\\)-th characteristic is categorical, we draw the class to create the “transported” value, as in the previous function.\nWe define a new function to do so.\n\n\nR code for the seq_trans_new() function.\n#' Sequential Transport of New Observations Using a Pre-Defined Causal Graph\n#'\n#' This function transports new observations from the source group to the target\n#' group, using the mappings previously learned when evaluating the\n#' `seq_transport_binary()` function.\n#'\n#' @param x Object containing previously transported values, obtained with\n#'        `seq_transport_binary()`.\n#' @param newdata New data with observations from initial group to transport.\n#' @param data Data used during the construction of counterfactuals with\n#'        `seq_transport_binary()`.\n#' @export\n#' @returns A list with the transported values. Each element contains the\n#'          transported values of a variable.\n#'\n#' @importFrom stats predict quantile\n#' @importFrom dplyr across filter mutate pull select\n#' @importFrom purrr map_dbl\n#' @importFrom rlang sym !! :=\n#' @importFrom cluster daisy\n#' @importFrom Hmisc wtd.quantile\n#' @importFrom nnet multinom\nseq_trans_new &lt;- function(x,\n                          newdata,\n                          data) {\n\n  top_order &lt;- x$params$top_order\n  s &lt;- x$params$s\n  S_0 &lt;- x$params$S_0\n  y &lt;- x$params$y\n  adj &lt;- x$params$adj\n  num_neighbors &lt;- x$params$num_neighbors\n  variables &lt;- top_order[!top_order %in% c(s, y)]\n  newdata_0 &lt;- newdata |&gt; filter(!!sym(s) == !!S_0)\n  data_0 &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n  data_1 &lt;- data |&gt; filter(!!sym(s) != !!S_0)\n  list_ecdf &lt;- x$ecdf\n  list_ecdf_values &lt;- x$ecdf_values\n  fit_for_categ &lt;- x$fit_for_categ\n\n  # Lists where results will be stored\n  list_transported &lt;- list()  # Transported values\n\n  for (x_name in variables) {\n    # Names of the parent variables\n    parents &lt;- colnames(adj)[adj[, x_name] == 1]\n    # values of current x in each group\n    x_S0 &lt;- newdata |&gt; pull(!!x_name)\n    x_S0_initial &lt;- data_0 |&gt; pull(!!x_name)\n    x_S1 &lt;- data_1 |&gt; pull(!!x_name)\n    # Check whether X is numeric\n    is_x_num &lt;- is.numeric(x_S0)\n    # Characteristics of the parent variables (if any)\n    parents_characteristics &lt;- newdata_0 |&gt; select(!!parents, -!!s)\n\n    if (length(parents_characteristics) &gt; 0) {\n      newdata_0_parents &lt;- newdata_0 |&gt; select(!!parents) |&gt; select(-!!s)\n      data_0_parents &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\n      data_1_parents &lt;- data_1 |&gt; select(!!parents) |&gt; select(-!!s)\n      # Weights in S_0\n      weights_S0 &lt;- x$weights[[x_name]]$w_S0$weights\n      tot_weights_S0 &lt;- x$weights[[x_name]]$w_S0$tot_weights\n\n      # Weights in S_1\n      # First, we need to get the transported values for the parents, if necessary\n      newdata_0_parents_t &lt;- newdata_0_parents #init\n      data_0_parents_t &lt;- data_0_parents #init\n      for (parent in parents) {\n        # does the parent depend on the sensitive variable\n        if (parent %in% names(list_transported)) {\n          newdata_0_parents_t &lt;-\n            newdata_0_parents_t |&gt;\n            mutate(!!sym(parent) := list_transported[[parent]])\n          data_0_parents_t &lt;-\n            data_0_parents_t |&gt;\n            mutate(!!sym(parent) := x$transported[[parent]])\n        }\n      }\n\n      combined &lt;- rbind(newdata_0_parents_t, data_1_parents)\n      gower_dist &lt;- daisy(combined, metric = \"gower\")\n      gower_matrix &lt;- as.matrix(gower_dist)\n      n_0 &lt;- nrow(newdata_0_parents_t)\n      n_1 &lt;- nrow(data_1_parents)\n      weights_S1 &lt;- gower_matrix[1:n_0, (n_0 + 1):(n_0 + n_1), drop = FALSE]\n      weights_S1 &lt;- weights_S1 + 1e-8\n      weights_S1 &lt;- 1 / (weights_S1)^2\n      tot_weights_S1 &lt;- apply(weights_S1, MARGIN = 1, sum)\n\n      if (is_x_num == TRUE) {\n        # Find the closest point in S0 with respect to the current variable\n        closest_indices &lt;- map_dbl(x_S0, ~which.min(abs(x_S0_initial - .x)))\n\n        # Numerical variable to transport\n\n        # Empirical distribution function\n        f &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          ind_closest &lt;- closest_indices[i]\n          f[i] &lt;- weights_S0[ind_closest, ] %*% (x_S0_initial &lt;= x_S0_initial[ind_closest]) / tot_weights_S0[ind_closest]\n        }\n        f[f==1] &lt;- 1-(1e-8)\n        # Transported values\n        transported &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          wts &lt;- weights_S1[i, ]\n          # Give weights to the 5 closests points only\n          wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n          transported[i] &lt;- Hmisc::wtd.quantile(\n            x = x_S1, weights = weights_S1[i, ], probs = f[i]\n          )\n        }\n      } else {\n        # X is non numeric and has parents\n\n        # Retrieve fitted model (categorical variable given the characteristics\n        # of the parents in group to transport into)\n        fit_indix_x &lt;- fit_for_categ[[x_name]]\n        # Predictions with that model for transported parents\n        pred_probs &lt;- predict(fit_indix_x, type = \"probs\", newdata = newdata_0_parents_t)\n        # For each observation, random draw of the class, using the pred probs\n        # as weights\n        drawn_class &lt;- apply(\n          pred_probs, 1,\n          function(x) sample(1:ncol(pred_probs), prob = x, size = 1)\n        )\n        transported &lt;- colnames(pred_probs)[drawn_class]\n        if (is.factor(x_S1)) {\n          transported &lt;- factor(transported, levels = levels(x_S1))\n        }\n      }\n      list_transported[[x_name]] &lt;- transported\n    } else {\n      # No parents\n      if (is_x_num == TRUE) {\n        # X is numerical and has no parents\n        F_X_S0 &lt;- list_ecdf[[x_name]]\n        f &lt;- F_X_S0(x_S0)\n        transported &lt;- as.numeric(quantile(x_S1, probs = f))\n      } else {\n        # X is not numerical and has no parents\n        transported &lt;- sample(x_S1, size = length(x_S0), replace = TRUE)\n        if (is.factor(x_S1)) {\n          transported &lt;- factor(transported, levels = levels(x_S1))\n        } else {\n          transported &lt;- as.factor(transported)\n        }\n      }\n      list_transported[[x_name]] &lt;- transported\n    }\n  }\n  list_transported\n}\n\n\nWe will transport the following individual.\n\nnew_obs &lt;- tibble(X1 = -2, X2 = -1, S = 0)\n\n\n4.6.1 Optimal Transport\nSince we have previously defined the optimal transport function for our simulated data (drawn from a bivariate Gaussian distribution), we can apply the mapping to our new individual.\n\nnew_obs_ot &lt;- t(apply(new_obs[, c(\"X1\", \"X2\")], 1, OT))\nnew_obs_ot\n\n          [,1]     [,2]\n[1,] 0.6353342 1.890324\n\n\n\n\n4.6.2 Sequential Transport\nNow, let us consider two cases:\n\nTransport first X1 then X2.\nTransport first X2 then X1.\n\n\nvariables &lt;- c(\"S\", \"X1\", \"X2\", \"S\")\n\n\n4.6.2.1 X1 then X2\nThe adjacency matrix:\n\nadj_1 &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1,# S\n    0, 0, 1, 1,# X1\n    0, 0, 0, 1,# X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\nThe causal graph:\n\ncausal_graph_1 &lt;- fairadapt::graphModel(adj_1)\nplot(causal_graph_1)\n\n\n\n\nFigure 4.5: Assumed Causal Graph\n\n\n\n\n\n\n\n\nWe can then use our seq_trans() to first learn the mapping.\n\ntrans_x1_then_x2 &lt;- seq_trans(\n  data = D_SXY, adj = adj_1, s = \"S\", S_0 = 0, y = \"Y\"\n)\n\nTransporting  X1 \nTransporting  X2 \n\n\nWarning in Hmisc::wtd.quantile(x = x_S1, weights = weights_S1[i, ], probs =\nf[i]): probable complete loss of accuracy in modulus\n\n\nWarning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):\ncollapsing to unique 'x' values\n\n\nUsing the learned mapping, we can transport our new individual, thanks to our seq_trans_new() function.\n\nnew_obs_x1_then_x2 &lt;- seq_trans_new(\n  x = trans_x1_then_x2, newdata = new_obs, data = D_SXY\n)\nnew_obs_x1_then_x2\n\n$X1\n[1] 0.607805\n\n$X2\n[1] 2.32019\n\n\n\n\n4.6.2.2 X2 then X1\nNow let us turn to the alternative assumption, where we first transport X2, then X1.\nThe adjacency matrix:\n\nadj_2 &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1,# S\n    0, 0, 0, 1,# X1\n    0, 1, 0, 1,# X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\nThe causal graph:\n\ncausal_graph_2 &lt;- fairadapt::graphModel(adj_2)\nplot(causal_graph_2)\n\n\n\n\nFigure 4.6: Assumed Causal Graph\n\n\n\n\n\n\n\n\nWe can then use our seq_trans() to first learn the mapping.\n\ntrans_x2_then_x1 &lt;- seq_trans(\n  data = D_SXY, adj = adj_2, s = \"S\", S_0 = 0, y = \"Y\"\n)\n\nTransporting  X2 \nTransporting  X1 \n\n\nWarning in Hmisc::wtd.quantile(x = x_S1, weights = weights_S1[i, ], probs =\nf[i]): probable complete loss of accuracy in modulus\n\n\nWarning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):\ncollapsing to unique 'x' values\n\n\nUsing the learned mapping, we can transport our new individual, thanks to our seq_trans_new() function.\n\nnew_obs_x2_then_x1 &lt;- seq_trans_new(\n  x = trans_x2_then_x1, newdata = new_obs, data = D_SXY\n)\nnew_obs_x2_then_x1\n\n$X2\n[1] 1.480031\n\n$X1\n[1] 1.029645\n\n\n\n\n\n4.6.3 Hypothetical Model\nAssume the scores obtained from a logistic regression write: \\[\nm(x_1,x_2,s)=\\big(1+\\exp\\big[-\\big((x_1+x_2)/2 + \\boldsymbol{1}(s=1)\\big)\\big]\\big)^{-1}.\n\\]\n\n#' Logistic regression\n#' \n#' @param x1 first numerical predictor\n#' @param x2 second numerical predictor\n#' @param s sensitive attribute (0/1)\nlogistique_reg &lt;- function(x1, x2, s) {\n  eta &lt;- (x1 + x2) / 2 - s\n  exp(eta) / (1 + exp(eta))\n}\n\nWe can use this hypothetical model to make predictions given the values of \\(x_1\\) and \\(x_2\\). Let us make some on a grid.\n\nvx0 &lt;- seq(-5, 5, length = 251)\ndata_grid &lt;- expand.grid(x = vx0, y = vx0)\nL0 &lt;- logistique_reg(x1 = data_grid$x, x2 = data_grid$y, s = 0)\nL1 &lt;- logistique_reg(x1 = data_grid$x, x2 = data_grid$y, s = 1)\n# as a grid:\ndlogistique0 &lt;- matrix(L0, length(vx0), length(vx0))\ndlogistique1 &lt;- matrix(L1, length(vx0), length(vx0))\n\n\n\n4.6.4 Visualization\nLet us estimate (again) the kernel densities in each group.\n\n# Computation of smoothing parameters (bandwidth) for kernel density estimation\nH0 &lt;- Hpi(D_SXY0[, c(\"X1\",\"X2\")])\nH1 &lt;- Hpi(D_SXY1[, c(\"X1\",\"X2\")])\n\n# Calculating multivariate densities in each group\nf0_2d &lt;- kde(D_SXY0[, c(\"X1\",\"X2\")], H = H0, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d &lt;- kde(D_SXY1[, c(\"X1\",\"X2\")], H = H1, xmin = c(-5, -5), xmax = c(5, 5))\n\nLet us create a table with the coordinates of different points: the new individual and its new coordinates depending on the transport method.\n\ncoords &lt;- tibble(\n  # 1. (x1, x2)\n  start = c(new_obs$X1, new_obs$X2),\n  # 2. (T_1(x1 | x2), T_2(x2))\n  x2_then_x1 = c(new_obs_x2_then_x1$X1, new_obs_x2_then_x1$X2),\n  # 3. (T_1(x1), T_2(x2 | x1))\n  x1_then_x2 = c(new_obs_x1_then_x2$X1, new_obs_x1_then_x2$X2),\n  # 4. (T_1(x1), x2)\n  x1_intermediaire = c(new_obs_x1_then_x2$X1, new_obs$X2),\n  # 5. (x1, T_2(x2))\n  x2_intermediaire = c(new_obs$X1, new_obs_x2_then_x1$X2),\n  # 6. T*(x1,x2)\n  x_ot = c(new_obs_ot[1], new_obs_ot[2])\n)\n\nWe can use the hypothetical model to compute its prediction for all these points. We also add a prediction when we only change the sensitive variable \\(S\\) from 0 to 1 and leave the coordinates \\(x_1\\) and \\(x_2\\) unchanged.\n\nv &lt;- c(\n  # 1. Prediction at initial values (S=0, x1, x2)\n  logistique_reg(x1 = coords$start[1], x2 = coords$start[2], s = 0),\n  # 2. Prediction if (S=1, x1, x2)\n  logistique_reg(coords$start[1], coords$start[2], 1),\n  # 3. Prediction if (S = 1, T_1(x1), T_2(x2 | x1))\n  logistique_reg(coords$x1_then_x2[1], coords$x1_then_x2[2], 1),\n  # 4. Prediction if (S = 1, T_1(x1 | x2), T_2(x2))\n  logistique_reg(coords$x2_then_x1[1], coords$x2_then_x1[2], 1),\n  # 5. Prediction if (S = 1, T_1(x1), x2)\n  logistique_reg(coords$x1_intermediaire[1], coords$x1_intermediaire[2], 1),\n  # 6. Prediction if (S = 1, x1, T_2(x2))\n  logistique_reg(coords$x2_intermediaire[1], coords$x2_intermediaire[2], 1),\n  # 7. Prediction if (S=1, T*(x1), T*(x2))\n  logistique_reg(coords$x_ot[1], coords$x_ot[2], 1)\n)\n\nThen, we can plot all this information on a graph. The arrows show the path from the new individual to its counterfactual assuming the two different causal relationships. The red square shows the value obtained with multivariate optimal transport.\n\n\nCode\npar(mar = c(2, 2, 0, 0))\n# Group 0\n## Estimated density: level curves for (x1, x2) -&gt; m(0, x1, x2)\nCeX &lt;- 1\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,\n  col = scales::alpha(colours[\"A\"], .3),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Group 1\n## Estimated density: level curves for (x1, x2) -&gt; m(1, x1, x2)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,\n  col = scales::alpha(colours[\"B\"], .3), add = TRUE\n)\ncontour(\n  vx0, vx0, dlogistique0,\n  levels = (1:9)/10,\n  col = scl,\n  add = TRUE,lwd = 2\n)\naxis(1)\naxis(2)\n\n###\n# Individual (S=0, x1=-2, x2=-1)\n###\npoints(coords$start[1], coords$start[2], pch = 19, cex = CeX)\n## Predicted value for the individual, based on factuals\ntext(\n  coords$start[1], coords$start[2],\n  paste(round(v[1] * 100, 1), \"%\", sep = \"\"), \n  pos = 1, cex = CeX, col = \"darkblue\"\n)\n\n\n\n\n\nFigure 4.7: In the background, level curves for \\((x_1,x_2)\\mapsto m(0,x_1,x_2)\\). The blue point corresponds to the individual \\((s,x_1,x_2)=(s=0,-2,-1)\\) (predicted 18.2% by model \\(m\\), and 7.6% if \\(s\\) is set to 1 leaving \\(x_1\\) and \\(x_2\\) unchanged).\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar = c(2, 2, 0, 0))\n# Group 0\n## Estimated density: level curves for (x1, x2) -&gt; m(0, x1, x2)\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,\n  col = scales::alpha(colours[\"A\"], .3),\n  axes = FALSE, xlab = \"\", ylab = \"\"\n)\n# Group 1\n## Estimated density: level curves for (x1, x2) -&gt; m(1, x1, x2)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,\n  col = scales::alpha(colours[\"B\"], .3), add = TRUE\n)\n\n# Contour of estimates by the model for s=1\ncontour(\n  vx0, vx0, dlogistique1,\n  levels = (1:9) / 10,\n  col = scl, lwd=2,\n  add = TRUE\n)\naxis(1)\naxis(2)\n\n###\n# Individual (s=0, x1=-2, x2=-1)\n###\npoints(coords$start[1], coords$start[2], pch = 19, cex = CeX)\n## Predicted value for the individual, based on factuals\ntext(\n  coords$start[1] - .3, coords$start[2] - .42 - .3,\n  paste(round(v[1] * 100, 1), \"%\", sep = \"\"), \n  pos = 1, cex = CeX, col = \"darkblue\"\n)\n\n###\n# Transported individual when transporting x1 and then x2, i.e.,\n# (do(s=1), T_1^*(x1), T_2^*(x_2 | x_1))\n###\npoints(coords$x1_then_x2[1],coords$x1_then_x2[2], pch = 19, cex = CeX)\nsegments(\n  x0 = coords$start[1], y0 = coords$start[2], \n  x1 = coords$x1_then_x2[1], y1 = coords$start[2], \n  lwd = .8\n)\nsegments(\n  x0 = coords$x1_then_x2[1], y0 = coords$x1_then_x2[2],\n  x1 = coords$x1_then_x2[1], y1 = coords$start[2], \n  lwd = .8\n)\n## Intermediate point\npoints(coords$x1_then_x2[1], coords$start[2], pch = 19, col = \"white\", cex = CeX)\npoints(coords$x1_then_x2[1], coords$start[2], pch = 1, cex = CeX)\ntext(\n  coords$x1_then_x2[1], coords$start[2] - .42,\n  paste(round(v[5] * 100, 1), \"%\", sep = \"\"), pos = 4, cex = CeX\n)\n# New predicted value for # (do(s=1), T_1^*(x1), T_2^*(x_2 | x_1))\ntext(\n  coords$x1_then_x2[1], coords$x1_then_x2[2],\n  paste(round(v[3]*100,1),\"%\",sep=\"\"), pos = 3, cex = CeX\n)\n\n###\n# Transported individual when transporting x2 and then x1, i.e.,\n# (do(s=1), T_1^*(x1 | x2), T_2^*(x_2))\n###\npoints(coords$x2_then_x1[1],coords$x2_then_x1[2],pch=19,cex=CeX)\nsegments(\n  x0 = coords$start[1], y0 = coords$start[2],\n  x1 = coords$start[1], y1 = coords$x2_then_x1[2],\n  lwd = .8\n)\nsegments(\n  x0 = coords$x2_then_x1[1], y0 = coords$x2_then_x1[2],\n  x1 = coords$start[1], y1 = coords$x2_then_x1[2],\n  lwd = .8\n)\n## Intermediate point\npoints(coords$start[1], coords$x2_then_x1[2], pch = 19, col = \"white\", cex = CeX)\npoints(coords$start[1], coords$x2_then_x1[2], pch = 1, cex = CeX)\ntext(\n  coords$start[1], coords$x2_then_x1[2],\n  paste(round(v[6] * 100, 1), \"%\", sep = \"\"), pos = 2, cex = CeX\n)\n## New predicted value for (do(s=1), T_1^*(x1 | x2), T_2^*(x_2))\ntext(\n  coords$x2_then_x1[1], coords$x2_then_x1[2],\n  paste(round(v[4] * 100, 1), \"%\", sep = \"\"), pos = 4, cex = CeX\n)\n\n###\n# New predicted value for (do(s=1), x1, x2), no transport\n###\nry &lt;- .2\nplotrix::draw.circle(\n  x = coords$start[1] - ry, y = coords$start[2] - ry, \n  radius = ry * sqrt(2)\n)\ntext(\n  coords$start[1], coords$start[2] + .42,\n  paste(round(v[2] * 100, 1), \"%\", sep = \"\"), pos = 4, cex = CeX\n)\n\n###\n# Transported individual with optimal multivariate transport\n###\npoints(coords$x_ot[1],coords$x_ot[2], pch = 15, cex = CeX, col = \"#C93312\")\nsegments(\n  x0 = coords$start[1], y0 = coords$start[2], \n  x1 = coords$x_ot[1], y1 = coords$x_ot[2], \n  lwd = .8,\n  col = \"#C93312\", lty = 2\n)\ntext(\n  coords$x_ot[1], coords$x_ot[2] + .22,\n  paste(round(v[7] * 100, 1), \"%\", sep = \"\"), pos = 4, cex = CeX,\n  col = \"#C93312\",\n)\n\n\n\n\n\nFigure 4.8: In the background, level curves for\\(m(1,x_1,x_2)\\). Two counterfactuals are depicted by the black dots \\((s=1,x_1^\\star,x_2^\\star)\\) according to a causal graph where \\(x_2\\) depends on \\(x_1\\) (bottom left path, predicted 61.4%) and a causal graph where \\(x_1\\) depends on \\(x_2\\) (top left path, predicted 56.5%). The red square shows the counterfactual obtained with optimal transport (with a predicted value by model \\(m\\) at 56.5%).",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Faster Algorithm</span>"
    ]
  },
  {
    "objectID": "gaussian-dep.html",
    "href": "gaussian-dep.html",
    "title": "5  Wrong Causal Assumptions",
    "section": "",
    "text": "5.1 Assumed Causal Models\nIn this simulation setup where the covariates \\(X_1\\) and \\(X_2\\) are independent, we will assume two causal models:\nvariables &lt;- c(\"S\", \"X1\", \"X2\", \"Y\")",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wrong Causal Assumptions</span>"
    ]
  },
  {
    "objectID": "gaussian-dep.html#assumed-causal-models",
    "href": "gaussian-dep.html#assumed-causal-models",
    "title": "5  Wrong Causal Assumptions",
    "section": "",
    "text": "Correct assumption: we will assume that there is no dependence between \\(X_1\\) and \\(X_2\\) (as shown in Figure 5.2)\nWrong Dependence 1: we will asumme that \\(X_2\\) depends on \\(X_1\\) (as shown in Figure 5.3)\nWrong Dependence 2: we will asumme that \\(X_1\\) depends on \\(X_2\\) (as shown in Figure 5.4).\n\n\n\n5.1.1 Correct Assumption\n\nadj_indep_correct &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1, # S\n    0, 0, 0, 1, # X1\n    0, 0, 0, 1, # X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\n\n\nCodes to create Tikz from an adjacency matrix.\n#' Add a tikz graph in a quarto HTML document\n#'\n#' @param tikz_code Tikz code.\nadd_tikz_graph &lt;- function(tikz_code,\n                           label,\n                           caption = \"Causal Graph\",\n                           echo = \"true\",\n                           code_fold = \"true\",\n                           fig_ext = \"png\",\n                           code_summary = \"Tikz code\") {\n  \n  res &lt;- knitr::knit_child(\n    text = glue::glue(r\"(\n             ```{tikz}\n             #| echo: {echo}\n             #| label: {label}\n             #| fig-cap: {caption}\n             #| fig-ext: {fig_ext}\n             #| code-fold: {code_fold}\n             #| code-summary: {code_summary}\n             \\usetikzlibrary{{arrows}}\n             {tikz_code}\n             ```)\"\n    ),\n    quiet = TRUE\n  )\n  knitr::asis_output(res)\n}\n\ncolour_nodes &lt;- c(\n  \"S\" = \"red!30\",\n  \"X1\" = \"yellow!60\", \n  \"X2\" = \"yellow!60\", \n  \"Y\" = \"blue!30\"\n)\n# Then, in the document:\n# `r add_tikz_graph(tikz_code = causal_graph_tikz(adj_indep_correct,colour_nodes), label = \"fig-causal-graph-indep-correct\", caption = \"\\\"Assumed Causal Graph: Correct Model\\\"\", echo = \"false\")`\n\n\n\n\n\n\n\nFigure 5.2: Assumed Causal Graph: Correct Model\n\n\n\n\n\n\n\n\n\n\n5.1.2 Wrong Assumption: \\(X_1\\) causes \\(X_2\\)\n\nadj_indep_inc_x1_then_x2 &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1, # S\n    0, 0, 1, 1, # X1\n    0, 0, 0, 1, # X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\n\n\n\n\n\nFigure 5.3: Assumed Causal Graph: Incorrecly Assumes that \\(X_1\\) causes \\(X_2\\)\n\n\n\n\n\n\n\n\n\n\n5.1.3 Wrong Assumption: \\(X_2\\) causes \\(X_1\\)\n\nadj_indep_inc_x2_then_x1 &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1, # S\n    0, 1, 0, 1, # X1\n    0, 1, 0, 1, # X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\n\n\n\n\n\nFigure 5.4: Assumed Causal Graph: Incorrecly Assumes that \\(X_2\\) causes \\(X_1\\)",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wrong Causal Assumptions</span>"
    ]
  },
  {
    "objectID": "gaussian-dep.html#counterfactuals",
    "href": "gaussian-dep.html#counterfactuals",
    "title": "5  Wrong Causal Assumptions",
    "section": "5.2 Counterfactuals",
    "text": "5.2 Counterfactuals\nWe now build counterfactuals for individuals from group \\(S=0\\). First, we get the counterfactuals using optimal transport.\n\n5.2.1 Multivariate OT\nTo compute the counterfactual with multivariate optimal transport, we turn to python, to use the {POT: Python Optimal Transport} library.\nWe export the data into a CSV file:\n\nwrite_csv(D_SXY, file = \"../data/D_SXY_indep.csv\")\n\nAnd we use the {reticulate} R package to run python in this chapter.\n\nlibrary(reticulate)\n# reticulate::install_miniconda(force = TRUE)\nuse_virtualenv(\"~/quarto-python-env\", required = TRUE)\n# py_install(\"POT\")\n\nSome libraries need to be loaded, including the {POT} library, called ot.\n\nimport ot\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pl\nimport ot.plot\n\nThe data with the factuals need to be loaded:\n\ntb = pd.read_csv('../data/D_SXY_indep.csv')\nx_S = tb.drop(columns=['Y'])\nx_S.head()\n\n   S        X1        X2\n0  0  0.287578  0.599989\n1  0  0.788305  0.332824\n2  0  0.408977  0.488613\n3  0  0.883017  0.954474\n4  0  0.940467  0.482902\n\n\nWe will also make some predictions for an additional point: \\((s=0, x_1= 0, x_2=0.5)\\).\n\nnew_point = pd.DataFrame({'S': [0], 'X1': [0], 'X2': [0.5]})\n\n\nx_S = pd.concat([x_S, new_point], ignore_index=True)\n\nx_0 = x_S[x_S['S'] == 0]\nx_0 = x_0.drop(columns=['S'])\nx_1 = x_S[x_S['S'] == 1]\nx_1 = x_1.drop(columns=['S'])\n\nn_0 = len(x_0)\nn_1 = len(x_1)\n# Uniform weights\nw_0 = (1/n_0)*np.ones(n_0)\nw_1 = (1/n_1)*np.ones(n_1)\n\nCost matrix between both distributions:\n\nx_0 = x_0.to_numpy()\nx_1 = x_1.to_numpy()\nC = ot.dist(x_0, x_1)\n\nTransport plan: from 0 to 1\n\npi_0_1 = ot.emd(w_0, w_1, C, numItermax=1e8)\npi_1_0 = pi_0_1.T\npi_0_1.shape\n\n(101, 100)\n\nsum_of_rows = np.sum(pi_0_1, axis=1)\nsum_of_rows*n_0\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n\npi_1_0.shape\n\n(100, 101)\n\nsum_of_rows = np.sum(pi_1_0, axis=1)\nsum_of_rows*n_1\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n\n\nThe transported values:\n\ntransformed_x_0 = n_0*pi_0_1@x_1\ntransformed_x_1 = n_1*pi_1_0@x_0\n\nLet us build an array with the values of the counterfactuals (for both groups here, even if we will only use the counterfactuals for group \\(S=0\\) only).\n\ncounterfactual_x = x_S.drop(columns=['S'])\ncounterfactual_x[x_S['S'] == 0] = transformed_x_0\ncounterfactual_x[x_S['S'] == 1] = transformed_x_1\n\nLastly, we export this array in a CSV file:\n\ncsv_file_path = '../data/counterfactuals_ot_test_indep.csv'\ncounterfactual_x.to_csv(csv_file_path, index=False)\n\nWe can then go back to R.\n\ncounterfactuals_ot &lt;- \n  read_csv(\"../data/../data/counterfactuals_ot_test_indep.csv\")\n\nRows: 201 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): X1, X2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncounterfactuals_ot\n\n# A tibble: 201 × 2\n      X1    X2\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  1.25  1.51\n 2  1.82  1.24\n 3  1.40  1.42\n 4  1.80  1.99\n 5  1.97  1.39\n 6  1.06  1.84\n 7  1.48  2.00\n 8  1.77  1.59\n 9  1.49  1.34\n10  1.40  1.03\n# ℹ 191 more rows\n\n\nRecall that we added an additional point. The last observation from this table corresponds to the counterfactual of \\((s=0, x_1=0, x_2=0.5)\\).\n\n\n5.2.2 Sequential Transport\nWe rely on our function, seq_trans() available in our small R package (type ?seq_trans in the console after loading the package.\nWe compute the counterfactuals for individuals from group \\(S=0\\) for each assumed causal graph.\n\ntrans_indep_correct &lt;- seq_trans(\n  data = D_SXY, adj = adj_indep_correct, s = \"S\", S_0 = 0, y = \"Y\"\n)\n\nTransporting  X1 \nTransporting  X2 \n\ntrans_indep_inc_x1_then_x2 &lt;- seq_trans(\n  data = D_SXY, adj = adj_indep_inc_x1_then_x2, s = \"S\", S_0 = 0, y = \"Y\"\n)\n\nTransporting  X1 \nTransporting  X2 \n\ntrans_indep_inc_x2_then_x1 &lt;- seq_trans(\n  data = D_SXY, adj = adj_indep_inc_x2_then_x1, s = \"S\", S_0 = 0, y = \"Y\"\n)\n\nTransporting  X2 \nTransporting  X1 \n\n\nLet us also get a counterfactual for the additional point \\((s=0, x_1=0, x_2=0.5)\\).\n\nnew_obs &lt;- tibble(S = 0, X1 = 0, X2 = .5)\n\n\nnew_obs_indep_correct &lt;- seq_trans_new(\n  x = trans_indep_correct, newdata = new_obs, data = D_SXY\n)\nnew_obs_indep_inc_x1_then_x2 &lt;- seq_trans_new(\n  x = trans_indep_inc_x1_then_x2, newdata = new_obs, data = D_SXY\n)\nnew_obs_indep_inc_x2_then_x1 &lt;- seq_trans_new(\n  x = trans_indep_inc_x2_then_x1, newdata = new_obs, data = D_SXY\n)",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wrong Causal Assumptions</span>"
    ]
  },
  {
    "objectID": "gaussian-dep.html#hypothetical-model",
    "href": "gaussian-dep.html#hypothetical-model",
    "title": "5  Wrong Causal Assumptions",
    "section": "5.3 Hypothetical Model",
    "text": "5.3 Hypothetical Model\nAssume the scores obtained from a logistic regression write:\n\\[\nm(x_1,x_2,s)=\\big(1+\\exp\\big[-\\big((x_1+x_2)/2 + \\boldsymbol{1}(s=1)\\big)\\big]\\big)^{-1}.\n\\]\n\n#' Logistic regression\n#' \n#' @param x1 first numerical predictor\n#' @param x2 second numerical predictor\n#' @param s sensitive attribute (0/1)\nlogistique_reg &lt;- function(x1, x2, s) {\n  eta &lt;- (x1 + x2) / 2 - s\n  exp(eta) / (1 + exp(eta))\n}\n\nWe can use this hypothetical model to make predictions given the values of \\(x_1\\) and \\(x_2\\). Let us make some on a grid.\n\nvx0 &lt;- seq(-5, 5, length = 251)\ndata_grid &lt;- expand.grid(x = vx0, y = vx0)\nL0 &lt;- logistique_reg(x1 = data_grid$x, x2 = data_grid$y, s = 0)\nL1 &lt;- logistique_reg(x1 = data_grid$x, x2 = data_grid$y, s = 1)\n# as a grid:\ndlogistique0 &lt;- matrix(L0, length(vx0), length(vx0))\ndlogistique1 &lt;- matrix(L1, length(vx0), length(vx0))",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wrong Causal Assumptions</span>"
    ]
  },
  {
    "objectID": "gaussian-dep.html#visualization",
    "href": "gaussian-dep.html#visualization",
    "title": "5  Wrong Causal Assumptions",
    "section": "5.4 Visualization",
    "text": "5.4 Visualization\nLet us create a table with the coordinates of different points: the new individual and its new coordinates depending on the transport method.\n\ncoords_indep &lt;- tibble(\n  # 1. (x1, x2)\n  start = c(new_obs$X1, new_obs$X2),\n  #\n  # 2. (T_1(x1 | x2), T_2(x2)), correct assumption\n  correct = c(\n    new_obs_indep_correct$X1, new_obs_indep_correct$X2\n  ),\n  # 3. (T_1(x1), T_2(x2 | x1)), assuming X1 -&gt; X2\n  inc_x1_then_x2 = c(\n    new_obs_indep_inc_x1_then_x2$X1, new_obs_indep_inc_x1_then_x2$X2\n  ),\n  # 4. (T_1(x1 | x2), T_2(x2)), assuming X2 -&gt; X1\n  inc_x2_then_x1 = c(\n    new_obs_indep_inc_x2_then_x1$X1, new_obs_indep_inc_x2_then_x1$X2\n  ),\n  #\n  # 5. (T_1(x1), x2)\n  correct_interm_x2 = c(new_obs_indep_correct$X1, new_obs$X2),\n  # 6. (T_1(x1), x2), assuming X1 -&gt; X2\n  inc_x1_then_x2_interm_x2 = c(new_obs_indep_inc_x1_then_x2$X1, new_obs$X2),\n  # 7. (T_1(x1), x2), assuming X2 -&gt; X1\n  inc_x2_then_x1_interm_x2 = c(new_obs_indep_inc_x2_then_x1$X1, new_obs$X2),\n  #\n  # 8. (x1, T(x2))\n  correct_interm_x1 = c(new_obs$X1, new_obs_indep_correct$X2),\n  # 9. (T_1(x1), x2), assuming X1 -&gt; X2\n  inc_x1_then_x2_interm_x1 = c(new_obs$X1, new_obs_indep_inc_x1_then_x2$X2),\n  # 10. (T_1(x1), x2), assuming X2 -&gt; X1\n  inc_x2_then_x1_interm_x1 = c(new_obs$X1, new_obs_indep_inc_x2_then_x1$X2),\n  # 11. T*(x1,x2)\n  ot = c(last(counterfactuals_ot$X1), last(counterfactuals_ot$X2))\n)\n\nWe make “Predictions” by the hypothetical model for the new point, given the characteristics \\(x_1\\) and \\(x_2\\) contained in coords_indep, setting \\(s=0\\).\n\npredicted_val &lt;- apply(\n  coords_indep, \n  2, \n  function(column) logistique_reg(x1 = column[1], x2 = column[2], s = 1)\n)\n\nThen, we add a prediction for the point using the factuals values:\n\npredicted_val &lt;- c(\n  naive = logistique_reg(\n    x1 = coords_indep$start[1], x2 = coords_indep$start[2], s = 0\n  ),\n  predicted_val\n)\n\n\n\nCode\ncolour_start &lt;- \"darkblue\"\ncolour_correct &lt;- \"#CC79A7\"\ncolour_inc_x1_then_x2 &lt;- \"darkgray\"\ncolour_inc_x2_then_x1 &lt;- \"#56B4E9\"\ncolour_ot &lt;- \"#C93312\"\ncolour_naive &lt;- \"#000000\"\n\n# Colour scale from colour of class 0 to class 1\ncolfunc &lt;- colorRampPalette(c(colours[\"0\"], colours[\"1\"]))\nscl &lt;- scales::alpha(colfunc(9),.9)\n\nCeX &lt;- 1\npar(mar = c(2, 2, 0, 0))\n# Group 0\n## Estimated density: level curves for (x1, x2) -&gt; m(0, x1, x2)\ncontour(\n  f0_2d$eval.point[[1]],\n  f0_2d$eval.point[[2]],\n  f0_2d$estimate,\n  col = scales::alpha(colours[\"A\"], .3),\n  axes = FALSE, xlab = \"\", ylab = \"\",\n  xlim = c(-1, 3), ylim = c(-1, 3)\n)\n# Group 1\n## Estimated density: level curves for (x1, x2) -&gt; m(1, x1, x2)\ncontour(\n  f1_2d$eval.point[[1]],\n  f1_2d$eval.point[[2]],\n  f1_2d$estimate,\n  col = scales::alpha(colours[\"B\"], .3), add = TRUE\n)\n\n# Contour of estimates by the model for s=1\ncontour(\n  vx0, vx0, dlogistique1,\n  levels = (1:9) / 10,\n  col = scl, lwd=2,\n  add = TRUE\n)\naxis(1)\naxis(2)\n###\n# Individual (s=0, x1=-2, x2=-1)\n###\npoints(\n  coords_indep$start[1], coords_indep$start[2], \n  pch = 19, cex = CeX, col = colour_start\n)\n## Predicted value for the individual, based on factuals\ntext(\n  coords_indep$start[1], coords_indep$start[2], \n  paste(round(predicted_val[\"start\"] * 100, 1), \"%\", sep = \"\"),\n  pos = 1, cex = CeX, col = colour_start\n)\n\n###\n# Transported individual using correct DAG\n###\npoints(\n  coords_indep$correct[1], coords_indep$correct[2],\n  pch = 19, cex = CeX, col = colour_correct\n)\ntext(\n  coords_indep$correct[1], coords_indep$correct[2],\n  paste(round(predicted_val[[\"correct\"]]*100,1),\"%\",sep=\"\"),\n  pos = 4, cex = CeX, col = colour_correct\n)\nsegments(\n  x0 = coords_indep$start[1], y0 = coords_indep$start[2],\n  x1 = coords_indep$correct_interm_x2[1], y1 = coords_indep$correct_interm_x2[2],\n  lwd = .8, col = colour_correct\n)\nsegments(\n  x0 = coords_indep$correct_interm_x2[1], y0 = coords_indep$correct_interm_x2[2],\n  x1 = coords_indep$correct[1], y1 = coords_indep$correct[2], ,\n  lwd = .8, col = colour_correct\n)\n## Intermediate point\npoints(\n  coords_indep$correct_interm_x2[1], coords_indep$correct_interm_x2[2],\n  pch = 19, col = \"white\", cex = CeX\n)\npoints(\n  coords_indep$correct_interm_x2[1], coords_indep$correct_interm_x2[2],\n  pch = 1, cex = CeX, col = colour_correct\n)\n\n\n###\n# Transported individual assuming X2 depends on X1\n###\npoints(\n  coords_indep$inc_x1_then_x2[1], coords_indep$inc_x1_then_x2[2],\n  pch=19,cex=CeX, col = colour_inc_x1_then_x2\n)\nsegments(\n  x0 = coords_indep$start[1], y0 = coords_indep$start[2],\n  x1 = coords_indep$inc_x1_then_x2[1], y1 = coords_indep$inc_x1_then_x2_interm_x2[2],\n  lwd = .8, col = colour_inc_x1_then_x2\n)\nsegments(\n  x0 = coords_indep$inc_x1_then_x2[1], y0 = coords_indep$inc_x1_then_x2_interm_x2[2],\n  x1 = coords_indep$inc_x1_then_x2[1], y1 = coords_indep$inc_x1_then_x2[2],\n  lwd = .8, col = colour_inc_x1_then_x2\n)\n## Intermediate point\npoints(\n  coords_indep$inc_x1_then_x2[1], coords_indep$inc_x1_then_x2_interm_x2[2],\n  pch = 19, col = \"white\", cex = CeX\n)\npoints(\n  coords_indep$inc_x1_then_x2[1], coords_indep$inc_x1_then_x2_interm_x2[2],\n  pch = 1, cex = CeX, col = colour_inc_x1_then_x2\n)\n## New predicted value\ntext(\n  coords_indep$inc_x1_then_x2[1], coords_indep$inc_x1_then_x2[2],\n  paste(round(predicted_val[[\"inc_x1_then_x2\"]]*100,1),\"%\",sep=\"\"),\n  pos = 2, cex = CeX, col = colour_inc_x1_then_x2\n)\n\n\n###\n# Transported individual assuming X1 depends on X2\n###\npoints(\n  coords_indep$inc_x2_then_x1[1], coords_indep$inc_x2_then_x1[2],\n  pch=19,cex=CeX, col = colour_inc_x2_then_x1\n)\nsegments(\n  x0 = coords_indep$start[1], y0 = coords_indep$start[2],\n  x1 = coords_indep$inc_x2_then_x1_interm_x1[1], y1 = coords_indep$inc_x2_then_x1[2],\n  lwd = .8, col = colour_inc_x2_then_x1\n)\nsegments(\n  x0 = coords_indep$inc_x2_then_x1_interm_x1[1], y0 = coords_indep$inc_x2_then_x1[2],\n  x1 = coords_indep$inc_x2_then_x1[1], y1 = coords_indep$inc_x2_then_x1[2],\n  lwd = .8, col = colour_inc_x2_then_x1\n)\n## Intermediate point\npoints(\n  coords_indep$inc_x2_then_x1_interm_x1[1], coords_indep$inc_x2_then_x1[2],\n  pch = 19, col = \"white\", cex = CeX\n)\npoints(\n  coords_indep$inc_x2_then_x1_interm_x1[1], coords_indep$inc_x2_then_x1[2],\n  pch = 1, cex = CeX, col = colour_inc_x2_then_x1\n)\n## New predicted value\ntext(\n  coords_indep$inc_x2_then_x1[1], coords_indep$inc_x2_then_x1[2],\n  paste(round(predicted_val[[\"inc_x2_then_x1\"]]*100,1),\"%\",sep=\"\"),\n  pos = 3, cex = CeX, col = colour_inc_x2_then_x1\n)\n\n\n###\n# Transported individual with multivariate optimal transport\n###\npoints(\n  coords_indep$ot[1], coords_indep$ot[2],\n  pch=15,cex=CeX, col = colour_ot\n)\nsegments(\n  x0 = coords_indep$start[1], y0 = coords_indep$start[2],\n  x1 = coords_indep$ot[1], y1 = coords_indep$ot[2],\n  lwd = .8, col = colour_ot, lty = 2\n)\n## New predicted value\ntext(\n  coords_indep$ot[1], coords_indep$ot[2]-.2,\n  paste(round(predicted_val[[\"ot\"]] * 100, 1), \"%\", sep = \"\"),\n  pos = 4, cex = CeX, col = colour_ot\n)\n\n###\n# New predicted value for (do(s=1), x1, x2), no transport\n###\nry &lt;- .09\nplotrix::draw.circle(\n  x = coords_indep$start[1] - .9*ry * sqrt(2), \n  y = coords_indep$start[2] - .9*ry * sqrt(2),\n  radius = ry * sqrt(2), border = colour_naive\n)\ntext(\n  coords_indep$start[1], coords_indep$start[2],\n  paste(round(predicted_val[\"naive\"] * 100, 1), \"%\", sep = \"\"),\n  pos = 3, cex = CeX, col = colour_naive\n)\nlegend(\n  \"topleft\",\n  legend = c(\n    \"Start point\",\n    \"Naive\",\n    \"Multivariate optimal transport\",\n    \"Seq. T.: Correct DAG\",\n    latex2exp::TeX(\"Seq. T.: Assuming $X_1 \\\\rightarrow X_2$\"),\n    latex2exp::TeX(\"Seq. T.: Assuming $X_2 \\\\rightarrow X_1$\")\n  ),\n  col = c(\n    colour_start,\n    colour_naive,\n    colour_ot,\n    colour_correct,\n    colour_inc_x1_then_x2,\n    colour_inc_x2_then_x1\n  ),\n  pch = c(19, 19, 15, 19, 19, 19),\n  lty = c(NA, NA, 2, 1, 1, 1), bty = \"n\"\n)\n\n\n\n\n\nFigure 5.5: In the background, level curves for\\(m(1,x_1,x_2)\\). The dark blue dot represents an individual \\((s,x_1,x_2)=(s=0, 0,.5)\\) (predicted 32.1% by model \\(m\\), and 56.2% if \\(s\\) is set to 1 leaving \\(x_1\\) and \\(x_2\\) unchanged). The other dots represent counterfactuals \\((s=1,x_1^\\star,x_2^\\star)\\) according to the assumed causal graph where \\(x_1\\) and \\(x_2\\) are independent (correct DAG, predicted 55.8%), \\(x_2\\) depends on \\(x_1\\) (bottom right path, predicted 54.4%), \\(x_1\\) depends on \\(x_2\\) (top left path, predicted 58.8%). The red square shows the counterfactual obtained with optimal transport (with a predicted value by model \\(m\\) at 54.4%).\n\n\n\n\n\n\n\n\nLet us now consider all the points from \\(S=0\\) and not a single one.\nWe estimate the densities of \\((T(X_1), T(X_2))\\) in each of the four configurations. We can then plot these estimated densities on top of those previously estimated on \\((X_1, X_2)\\) using the factuals.\nWe define a table with the counterfactuals obtained with multivariate optimal transport on the subgroup of \\(S=0\\):\n\ntb_transpoort_ot &lt;- counterfactuals_ot |&gt; \n  slice(1:nrow(D_SXY)) |&gt; # remove last observation: this is the new point\n  mutate(S = D_SXY$S) |&gt; \n  filter(S == 0) |&gt; select(-S)\n\n\n\nCodes to create the Figure.\nH1_OT &lt;- Hpi(tb_transpoort_ot)\nH1_indep_correct &lt;- Hpi(as_tibble(trans_indep_correct$transported))\nH1_indep_inc_x1_then_x2 &lt;- Hpi(as_tibble(trans_indep_inc_x1_then_x2$transported))\nH1_indep_inc_x2_then_x1 &lt;- Hpi(as_tibble(trans_indep_inc_x2_then_x1$transported))\nf1_2d_OT &lt;- kde(tb_transpoort_ot, H = H1_OT, xmin = c(-5, -5), xmax = c(5, 5))\nf1_2d_indep_correct &lt;- kde(\n  as_tibble(trans_indep_correct$transported), \n  H = H1_indep_correct, xmin = c(-5, -5), xmax = c(5, 5)\n)\nf1_2d_indep_inc_x1_then_x2 &lt;- kde(\n  as_tibble(trans_indep_inc_x1_then_x2$transported), \n  H = H1_indep_inc_x1_then_x2, xmin = c(-5, -5), xmax = c(5, 5)\n)\nf1_2d_indep_inc_x2_then_x1 &lt;- kde(\n  as_tibble(trans_indep_inc_x2_then_x1$transported), \n  H = H1_indep_inc_x2_then_x1, xmin = c(-5, -5), xmax = c(5, 5)\n)\n\nx_lim &lt;- c(-.5, 2.5)\ny_lim &lt;- c(-.25, 3)\n\n# Plotting densities\npar(mar = c(2,2,0,0), mfrow = c(2,2))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\", \n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\n\n# Group S=1, Optimal transport\ncontour(\n  f1_2d_OT$eval.point[[1]], f1_2d_OT$eval.point[[2]], f1_2d_OT$estimate, \n  col = colour_ot, add = TRUE\n)\nlegend(\n  \"topleft\", legend = c(\"Obs S=0\", \"Obs S=1\", \"OT\"),\n  lty=1,\n  col = c(colours[\"A\"], colours[\"B\"], colour_ot), bty=\"n\"\n)\n\n\n\n# Group S=1, Sequential transport, correct DAG\n# par(mar = c(2,2,0,0))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\",\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\ncontour(\n  f1_2d_indep_correct$eval.point[[1]], f1_2d_indep_correct$eval.point[[2]], \n  f1_2d_indep_correct$estimate, \n  col = colour_correct, add = TRUE\n)\nlegend(\n  \"topleft\", legend = c(\"Obs S=0\", \"Obs S=1\", \"Seq. T: Correct DAG\"),\n  lty=1,\n  col = c(colours[\"A\"], colours[\"B\"], colour_correct), bty=\"n\"\n)\n\n\n# Group S=1, Sequential transport, Wrong DAG: assuming X2 depends on X1\n# par(mar = c(2,2,0,0))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\",\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\ncontour(\n  f1_2d_indep_inc_x1_then_x2$eval.point[[1]], \n  f1_2d_indep_inc_x1_then_x2$eval.point[[2]], \n  f1_2d_indep_inc_x1_then_x2$estimate, \n  col = colour_inc_x1_then_x2, add = TRUE\n)\nlegend(\n  \"topleft\", legend = c(\n    \"Obs S=0\", \"Obs S=1\", \n    latex2exp::TeX(\"Seq. T.: Assuming $X_1 \\\\rightarrow X_2$\")\n  ),\n  lty=1,\n  col = c(colours[\"A\"], colours[\"B\"], colour_inc_x1_then_x2), bty=\"n\"\n)\n\n# Group S=1, Sequential transport, Wrong DAG: assuming X1 depends on X2\n# par(mar = c(2,2,0,0))\n# Group S=0\ncontour(\n  f0_2d$eval.point[[1]], f0_2d$eval.point[[2]], f0_2d$estimate, \n  col = colours[\"A\"], axes = FALSE, xlab = \"\", ylab = \"\",\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\n# Group S=1\ncontour(\n  f1_2d$eval.point[[1]], f1_2d$eval.point[[2]], f1_2d$estimate, \n  col = colours[\"B\"], add = TRUE\n)\ncontour(\n  f1_2d_indep_inc_x2_then_x1$eval.point[[1]], \n  f1_2d_indep_inc_x2_then_x1$eval.point[[2]], \n  f1_2d_indep_inc_x2_then_x1$estimate, \n  col = colour_inc_x2_then_x1, add = TRUE\n)\nlegend(\n  \"topleft\", legend = c(\n    \"Obs S=0\", \"Obs S=1\",\n    latex2exp::TeX(\"Seq. T.: Assuming $X_2 \\\\rightarrow X_1$\")\n  ),\n  lty=1,\n  col = c(colours[\"A\"], colours[\"B\"], colour_inc_x2_then_x1), bty=\"n\"\n)\n\n\n\n\n\nFigure 5.6: Estimated densities of \\((X_1, X_2)\\) using the factual values or the counterfactual values.",
    "crumbs": [
      "II. Simulations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wrong Causal Assumptions</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "6  Data",
    "section": "",
    "text": "6.1 Data Pre-Processing\nWe load the data:\ndf &lt;- read_csv('../data/law_data.csv')\nHere is some summary information on this dataset:\nsummary(df)\n\n      ...1           race                sex             LSAT      \n Min.   :    0   Length:21791       Min.   :1.000   Min.   :11.00  \n 1st Qu.: 6516   Class :character   1st Qu.:1.000   1st Qu.:33.00  \n Median :13698   Mode  :character   Median :2.000   Median :37.00  \n Mean   :13732                      Mean   :1.562   Mean   :36.77  \n 3rd Qu.:20862                      3rd Qu.:2.000   3rd Qu.:41.00  \n Max.   :27476                      Max.   :2.000   Max.   :48.00  \n      UGPA       region_first            ZFYA           sander_index   \n Min.   :0.000   Length:21791       Min.   :-3.35000   Min.   :0.3875  \n 1st Qu.:3.000   Class :character   1st Qu.:-0.55000   1st Qu.:0.7116  \n Median :3.300   Mode  :character   Median : 0.09000   Median :0.7696  \n Mean   :3.227                      Mean   : 0.09643   Mean   :0.7669  \n 3rd Qu.:3.500                      3rd Qu.: 0.75000   3rd Qu.:0.8274  \n Max.   :4.200                      Max.   : 3.48000   Max.   :1.0000  \n    first_pf     \n Min.   :0.0000  \n 1st Qu.:1.0000  \n Median :1.0000  \n Mean   :0.8884  \n 3rd Qu.:1.0000  \n Max.   :1.0000\nThen, we focus on a subset of variables of interest:\ndf &lt;- df |&gt; \n  select(\n    race, # we can take S = race (white/black)\n    sex,  # or S = gender\n    LSAT, \n    UGPA,\n    ZFYA  # Y\n  )\nWe create a dataset where the only protected class is the race, and we focus on Black individuals and White individuals only:\n# Table for S = race\ndf_race &lt;- df |&gt; \n  select(\n    race,\n    UGPA,\n    LSAT,\n    ZFYA\n  ) |&gt; \n  filter(\n    race %in% c(\"Black\", \"White\")\n  ) |&gt; \n  rename(\n    S = race,\n    X1 = UGPA,\n    X2 = LSAT,\n    Y = ZFYA\n  ) |&gt;  # no NA values\n  mutate(\n    S = as.factor(S)\n  )\nAnd another dataset in which the only protected class is the sex:\n# Table for S = gender\ndf_gender &lt;- df |&gt; \n  select(\n    sex,\n    UGPA,\n    LSAT,\n    ZFYA\n  ) |&gt; \n  rename(\n    S = sex,\n    X1 = UGPA,\n    X2 = LSAT,\n    Y = ZFYA\n  ) |&gt;  # no NA values\n  mutate(\n    S = as.factor(S)\n  )",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-pre-processing",
    "href": "data.html#data-pre-processing",
    "title": "6  Data",
    "section": "",
    "text": "S = RaceS = Gender\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = df_race, \n  mapping = aes(x = Y, fill = S)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.5\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    \"S\",\n    values = c(\n      \"Black\" = colours_all[[\"source\"]], \n      \"White\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Race\",\n    x = \"Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 6.1: Distribution of the standardized first-year law school grades among the two groups, when \\(S\\) is the race\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = df_gender, \n  mapping = aes(x = Y, fill = S)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.5\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    \"S\",\n    values = c(\n      \"Black\" = colours_all[[\"source\"]], \n      \"White\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Gender\",\n    x = \"Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 6.2: Distribution of the standardized first-year law school grades among the two groups, when \\(S\\) is the gender",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#causal-graph",
    "href": "data.html#causal-graph",
    "title": "6  Data",
    "section": "6.2 Causal graph",
    "text": "6.2 Causal graph\nThe assumed causal graph we use here is different from that of the different papers De Lara et al. (2024), Kusner et al. (2017), Black, Yeom, and Fredrikson (2020) using the same dataset.\nWe make the following assumptions:\n\nThe sensitive attribute, (S) (race), has no parents.\nThe two other explanatory variables, (X_1) (UGPA) and (X_2) (LSAT), both directly depend on the sensitive attribute.\nThe second variable, (X_2) (LSAT), also depends on the first variable, (X_1) (UGPA). This is done for illustrative purposes, assuming that the score obtained on the LSAT is influenced by the UGPA.\nThe two variables, (X_1) (UGPA) and (X_2) (LSAT), cause the target variable (Y), i.e., whether the student obtained a high standardized first-year average (ZFYA).\n\nThe corresponding Structural Equation Model writes:\n\\[\n\\begin{cases}\nS: \\text{ sensitive attribute (race)} \\\\\nX_1 = h_1(S, U_1): \\text{ UGPA, dependent on } S \\\\\nX_2 = h_2(S, X_1, U_2): \\text{ LSAT, dependent on } S \\text{ and } X_1 \\\\\nY = h_3(X_1, X_2, U_Y): \\text{ ZFYA, dependent on } X_1 \\text{ and } X_2 \\\\\n\\end{cases}\n\\]\nwhere (U_1), (U_2), and (U_Y) are independent error terms.\nIn R, we construct the upper triangular adjacency matrix to reflect our assumed causal structure:\n\nvariables &lt;- colnames(df_race)\n# Adjacency matrix: upper triangular\nadj &lt;- matrix(\n  c(0, 1, 1, 1,\n    0, 0, 1, 1,\n    0, 0, 0, 1,\n    0, 0, 0, 0),\n  ncol = length(variables), \n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\nWhich can be visualized as follows:\n\ncausal_graph &lt;- fairadapt::graphModel(adj)\nplot(causal_graph)\n\n\n\n\nFigure 6.3: Causal Graph\n\n\n\n\n\n\n\n\nThe topological order:\n\ntop_order &lt;- variables\ntop_order\n\n[1] \"S\"  \"X1\" \"X2\" \"Y\"",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#sec-data-save",
    "href": "data.html#sec-data-save",
    "title": "6  Data",
    "section": "6.3 Saving objects",
    "text": "6.3 Saving objects\n\nsave(df_race, file = \"../data/df_race.rda\")\nsave(df_gender, file = \"../data/df_gender.rda\")\nsave(adj, file = \"../data/adj.rda\")\n\n\n\n\n\nBlack, Emily, Samuel Yeom, and Matt Fredrikson. 2020. “Fliptest: Fairness Testing via Optimal Transport.” In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 111–21.\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, and Jean-Michel Loubes. 2021. “Transport-Based Counterfactual Models.” arXiv 2108.13025.\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser, and Jean-Michel Loubes. 2024. “Transport-Based Counterfactual Models.” Journal of Machine Learning Research 25 (136): 1–59.\n\n\nKusner, Matt J, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. “Counterfactual Fairness.” In Advances in Neural Information Processing Systems 30, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 4066–76. NIPS.\n\n\nWightman, Linda F. 1998. “LSAC National Longitudinal Bar Passage Study. LSAC Research Report Series.” In. https://api.semanticscholar.org/CorpusID:151073942.",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "classifier.html",
    "href": "classifier.html",
    "title": "7  Classifier",
    "section": "",
    "text": "7.1 Load Data\nWe load the data obtained in Chapter 6.3:\nload(\"../data/df_race.rda\")",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classifier</span>"
    ]
  },
  {
    "objectID": "classifier.html#pre-processing",
    "href": "classifier.html#pre-processing",
    "title": "7  Classifier",
    "section": "7.2 Pre-processing",
    "text": "7.2 Pre-processing\nFirst, we transform \\(Y\\) into a binary variable:\n\nmed &lt;- median(df_race$Y)\ndf_race_c &lt;- df_race |&gt; \n  mutate(\n    Y_c = ifelse(Y &gt; med, 1, 0)\n  ) |&gt; \n  select(S, X1, X2, Y = Y_c)\n\nWe turn the response variable to a factor:\n\ndf_race_c$Y &lt;- as.factor(df_race_c$Y)\nlevels(df_race_c$Y)\n\n[1] \"0\" \"1\"\n\n\nLet us split the dataset into train/test sets (we use the split_dataset() function defined in our small package):\n\nlibrary(devtools)\n\nLoading required package: usethis\n\nload_all(\"../seqtransfairness/\") # load the functions from our package\n\nℹ Loading seqtransfairness\n\nseed &lt;- 2025\nsets &lt;- split_dataset(df_race_c, seed)\ndata_train &lt;- sets$data_train\ndata_test &lt;- sets$data_test",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classifier</span>"
    ]
  },
  {
    "objectID": "classifier.html#training-the-model",
    "href": "classifier.html#training-the-model",
    "title": "7  Classifier",
    "section": "7.3 Training the Model",
    "text": "7.3 Training the Model\nThen, we train two models:\n\nunaware logistic regression classifier: model without including the sensitive attribute.\naware logistic regression classifier: model with the sensitive attribute included in the set of features.\n\nThe model is trained using the log_reg_train() function defined in our small package.\n\nlog_reg_train\n\nfunction(train_data,\n                          test_data,\n                          s,\n                          y,\n                          type = c(\"aware\", \"unaware\")) {\n  if (type == \"unaware\") {\n    train_data_ &lt;- train_data |&gt; select(-!!s)\n    test_data_ &lt;- test_data |&gt; select(-!!s)\n  } else {\n    train_data_ &lt;- train_data\n    test_data_ &lt;- test_data\n  }\n  # Train the logistic regression model\n  form &lt;- paste0(y, \"~.\")\n  model &lt;- glm(as.formula(form), data = train_data_, family = binomial)\n  # Predictions on train and test sets\n  pred_train &lt;- predict(model, newdata = train_data_, type = \"response\")\n  pred_test &lt;- predict(model, newdata = test_data_, type = \"response\")\n  list(\n    model = model,\n    pred_train = pred_train,\n    pred_test = pred_test\n  )\n}\n&lt;environment: namespace:seqtransfairness&gt;\n\n\nLet us train the two models. Then, we extract the predicted values on both the train set and the test set.\n\n# Unaware logistic regression classifier (model without S)\npred_unaware &lt;- log_reg_train(\n  data_train, data_test, type = \"unaware\", s = \"S\", y = \"Y\"\n)\npred_unaware_train &lt;- pred_unaware$pred_train\npred_unaware_test &lt;- pred_unaware$pred_test\n\n# Aware logistic regression classifier (model with S)\npred_aware &lt;- log_reg_train(\n  data_train, data_test, type = \"aware\", s = \"S\", y = \"Y\"\n)\npred_aware_train &lt;- pred_aware$pred_train\npred_aware_test &lt;- pred_aware$pred_test\n\nWe create a table for each model, with the sensitive attribute and the predicted value by the model (\\(\\hat{y}\\)), only for observations from the test set.\n\ndf_test_unaware &lt;- tibble(\n  S = data_test$S, \n  pred = pred_unaware_test\n)\n\ndf_test_aware &lt;- tibble(\n  S = data_test$S, \n  pred = pred_aware_test\n)\n\n\nUnawareAware\n\n\n\n\nCodes to create the Figure.\nggplot(\n  data = df_test_unaware, \n  mapping = aes(x = pred, fill = S)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    \"S\", values = c(\n      \"Black\" = colours_all[[\"source\"]],\n      \"White\" = colours_all[[\"reference\"]]),\n  ) +\n  labs(\n    title = \"Unaware Model, with S being Race\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 7.1: Density of predictions on the test set, for the unaware model, when the sensitive attribute is the race\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\nggplot(\n  data = df_test_aware,\n  mapping = aes(x = pred, fill = S)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    \"S\", values = c(\n      \"Black\" = colours_all[[\"source\"]],\n      \"White\" = colours_all[[\"reference\"]]),\n  ) +\n  labs(\n    title = \"Aware Model, with S being Race\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 7.2: Density of predictions on the test set, for the aware model, when the sensitive attribute is the race",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classifier</span>"
    ]
  },
  {
    "objectID": "classifier.html#predictions",
    "href": "classifier.html#predictions",
    "title": "7  Classifier",
    "section": "7.4 Predictions",
    "text": "7.4 Predictions\nWe predict values with the unaware model on the factuals:\n\nmodel_unaware &lt;- pred_unaware$model\npred_unaware_all &lt;- predict(\n  model_unaware, \n  newdata = df_race_c |&gt; select(S, X1, X2), \n  type = \"response\"\n)\n\nAnd with the aware model:\n\nmodel_aware &lt;- pred_aware$model\npred_aware_all &lt;- predict(\n  model_aware, \n  newdata = df_race_c |&gt; select(S, X1, X2), \n  type = \"response\"\n)",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classifier</span>"
    ]
  },
  {
    "objectID": "classifier.html#sec-classifier-save",
    "href": "classifier.html#sec-classifier-save",
    "title": "7  Classifier",
    "section": "7.5 Saving Objects",
    "text": "7.5 Saving Objects\n\nsave(df_race_c, file = \"../data/df_race_c.rda\")\nsave(pred_aware, file = \"../data/pred_aware.rda\")\nsave(pred_unaware, file = \"../data/pred_unaware.rda\")\nsave(pred_unaware_all, file = \"../data/pred_unaware_all.rda\")\nsave(pred_aware_all, file = \"../data/pred_aware_all.rda\")\n\n\n\n\n\nBlack, Emily, Samuel Yeom, and Matt Fredrikson. 2020. “Fliptest: Fairness Testing via Optimal Transport.” In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 111–21.\n\n\nKusner, Matt J, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. “Counterfactual Fairness.” In Advances in Neural Information Processing Systems 30, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 4066–76. NIPS.\n\n\nPlečko, Drago, Nicolas Bennett, and Nicolai Meinshausen. 2021. “Fairadapt: Causal Reasoning for Fair Data Pre-Processing.” arXiv Preprint arXiv:2110.10200.",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classifier</span>"
    ]
  },
  {
    "objectID": "cf-naive.html",
    "href": "cf-naive.html",
    "title": "8  Naive Approach",
    "section": "",
    "text": "8.1 Load Data and Classifier\nWe load the dataset where the sensitive attribute ((S)) is the race, obtained Chapter 6.3:\nload(\"../data/df_race.rda\")\nWe also load the dataset where the sensitive attribute is also the race, but where where the target variable ((Y), ZFYA) is binary (1 if the student obtained a standardized first year average over the median, 0 otherwise). This dataset was saved in Chapter 7.5:\nload(\"../data/df_race_c.rda\")\nWe also need the predictions made by the classifier (see Chapter 7):\n# Predictions on train/test sets\nload(\"../data/pred_aware.rda\")\nload(\"../data/pred_unaware.rda\")\n# Predictions on the factuals, on the whole dataset\nload(\"../data/pred_aware_all.rda\")\nload(\"../data/pred_unaware_all.rda\")",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Naive Approach</span>"
    ]
  },
  {
    "objectID": "cf-naive.html#counterfactuals-with-the-naive-approach",
    "href": "cf-naive.html#counterfactuals-with-the-naive-approach",
    "title": "8  Naive Approach",
    "section": "8.2 Counterfactuals with the Naive Approach",
    "text": "8.2 Counterfactuals with the Naive Approach\nWe begin with the reference class being Black individuals (minority group). We set the sensitive variable (race) of Black individuals into the value of the majority group, i.e., White.\n\nmodel_unaware &lt;- pred_unaware$model\npred_unaware_naive_black &lt;- predict(\n  model_unaware, \n  newdata = df_race_c |&gt; select(S, X1, X2) |&gt; filter(S == \"Black\") |&gt; mutate(S = \"White\"), \n  type = \"response\"\n)\n\nmodel_aware &lt;- pred_aware$model\npred_aware_naive_black &lt;- predict(\n  model_aware, \n  newdata = df_race_c |&gt; select(S, X1, X2) |&gt; filter(S == \"Black\") |&gt;  mutate(S = \"White\"), \n  type = \"response\"\n)\n\nWe build two tables, one for the unaware model, the other for the aware model, with the predicted values using the naive version of the counterfactuals.\n\ncounterfactuals_unaware_naive_black &lt;- \n  df_race_c |&gt; \n  filter(S == \"Black\") |&gt; \n  mutate(\n    S_origin = S,\n    S = \"White\",\n    pred = pred_unaware_naive_black,\n    type = \"counterfactual\"\n  ) |&gt; \n  mutate(id_indiv = row_number())\n\ncounterfactuals_aware_naive_black &lt;- \n  df_race_c |&gt; \n  filter(S == \"Black\") |&gt; \n  mutate(\n    S_origin = S,\n    S = \"White\",\n    pred = pred_aware_naive_black,\n    type = \"counterfactual\"\n  ) |&gt; \n  mutate(id_indiv = row_number())\n\n\n8.2.1 Unaware Model\nThe predicted values using the initial characteristics (the factuals), for the unaware model are stored in the object pred_unaware_all. We put in a table the initial characteristics (factuals) and the prediction made by the unaware model:\n\nfactuals_unaware &lt;- tibble(\n  S = df_race_c$S,\n  S_origin = df_race_c$S,\n  X1 = df_race_c$X1,\n  X2 = df_race_c$X2,\n  Y = df_race_c$Y,\n  pred = pred_unaware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\n\nunaware_naive_black &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_unaware_naive_black)\n\nThe unaware model is blind to the sensitive attribute. Hence, changing the sensitive attribute does not affect the predicted scores.\n\n\nCodes used to create the Figure.\nggplot(\n  unaware_naive_black |&gt; mutate(\n    group = case_when(\n      S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n      S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n      S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n      )\n    )\n  ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 8.1: Unaware model, Sensitive: Race, Black -&gt; White\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_naive_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 8.2: Distribution of Predicted Scores for Minority Class (Black), Unaware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n8.2.2 Aware Model\nNow, we turn to the model that includes the sensitive attribute, i.e., the aware model.\nWe create a tibble with the factuals and the predictions by the aware model:\n\nfactuals_aware &lt;- tibble(\n  S = df_race_c$S,\n  S_origin = df_race_c$S,\n  X1 = df_race_c$X1,\n  X2 = df_race_c$X2,\n  Y = df_race_c$Y,\n  pred = pred_aware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\n\naware_naive_black &lt;- \n  factuals_aware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_naive_black)\n\n\n\nCodes used to create the Figure.\nggplot(\n  aware_naive_black |&gt; mutate(\n    group = case_when(\n      S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n      S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n      S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n      )\n    )\n  ),\n  aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), alpha = 0.5,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  facet_wrap(~S) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 8.3: Aware model, Sensitive: Race, Black -&gt; White\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_naive_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 8.4: Distribution of Predicted Scores for Minority Class (Black), Aware model, Sensitive: Race, Black -&gt; White",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Naive Approach</span>"
    ]
  },
  {
    "objectID": "cf-naive.html#sec-cf-fairadapt-save",
    "href": "cf-naive.html#sec-cf-fairadapt-save",
    "title": "8  Naive Approach",
    "section": "8.3 Saving Objects",
    "text": "8.3 Saving Objects\n\nsave(counterfactuals_unaware_naive_black, \n     file = \"../data/counterfactuals_unaware_naive_black.rda\")\nsave(counterfactuals_aware_naive_black, \n     file = \"../data/counterfactuals_aware_naive_black.rda\")",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Naive Approach</span>"
    ]
  },
  {
    "objectID": "cf-fairadapt.html",
    "href": "cf-fairadapt.html",
    "title": "9  Fairadapt",
    "section": "",
    "text": "9.1 Load Data and Classifier\nWe load the dataset where the sensitive attribute ((S)) is the race, obtained Chapter 6.3:\nload(\"../data/df_race.rda\")\nWe also load the dataset where the sensitive attribute is also the race, but where where the target variable ((Y), ZFYA) is binary (1 if the student obtained a standardized first year average over the median, 0 otherwise). This dataset was saved in Chapter 7.5:\nload(\"../data/df_race_c.rda\")\nWe also need the predictions made by the classifier (see Chapter 7):\n# Predictions on train/test sets\nload(\"../data/pred_aware.rda\")\nload(\"../data/pred_unaware.rda\")\n# Predictions on the factuals, on the whole dataset\nload(\"../data/pred_aware_all.rda\")\nload(\"../data/pred_unaware_all.rda\")\nWe load the adjacency matrix that translates the assumed causal structure, obtained in Chapter 6.3:\nload(\"../data/adj.rda\")",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Fairadapt</span>"
    ]
  },
  {
    "objectID": "cf-fairadapt.html#counterfactuals-with-fairadapt",
    "href": "cf-fairadapt.html#counterfactuals-with-fairadapt",
    "title": "9  Fairadapt",
    "section": "9.2 Counterfactuals with fairadapt",
    "text": "9.2 Counterfactuals with fairadapt\nWe adapt the code from Plečko, Bennett, and Meinshausen (2021) to handle the test set. This avoids estimating cumulative distribution and quantile functions on the test set, which would otherwise necessitate recalculating quantile regression functions for each new sample.\nWe do not need to adapt Y here, so we need to remove it from the adjacency matrix:\n\nadj_wo_Y &lt;- adj[-4,-4]\nadj_wo_Y\n\n   S X1 X2\nS  0  1  1\nX1 0  0  1\nX2 0  0  0\n\n\nWe create a dataset with the sensitive attribute and the two other predictors:\n\ndf_race_fpt &lt;- df_race_c |&gt; select(S, X1, X2)\n\nLet us have a look at the levels of our sensitive variable:\n\nlevels(df_race_fpt$S)\n\n[1] \"Black\" \"White\"\n\n\nThe reference class here consists of Black individuals.\nTwo configurations will be considered in turn:\n\nThe reference class consists of Black individuals, and FairAdapt will be used to obtain the counterfactual UGPA and LSAT scores for White individuals as if they had been Black.\nThe reference class consists of White individuals, and FairAdapt will be used to obtain the counterfactual UGPA and LSAT scores for Black individuals as if they had been White.\n\n\n# White (factuals) --&gt; Black (counterfactuals)\nfpt_model_white &lt;- fairadapt(\n  X2 ~ ., \n  train.data = df_race_fpt,\n  prot.attr = \"S\", adj.mat = adj_wo_Y,\n  quant.method = linearQuants\n)\nadapt_df_white &lt;- adaptedData(fpt_model_white)\n\n# Black (factuals) --&gt; White (counterfactuals)\ndf_race_fpt$S &lt;- factor(df_race_fpt$S, levels = c(\"White\", \"Black\"))\nfpt_model_black &lt;- fairadapt(\n  X2 ~ ., \n  train.data = df_race_fpt,\n  prot.attr = \"S\", adj.mat = adj_wo_Y,\n  quant.method = linearQuants\n)\nadapt_df_black &lt;- adaptedData(fpt_model_black)\n\nLet us wrap up:\n\nwe have two predictive models for the FYA (above median = 1, or below median = 0):\n\nunaware (without S)\naware (with S)\n\nwe have the counterfactual characteristics obtained with fairadapt in two situations depending on the reference class:\n\nBlack individuals as reference\nWhite individuals as reference.\n\n\nThe predictive models will be used to compare predictions made using:\n\nRaw characteristics (initial characteristics).\nCharacteristics possibly altered through fairadapt for individuals who were not in the reference group (i.e., using counterfactuals).\n\n\n9.2.1 Unaware Model\nThe predicted values using the initial characteristics (the factuals), for the unaware model are stored in the object pred_unaware_all. We put in a table the initial characteristics (factuals) and the prediction made by the unaware model:\n\nfactuals_unaware &lt;- tibble(\n  S = df_race_c$S,\n  X1 = df_race_c$X1,\n  X2 = df_race_c$X2,\n  pred = pred_unaware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\nLet us save this dataset in a csv file (this file will be used to perform multivariate transport in python).\n\nwrite.csv(\n  factuals_unaware, \n  file = \"../data/factuals_unaware.csv\", row.names = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nLet us get the predicted values for the counterfactuals, using the unaware model:\n\nind_black &lt;- which(df_race_c$S == \"Black\")\nind_white &lt;- which(df_race_c$S == \"White\")\n\nmodel_unaware &lt;- pred_unaware$model\npred_unaware_fpt_black &lt;- predict(\n  model_unaware, \n  newdata = adapt_df_black[ind_black, ], \n  type = \"response\"\n)\npred_unaware_fpt_white &lt;- predict(\n  model_unaware, \n  newdata = adapt_df_white[ind_white, ],\n  type = \"response\"\n)\n\nWe create a table with the counterfactual characteristics and the prediction by the unaware model:\n\ncounterfactuals_unaware_fpt_black &lt;- \n  as_tibble(adapt_df_black[ind_black, ]) |&gt; \n  mutate(\n    S_origin = df_race_c$S[ind_black],\n    pred = pred_unaware_fpt_black,\n    type = \"counterfactual\",\n    id_indiv = ind_black\n  )\n\ncounterfactuals_unaware_fpt_white &lt;- \n  as_tibble(adapt_df_white[ind_white, ]) |&gt; \n  mutate(\n    S_origin = df_race_c$S[ind_white],\n    pred = pred_unaware_fpt_white,\n    type = \"counterfactual\",\n    id_indiv = ind_white\n  )\n\nWe merge the two datasets, factuals_unaware and counterfactuals_unaware_fpt in a single one.\n\n# dataset with counterfactuals, for unaware model\nunaware_fpt_black &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_unaware_fpt_black)\n  \nunaware_fpt_white &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_unaware_fpt_white)\n\nNow, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.1: Unaware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.2: Unaware model, Sensitive: Race, Reference: Black individuals\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.3: Distribution of Predicted Scores for Minority Class (Black), Unaware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"White\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.4: Distribution of Predicted Scores for Minority Class (White), Unaware model, Sensitive: Race, Reference: Black individuals\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.2 Aware Model\nNow, we turn to the model that includes the sensitive attribute, i.e., the aware model.\nThe predicted values by the model, on the initial characteristics (on the factuals) are stored in the pred_aware_all object.\nWe create a tibble with the factuals and the predictions by the aware model:\n\nfactuals_aware &lt;- tibble(\n  S = df_race$S,\n  X1 = df_race$X1,\n  X2 = df_race$X2,\n  pred = pred_aware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\nLet us save this table in a CSV file (this file will be used to perform multivariate transport in python):\n\nwrite.csv(\n  factuals_aware, file = \"../data/factuals_aware.csv\", row.names = FALSE\n)\n\nLet us get the predicted values for the counterfactuals, using the aware model:\n\nmodel_aware &lt;- pred_aware$model\npred_aware_fpt_black &lt;- predict(\n  model_aware, \n  newdata = adapt_df_black[ind_black, ], \n  type = \"response\"\n)\npred_aware_fpt_white &lt;- predict(\n  model_aware, \n  newdata = adapt_df_white[ind_white, ],\n  type = \"response\"\n)\n\nWe create a table with the counterfactual characteristics and the prediction by the aware model:\n\ncounterfactuals_aware_fpt_black &lt;- \n  as_tibble(adapt_df_black[ind_black, ]) |&gt; \n  mutate(\n    S_origin = df_race_c$S[ind_black],\n    pred = pred_aware_fpt_black,\n    type = \"counterfactual\",\n    id_indiv = ind_black\n  )\n\ncounterfactuals_aware_fpt_white &lt;- \n  as_tibble(adapt_df_white[ind_white, ]) |&gt; \n  mutate(\n    S_origin = df_race_c$S[ind_white],\n    pred = pred_aware_fpt_white,\n    type = \"counterfactual\",\n    id_indiv = ind_white\n  )\n\nWe merge the two datasets, factuals_unaware and counterfactuals_aware_fpt in a single one.\n\n# dataset with counterfactuals, for aware model\naware_fpt_black &lt;- \n  factuals_aware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_fpt_black)\n  \naware_fpt_white &lt;- \n  factuals_aware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_fpt_white)\n\nNow, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.5: Aware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.6: Aware model, Sensitive: Race, Reference: Black individuals\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.7: Distribution of Predicted Scores for Minority Class (Black), Aware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"White\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 9.8: Distribution of Predicted Scores for Minority Class (White), Aware model, Sensitive: Race, Reference: Black individuals",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Fairadapt</span>"
    ]
  },
  {
    "objectID": "cf-fairadapt.html#comparison-for-two-individuals",
    "href": "cf-fairadapt.html#comparison-for-two-individuals",
    "title": "9  Fairadapt",
    "section": "9.3 Comparison for Two Individuals",
    "text": "9.3 Comparison for Two Individuals\nLet us focus on two individuals: the 24th (Black) and the 25th (White) of the dataset.\n\n(indiv_factuals_unaware &lt;- factuals_unaware |&gt; filter(id_indiv %in% c(24, 25)))\n\n# A tibble: 2 × 6\n  S        X1    X2  pred type    id_indiv\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;\n1 Black   2.8    29 0.300 factual       24\n2 White   2.8    34 0.382 factual       25\n\n\nThe characteristics of these two individuals would be, according to what was estimated using fairadapt, if the reference group was the one in which they do not belong:\n\nindiv_counterfactuals_unaware_fpt &lt;- \n   counterfactuals_unaware_fpt_black |&gt; filter(id_indiv %in% c(24)) |&gt; \n  bind_rows(\n    counterfactuals_unaware_fpt_white |&gt; filter(id_indiv %in% c(25))  \n  )\nindiv_counterfactuals_unaware_fpt  \n\n# A tibble: 2 × 7\n     X2 S        X1 S_origin  pred type           id_indiv\n  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt;\n1  37.6 White  3.25 Black    0.509 counterfactual       24\n2  26   Black  2.5  White    0.225 counterfactual       25\n\n\nWe put the factuals and counterfactuals in a single table:\n\nindiv_unaware_fpt &lt;- bind_rows(\n  indiv_factuals_unaware,\n  indiv_counterfactuals_unaware_fpt\n)\nindiv_unaware_fpt\n\n# A tibble: 4 × 7\n  S        X1    X2  pred type           id_indiv S_origin\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt; &lt;fct&gt;   \n1 Black  2.8   29   0.300 factual              24 &lt;NA&gt;    \n2 White  2.8   34   0.382 factual              25 &lt;NA&gt;    \n3 White  3.25  37.6 0.509 counterfactual       24 Black   \n4 Black  2.5   26   0.225 counterfactual       25 White   \n\n\nThe difference between the counterfactual and the factual for these two individuals:\n\nindiv_unaware_fpt |&gt; select(id_indiv , type, pred) |&gt; \n  pivot_wider(names_from = type, values_from = pred) |&gt; \n  mutate(diff_fpt = counterfactual - factual)\n\n# A tibble: 2 × 4\n  id_indiv factual counterfactual diff_fpt\n     &lt;int&gt;   &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n1       24   0.300          0.509    0.209\n2       25   0.382          0.225   -0.157\n\n\nWe apply the same procedure with the aware model:\n\nindiv_aware_fpt &lt;- bind_rows(\n  factuals_aware |&gt; filter(id_indiv %in% c(24, 25)),\n  counterfactuals_aware_fpt_black |&gt; filter(id_indiv == 24),\n  counterfactuals_aware_fpt_white |&gt; filter(id_indiv == 25)\n)\nindiv_aware_fpt\n\n# A tibble: 4 × 7\n  S        X1    X2   pred type           id_indiv S_origin\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt; &lt;fct&gt;   \n1 Black  2.8   29   0.133  factual              24 &lt;NA&gt;    \n2 White  2.8   34   0.413  factual              25 &lt;NA&gt;    \n3 White  3.25  37.6 0.522  counterfactual       24 Black   \n4 Black  2.5   26   0.0991 counterfactual       25 White   \n\n\nThe difference between the counterfactual and the factual for these two individuals, when using the aware model:\n\nindiv_aware_fpt |&gt; select(id_indiv , type, pred) |&gt; \n  pivot_wider(names_from = type, values_from = pred) |&gt; \n  mutate(diff = counterfactual - factual)\n\n# A tibble: 2 × 4\n  id_indiv factual counterfactual   diff\n     &lt;int&gt;   &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt;\n1       24   0.133         0.522   0.389\n2       25   0.413         0.0991 -0.314",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Fairadapt</span>"
    ]
  },
  {
    "objectID": "cf-fairadapt.html#sec-cf-fairadapt-save",
    "href": "cf-fairadapt.html#sec-cf-fairadapt-save",
    "title": "9  Fairadapt",
    "section": "9.4 Saving Objects",
    "text": "9.4 Saving Objects\n\nsave(factuals_unaware, file = \"../data/factuals_unaware.rda\")\nsave(factuals_aware, file = \"../data/factuals_aware.rda\")\nsave(counterfactuals_unaware_fpt_black, file = \"../data/counterfactuals_unaware_fpt_black.rda\")\nsave(counterfactuals_aware_fpt_black, file = \"../data/counterfactuals_aware_fpt_black.rda\")\n\n\n\n\n\nPlečko, Drago, Nicolas Bennett, and Nicolai Meinshausen. 2021. “Fairadapt: Causal Reasoning for Fair Data Pre-Processing.” arXiv Preprint arXiv:2110.10200.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data Adaptation with Quantile Preservation.” Journal of Machine Learning Research 21 (242): 1–44.",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Fairadapt</span>"
    ]
  },
  {
    "objectID": "cf-ot.html",
    "href": "cf-ot.html",
    "title": "10  Multivariate Optimal Transport",
    "section": "",
    "text": "10.1 Load Data and Classifier\nWe load the dataset where the sensitive attribute ((S)) is the race, obtained Chapter 6.3:\nload(\"../data/df_race.rda\")\nWe also load the dataset where the sensitive attribute is also the race, but where where the target variable ((Y), ZFYA) is binary (1 if the student obtained a standardized first year average over the median, 0 otherwise). This dataset was saved in Chapter 7.5:\nload(\"../data/df_race_c.rda\")\nWe also need the predictions made by the classifier (see Chapter 7):\n# Predictions on train/test sets\nload(\"../data/pred_aware.rda\")\nload(\"../data/pred_unaware.rda\")\n# Predictions on the factuals, on the whole dataset\nload(\"../data/pred_aware_all.rda\")\nload(\"../data/pred_unaware_all.rda\")",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Multivariate Optimal Transport</span>"
    ]
  },
  {
    "objectID": "cf-ot.html#counterfactuals-with-multivariate-optimal-transport",
    "href": "cf-ot.html#counterfactuals-with-multivariate-optimal-transport",
    "title": "10  Multivariate Optimal Transport",
    "section": "10.2 Counterfactuals with Multivariate Optimal Transport",
    "text": "10.2 Counterfactuals with Multivariate Optimal Transport\nWe apply multivariate optimal transport (OT), following the methodology developed in De Lara et al. (2024). Note that with OT, it is not possible to handle new cases. Counterfactuals will only be calculated on the train set.\nThe codes are run in python. We use the {reticulate} R package to call python in this notebook.\n\nlibrary(reticulate)\nuse_virtualenv(\"~/quarto-python-env\", required = TRUE)\n# reticulate::install_miniconda(force = TRUE)\n# py_install(\"POT\")\n\nSome libraries need to be loaded (including POT called ot)\n\nimport ot\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pl\nimport ot.plot\n\nThe data with the factuals need to be loaded:\n\ndf_aware = pd.read_csv('../data/factuals_aware.csv')\ndf_unaware = pd.read_csv('../data/factuals_unaware.csv')\n\n\nx_S = df_aware.drop(columns=['pred', 'type', 'id_indiv'])\nx_S.head()\n\n       S   X1    X2\n0  White  3.1  39.0\n1  White  3.0  36.0\n2  White  3.1  30.0\n3  White  3.4  37.0\n4  White  3.6  30.5\n\n\n\nx_white = x_S[x_S['S'] == 'White']\nx_white = x_white.drop(columns=['S'])\nx_black = x_S[x_S['S'] == 'Black']\nx_black = x_black.drop(columns=['S'])\n\nn_white = len(x_white)\nn_black = len(x_black)\n# Uniform weights\nw_white = (1/n_white)*np.ones(n_white)\nw_black = (1/n_black)*np.ones(n_black)\n\nCost matrix between both distributions:\n\nx_white = x_white.to_numpy()\nx_black = x_black.to_numpy()\nC = ot.dist(x_white, x_black)\n\n\npl.figure(1)\npl.plot(x_white[:, 0], x_white[:, 1], '+b', label='Source samples')\npl.plot(x_black[:, 0], x_black[:, 1], 'xr', label='Target samples')\npl.legend(loc=0)\npl.title('Source and target distributions')\n\n\n\n\nFigure 10.1: Source and target distributions\n\n\n\n\n\n\n\n\n\npl.figure(2)\npl.imshow(C, interpolation='nearest')\npl.title('Cost matrix C')\n\n\n\n\nFigure 10.2: Cost matric C\n\n\n\n\n\n\n\n\nThe transport plan: white –&gt; black\n\npi_white_black = ot.emd(w_white, w_black, C, numItermax=1e8)\npi_black_white = pi_white_black.T\npi_white_black.shape\n\n(18285, 1282)\n\n\n\nsum_of_rows = np.sum(pi_white_black, axis=1)\nsum_of_rows*n_white\n\narray([1., 1., 1., ..., 1., 1., 1.], shape=(18285,))\n\n\n\npi_black_white.shape\n\n(1282, 18285)\n\nsum_of_rows = np.sum(pi_black_white, axis=1)\nsum_of_rows*n_black\n\narray([1., 1., 1., ..., 1., 1., 1.], shape=(1282,))\n\n\n\npl.figure(3)\npl.imshow(pi_white_black, interpolation='nearest')\npl.title('OT matrix pi_white_black')\n\npl.figure(4)\not.plot.plot2D_samples_mat(x_white, x_black, pi_white_black, c=[.5, .5, 1])\npl.plot(x_white[:, 0], x_white[:, 1], '+b', label='Source samples')\npl.plot(x_black[:, 0], x_black[:, 1], 'xr', label='Target samples')\npl.legend(loc=0)\npl.title('OT matrix with samples')\n\n\n\n\nFigure 10.3: OT matrix pi_white_black\n\n\n\n\n\n\n\n\n\ntransformed_x_white = n_white*pi_white_black@x_black\n\n\n\n\n\n\n\n\n\ntransformed_x_white.shape\n\n(18285, 2)\n\n\n\ntransformed_x_white\n\narray([[ 2.7, 31. ],\n       [ 2.7, 28. ],\n       [ 2.6, 21. ],\n       ...,\n       [ 3.9, 28. ],\n       [ 2.5, 22. ],\n       [ 3. , 19. ]], shape=(18285, 2))\n\n\n\ntransformed_x_black = n_black*pi_black_white@x_white\n\n\ntransformed_x_black.shape\n\n(1282, 2)\n\n\n\ntransformed_x_black\n\narray([[ 3.2       , 37.58851518],\n       [ 3.28565491, 28.02103363],\n       [ 2.95793273, 32.14022423],\n       ...,\n       [ 3.28597758, 33.        ],\n       [ 2.65092152, 41.43910309],\n       [ 2.75152858, 36.        ]], shape=(1282, 2))\n\n\n\ncounterfactual_x = x_S.drop(columns=['S'])\ncounterfactual_x[x_S['S'] == 'White'] = transformed_x_white\ncounterfactual_x[x_S['S'] == 'Black'] = transformed_x_black\n\n\ncounterfactual_x.head()\n\n    X1    X2\n0  2.7  31.0\n1  2.7  28.0\n2  2.6  21.0\n3  3.1  28.0\n4  3.2  21.0\n\n\n\ncounterfactual_x.shape\n\n(19567, 2)\n\n\n\ntransformed_x_white\n\narray([[ 2.7, 31. ],\n       [ 2.7, 28. ],\n       [ 2.6, 21. ],\n       ...,\n       [ 3.9, 28. ],\n       [ 2.5, 22. ],\n       [ 3. , 19. ]], shape=(18285, 2))\n\n\nLastly, we export the results in a CSV file:\n\ncsv_file_path = '../data/counterfactuals_ot.csv'\ncounterfactual_x.to_csv(csv_file_path, index=False)\n\nLet us get back to R, and load the results.\n\ncounterfactuals_ot &lt;- read_csv('../data/counterfactuals_ot.csv') |&gt; \n  mutate(id_indiv = row_number())\n\nWe add the sensitive attribute to the dataset (Black individuals become White, and conversely):\n\nS_star &lt;- df_race_c |&gt; \n  mutate(\n    S_star = case_when(\n      S == \"Black\" ~ \"White\",\n      S == \"White\" ~ \"Black\",\n      TRUE ~ \"Error\"\n    )\n  ) |&gt; \n  pull(\"S_star\")\n\ncounterfactuals_ot &lt;- counterfactuals_ot |&gt; \n  mutate(\n    S_origin = df_race_c$S,\n    S = S_star\n  )\n\n\ncounterfactuals_ot_black &lt;- \n  counterfactuals_ot |&gt; filter(S_origin == \"Black\") |&gt; \n  bind_rows(\n    df_race_c |&gt; select(-Y) |&gt; \n      mutate(\n        id_indiv = row_number(),\n        S_origin = S,\n        ) |&gt; \n      filter(S == \"White\")\n  ) |&gt; \n  arrange(id_indiv)\ncounterfactuals_ot_white &lt;- \n  counterfactuals_ot |&gt; filter(S_origin == \"White\") |&gt; \n  bind_rows(\n    df_race_c |&gt; select(-Y) |&gt; \n      mutate(\n        id_indiv = row_number(),\n        S_origin = S,\n        ) |&gt; \n      filter(S == \"Black\")\n  ) |&gt; \n  arrange(id_indiv)\n\nWe consider Black individuals (minority group) to be the source group. Let us make prediction with the unaware model, then with the aware model on the counterfactuals obtained with OT.\n\nmodel_unaware &lt;- pred_unaware$model\npred_unaware_ot_black &lt;- predict(\n  model_unaware, newdata = counterfactuals_ot_black, type = \"response\"\n)\ncounterfactuals_unaware_ot_black &lt;- counterfactuals_ot_black |&gt; \n  mutate(pred = pred_unaware_ot_black, type = \"counterfactual\")\n\nIf, instead, the source group is White:\n\npred_unaware_ot_white &lt;- predict(\n  model_unaware, newdata = counterfactuals_ot_white, type = \"response\"\n)\ncounterfactuals_unaware_ot_white &lt;- counterfactuals_ot_white |&gt; \n  mutate(pred = pred_unaware_ot_white, type = \"counterfactual\")\n\nWith the aware model, if Black is the source group:\n\nmodel_aware &lt;- pred_aware$model\npred_aware_ot_black &lt;- predict(\n  model_aware, newdata = counterfactuals_ot_black, type = \"response\"\n)\ncounterfactuals_aware_ot_black &lt;- counterfactuals_ot_black |&gt; \n  mutate(pred = pred_aware_ot_black, type = \"counterfactual\")\n\nIf, instead, the source group is White:\n\npred_aware_ot_white &lt;- predict(\n  model_aware, newdata = counterfactuals_ot_white, type = \"response\"\n)\ncounterfactuals_aware_ot_white &lt;- counterfactuals_ot_white |&gt; \n  mutate(pred = pred_aware_ot_white, type = \"counterfactual\")\n\nNext, we can compare predicted scores for both type of model and on the source group.\n\n10.2.1 Unaware Model\nThe predicted values using the initial characteristics (the factuals), for the unaware model are stored in the object pred_unaware_all. We put in a table the initial characteristics (factuals) and the prediction made by the unaware model:\n\nfactuals_unaware &lt;- tibble(\n  S = df_race_c$S,\n  S_origin = df_race_c$S,\n  X1 = df_race_c$X1,\n  X2 = df_race_c$X2,\n  Y = df_race_c$Y,\n  pred = pred_unaware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\nWe bind together the predictions made with the observed values and those made with the counterfactual values.\n\nunaware_ot_black &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_unaware_ot_black)\n\nunaware_ot_white &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_unaware_ot_white)\n\nNow, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_ot_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Unaware model, Sensitive: Race, Reference: White individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 10.4: Unaware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_ot_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Unaware model, Sensitive: Race, Reference: Black individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 10.5: Unaware model, Sensitive: Race, Reference: Black individuals\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_ot_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Predicted Scores for Minority Class\\n Unware model, Sensitive: Race, Reference: White individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 10.6: Distribution of Predicted Scores for Minority Class (Black), Unaware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_ot_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"White\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]]\n    )\n  ) +\n  labs(\n    title = \"Predicted Scores for Minority Class\\n Unware model, Sensitive: Race, Reference: Black individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 10.7: Distribution of Predicted Scores for Minority Class (White), Unaware model, Sensitive: Race, Reference: Black individuals\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.2.2 Aware Model\n\nfactuals_aware &lt;- tibble(\n  S = df_race_c$S,\n  S_origin = df_race_c$S,\n  X1 = df_race_c$X1,\n  X2 = df_race_c$X2,\n  Y = df_race_c$Y,\n  pred = pred_aware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\nWe bind together the predictions made with the observed values and those made with the counterfactual values.\n\naware_ot_black &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_ot_black)\n\naware_ot_white &lt;- \n  factuals_unaware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_ot_white)\n\nWe merge the two datasets, factuals_aware and counterfactuals_aware_ot in a single one.\n\n# dataset with counterfactuals, for aware model\naware_ot_black &lt;- \n  factuals_aware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_ot_black)\n\naware_ot_white &lt;- \n  factuals_aware |&gt; mutate(S_origin = S) |&gt; \n  bind_rows(counterfactuals_aware_ot_white)\n\nNow, we can visualize the distribution of the values predicted by the unaware model within each group defined by the sensitive attribute.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_ot_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Aware model, Sensitive: Race, Reference: White individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 10.8: Aware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_ot_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"Black (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Aware model, Sensitive: Race, Reference: Black individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 10.9: Aware model, Sensitive: Race, Reference: Black individuals\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\nBlack -&gt; WhiteWhite -&gt; Black\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_ot_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"ot\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    title = \"Predicted Scores for Minority Class\\n Unware model, Sensitive: Race, Reference: White individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 10.10: Distribution of Predicted Scores for Minority Class (Black), Aware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_ot_white |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\",\n        S_origin == \"White\" & S == \"Black\" ~ \"White -&gt; Black (Counterfactual)\",\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Black (Counterfactual)\", \"Black (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"White\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Black (Counterfactual)\" = colours_all[[\"ot\"]]\n    )\n  ) +\n  labs(\n    title = \"Predicted Scores for Minority Class\\n Unware model, Sensitive: Race, Reference: Black individuals\",\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme()\n\n\n\n\n\nFigure 10.11: Distribution of Predicted Scores for Minority Class (White), Aware model, Sensitive: Race, Reference: Black individuals",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Multivariate Optimal Transport</span>"
    ]
  },
  {
    "objectID": "cf-ot.html#sec-cf-fairadapt-save",
    "href": "cf-ot.html#sec-cf-fairadapt-save",
    "title": "10  Multivariate Optimal Transport",
    "section": "10.3 Saving Objects",
    "text": "10.3 Saving Objects\n\nsave(\n  counterfactuals_unaware_ot_black,\n  file = \"../data/counterfactuals_unaware_ot_black.rda\"\n)\nsave(\n  counterfactuals_aware_ot_black, \n  file = \"../data/counterfactuals_aware_ot_black.rda\"\n)\n\n\n\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser, and Jean-Michel Loubes. 2024. “Transport-Based Counterfactual Models.” Journal of Machine Learning Research 25 (136): 1–59.",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Multivariate Optimal Transport</span>"
    ]
  },
  {
    "objectID": "cf-seq-transport.html",
    "href": "cf-seq-transport.html",
    "title": "11  Sequential Transport",
    "section": "",
    "text": "11.1 Load Data and Classifier\nWe load the dataset where the sensitive attribute ((S)) is the race, obtained Chapter 6.3:\nload(\"../data/df_race.rda\")\nWe also load the dataset where the sensitive attribute is also the race, but where where the target variable ((Y), ZFYA) is binary (1 if the student obtained a standardized first year average over the median, 0 otherwise). This dataset was saved in Chapter 7.5:\nload(\"../data/df_race_c.rda\")\nWe also need the predictions made by the classifier (see Chapter 7):\n# Predictions on train/test sets\nload(\"../data/pred_aware.rda\")\nload(\"../data/pred_unaware.rda\")\n# Predictions on the factuals, on the whole dataset\nload(\"../data/pred_aware_all.rda\")\nload(\"../data/pred_unaware_all.rda\")",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Sequential Transport</span>"
    ]
  },
  {
    "objectID": "cf-seq-transport.html#counterfactuals-with-sequential-transport",
    "href": "cf-seq-transport.html#counterfactuals-with-sequential-transport",
    "title": "11  Sequential Transport",
    "section": "11.2 Counterfactuals with Sequential Transport",
    "text": "11.2 Counterfactuals with Sequential Transport\nWe now turn to sequential transport (the methodology developed in our paper). We define a function, seq_trans() (see in functions/utils.R) to perform a fast sequential transport on causal graph.\n\n\nR codes for functions seq_trans(), topological_ordering(), and swap()\n#' Sequential Transport Using a Pre-Defined Causal Graph\n#'\n#' The sensitive attribute, S, is assumed to be a binary variable with value\n#' $S_0$ in the source distribution and $S_1$ in the target distribution.\n#'\n#' @param data Data frame with the observations.\n#' @param adj Adjacency matrix for the causal graph.\n#' @param s Name of the sensitive attribute column in the data.\n#' @param S_0 Label of the sensitive attribute in the source distribution.\n#' @param y Name of the outcome variable in the data.\n#' @param num_neighbors Number of neighbors to use in the weighted quantile\n#'        estimation. Default to 5.\n#' @param silent If `TRUE`, the messages showing progress in the estimation are\n#'        not shown. Default to `silent=FALSE`.\n#'\n#' @returns A list with the following elements:\n#' * `transported`: A named list with the transported values. The names are those of the variables.\n#' * `weights`: A list with the weights of each observation in the two groups.\n#' * `ecdf`: A list with empirical distribution functions for numerical variables.\n#' * `ecdf_values`: A list with the values of the ecdf evaluated for each observation in the source distribution.\n#' * `fit_for_categ`: A list with the estimated multinomial models to predict categories using parents characteristics\n#' * `params`: A list with some parameters used to transport observations:\n#'     * `adj`: Adjacency matrix.\n#'     * `top_order`: Topological ordering.\n#'     * `s`: Name of the sensitive attribute.\n#'     * `S_0`: Label of the sensitive attribute in the source distribution.\n#'     * `y`: Name of the outcome variable in the data.\n#'     * `num_neighbors`: Number of neighbors used when computing quantiles.\n#' @md\n#' @export\n#'\n#' @importFrom stats predict ecdf quantile\n#' @importFrom dplyr across filter mutate pull select\n#' @importFrom tidyselect where\n#' @importFrom rlang sym !! := is_character\n#' @importFrom cluster daisy\n#' @importFrom Hmisc wtd.quantile\n#' @importFrom nnet multinom\nseq_trans &lt;- function(data,\n                      adj,\n                      s,\n                      S_0,\n                      y,\n                      num_neighbors = 5,\n                      silent = FALSE) {\n  # Make sure character variables are encoded as factors\n  data &lt;-\n    data |&gt;\n    mutate(across(where(is_character), ~as.factor(.x)))\n\n  # Topological ordering\n  top_order &lt;- topological_ordering(adj)\n  variables &lt;- top_order[!top_order %in% c(s, y)]\n  # Observations in group S_0\n  data_0 &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n  data_1 &lt;- data |&gt; filter(!!sym(s) != !!S_0)\n\n  # Lists where results will be stored\n  list_transported &lt;- list()  # Transported values\n  list_weights &lt;- list()      # Weights\n  list_ecdf &lt;- list()         # Empirical dist. function\n  list_ecdf_values &lt;- list()  # Evaluated values of the ecdf\n  fit_for_categ &lt;- list()     # Fitted multinomial models for categ. variables\n\n  for (x_name in variables) {\n    if (silent == FALSE) cat(\"Transporting \", x_name, \"\\n\")\n    # Names of the parent variables\n    parents &lt;- colnames(adj)[adj[, x_name] == 1]\n    # values of current x in each group\n    x_S0 &lt;- data_0 |&gt; pull(!!x_name)\n    x_S1 &lt;- data_1 |&gt; pull(!!x_name)\n    # Check whether X is numeric\n    is_x_num &lt;- is.numeric(x_S0)\n    # Characteristics of the parent variables (if any)\n    parents_characteristics &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\n\n    if (length(parents_characteristics) &gt; 0) {\n      data_0_parents &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\n      data_1_parents &lt;- data_1 |&gt; select(!!parents) |&gt; select(-!!s)\n      # Weights in S_0\n      weights_S0 &lt;- as.matrix(cluster::daisy(data_0_parents, metric = \"gower\"))\n      tot_weights_S0 &lt;- apply(weights_S0, MARGIN = 1, sum)\n      # Weights in S_1\n      # First, we need to get the transported values for the parents, if necessary\n      data_0_parents_t &lt;- data_0_parents #init\n      for (parent in parents) {\n        # does the parent depend on the sensitive variable\n        if (parent %in% names(list_transported)) {\n          data_0_parents_t &lt;-\n            data_0_parents_t |&gt;\n            mutate(!!sym(parent) := list_transported[[parent]])\n        }\n      }\n      # Unfortunately, we will compute a lot of distances not needed\n      combined &lt;- rbind(data_0_parents_t, data_1_parents)\n      gower_dist &lt;- cluster::daisy(combined, metric = \"gower\")\n      gower_matrix &lt;- as.matrix(gower_dist)\n      n_0 &lt;- nrow(data_0_parents_t)\n      n_1 &lt;- nrow(data_1_parents)\n      weights_S1 &lt;- gower_matrix[1:n_0, (n_0 + 1):(n_0 + n_1), drop = FALSE]\n      weights_S1 &lt;- weights_S1 + 1e-8\n      weights_S1 &lt;- 1 / (weights_S1)^2\n      tot_weights_S1 &lt;- apply(weights_S1, MARGIN = 1, sum)\n\n      if (is_x_num == TRUE) {\n        # Numerical variable to transport\n\n        # Empirical distribution function\n        f &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          f[i] &lt;- weights_S0[i, ] %*% (x_S0 &lt;= x_S0[i]) / tot_weights_S0[i]\n        }\n        list_ecdf_values[[x_name]] &lt;- f\n        f[f==1] &lt;- 1-(1e-8)\n\n        # Transported values\n        transported &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          wts &lt;- weights_S1[i, ]\n          wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n          transported[i] &lt;- Hmisc::wtd.quantile(\n              x = x_S1, weights = weights_S1[i, ], probs = f[i]\n            ) |&gt; suppressWarnings()\n        }\n      } else {\n        # X is non numeric and has parents\n\n        # Fit a model to predict the categorical variables given the\n        # characteristics of the parents in group to transport into\n        fit_indix_x &lt;- nnet::multinom(\n          x_S0 ~ .,\n          data = data_1_parents |&gt; mutate(x_S0 = x_S1)\n        )\n        # Predictions with that model for transported parents\n        pred_probs &lt;- predict(fit_indix_x, type = \"probs\", newdata = data_0_parents_t)\n        # For each observation, random draw of the class, using the pred probs\n        # as weights\n        drawn_class &lt;- apply(\n          pred_probs, 1,\n          function(x) sample(1:ncol(pred_probs), prob = x, size = 1)\n        )\n        transported &lt;- colnames(pred_probs)[drawn_class]\n        if (is.factor(x_S1)) {\n          transported &lt;- factor(transported, levels = levels(x_S1))\n        }\n        fit_for_categ[[x_name]] &lt;- fit_indix_x\n      }\n      list_transported[[x_name]] &lt;- transported\n\n      # Store weights for possible later use\n      list_weights[[x_name]] &lt;- list(\n        w_S0 = list(weights = weights_S0, tot_weights = tot_weights_S0),\n        w_S1 = list(weights = weights_S1, tot_weights = tot_weights_S1)\n      )\n    } else {\n      # No parents\n      if (is_x_num == TRUE) {\n        # X is numerical and has no parents\n        F_X_S0 &lt;- ecdf(x_S0)\n        list_ecdf[[x_name]] &lt;- F_X_S0\n        f &lt;- F_X_S0(x_S0)\n        list_ecdf_values[[x_name]] &lt;- f\n        transported &lt;- as.numeric(quantile(x_S1, probs = f))\n      } else {\n        # X is not numerical and has no parents\n        transported &lt;- sample(x_S1, size = length(x_S0), replace = TRUE)\n        if (is.factor(x_S1)) {\n          transported &lt;- factor(transported, levels = levels(x_S1))\n        } else {\n          transported &lt;- as.factor(transported)\n        }\n      }\n      list_transported[[x_name]] &lt;- transported\n    }\n  }\n\n  return(\n    list(\n      transported = list_transported,\n      weights = list_weights,\n      ecdf = list_ecdf,\n      ecdf_values = list_ecdf_values,\n      fit_for_categ = fit_for_categ,\n      params = list(\n        adj = adj,\n        top_order = top_order,\n        s = s,\n        S_0 = S_0,\n        y = y,\n        num_neighbors = num_neighbors\n      )\n    )\n  )\n}\n#' Topological Ordering\n#'\n#' @source This function comes from the fairadapt package. Drago Plecko,\n#'         Nicolai Meinshausen (2020). Fair data adaptation with quantile\n#'         preservation Journal of Machine Learning Research, 21.242, 1-44.\n#'         URL https://www.jmlr.org/papers/v21/19-966.html.\n#' @param adj_mat Adjacency matrix with names of the variables for both rows and\n#'        columns.\n#' @return A character vector (names of the variables) providing a topological\n#'         ordering.\n#' @export\ntopological_ordering &lt;- function(adj_mat) {\n  nrw &lt;- nrow(adj_mat)\n  num_walks &lt;- adj_mat\n  for (i in seq_len(nrw + 1L)) {\n    num_walks &lt;- adj_mat + num_walks %*% adj_mat\n  }\n  comparison_matrix &lt;- num_walks &gt; 0\n  top_order &lt;- colnames(adj_mat)\n  for (i in seq_len(nrw - 1L)) {\n    for (j in seq.int(i + 1L, nrw)) {\n      if (comparison_matrix[top_order[j], top_order[i]]) {\n        top_order &lt;- swap(top_order, i, j)\n      }\n    }\n  }\n  top_order\n}\n\n#' Swap Two Elements in a Matrix.\n#'\n#' @source This function comes from the fairadapt package. Drago Plecko,\n#'         Nicolai Meinshausen (2020). Fair data adaptation with quantile\n#'         preservation Journal of Machine Learning Research, 21.242, 1-44.\n#'         URL https://www.jmlr.org/papers/v21/19-966.html.\n#' @param x A matrix.\n#' @param i Index of the first element to swap.\n#' @param j Index of the second element to swap.\n#' @return The matrix x where the i-th and j-th elements have been swapped.\n#' @noRd\nswap &lt;- function(x, i, j) {\n  keep &lt;- x[i]\n  x[i] &lt;- x[j]\n  x[j] &lt;- keep\n  x\n}\n\n\nLet us apply this function, but first, we create a dataset, df_race_c_light, with the sensitive attribute and the two characteristics only:\n\ndf_race_c_light &lt;- df_race_c |&gt; select(S, X1, X2)\nind_white &lt;- which(df_race_c_light$S == \"White\")\nind_black &lt;- which(df_race_c_light$S == \"Black\")\n\nWe first transport \\(x_1\\), then \\(x_2\\), assuming that \\(x_1\\) is influenced by \\(S\\) only, \\(x_2\\) is influenced by both \\(S\\) and \\(x_1\\), and \\(Y\\) is influenced by \\(S\\), \\(x_1\\), and \\(x_2\\).\n\nvariables &lt;- c(\"S\", \"X1\", \"X2\", \"Y\")\n# X1, then X2\nadj_1 &lt;- matrix(\n  # S  X1 X2 Y\n  c(0, 1, 1, 1,# S\n    0, 0, 1, 1,# X1\n    0, 0, 0, 1,# X2\n    0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\n\ntrans_x1_then_x2 &lt;- seq_trans(\n  data = df_race_c, adj = adj_1, s = \"S\", S_0 = \"Black\", y = \"Y\"\n)\n\nTransporting  X1 \nTransporting  X2 \n\n\nThe values of \\(X_1\\) and \\(X_2\\) for Black individuals:\n\na10 &lt;- df_race_c_light$X1[ind_black]\na20 &lt;- df_race_c_light$X2[ind_black]\n\nThe transported values:\n\nx1_star &lt;- trans_x1_then_x2$transported$X1 # Transport X1 to group S=White\nx2_star &lt;- trans_x1_then_x2$transported$X2 # Transport X2|X1 to group S=White\n\nWe build a dataset with the sensitive attribute of Black individuals changed to white, and their characteristics changed to their transported characteristics:\n\ndf_counterfactuals_seq_black &lt;- \n  df_race_c_light |&gt; mutate(id_indiv= row_number()) |&gt; \n  filter(S == \"Black\") |&gt; \n  mutate(\n    S_origin = \"Black\",\n    S = \"White\",\n    X1 = x1_star,\n    X2 = x2_star\n  )\n\nWe make predictions based on those counterfactuals obtained with sequential transport, on both models (the unaware model, and the aware model):\n\nmodel_unaware &lt;- pred_unaware$model\npred_seq_unaware &lt;- predict(\n  model_unaware, newdata = df_counterfactuals_seq_black,type = \"response\"\n)\n\nmodel_aware &lt;- pred_aware$model\npred_seq_aware &lt;- predict(\n  model_aware, newdata = df_counterfactuals_seq_black,type = \"response\"\n)\n\n\ncounterfactuals_unaware_seq_black &lt;- \n  df_counterfactuals_seq_black |&gt; \n  mutate(pred = pred_seq_unaware, type = \"counterfactual\")\ncounterfactuals_aware_seq_black &lt;- \n  df_counterfactuals_seq_black |&gt; \n  mutate(pred = pred_seq_aware, type = \"counterfactual\")\n\nWe create a tibble with the factuals and the predictions by the aware model, an another with the predictions by the unaware model:\n\nfactuals_aware &lt;- tibble(\n  S = df_race$S,\n  X1 = df_race$X1,\n  X2 = df_race$X2,\n  pred = pred_aware_all,\n  type = \"factual\"\n)\n\nfactuals_unaware &lt;- tibble(\n  S = df_race$S,\n  X1 = df_race$X1,\n  X2 = df_race$X2,\n  pred = pred_unaware_all,\n  type = \"factual\"\n)\n\nLet us put in a single table the predictions made by the classifier (either aware or unaware) on Black and White individuals based on their factual characteristics, and those made based on the counterfactuals (i.e., only for Black individuals).\n\naware_seq_black &lt;- bind_rows(\n  factuals_aware |&gt; mutate(id_indiv = row_number(), S_origin = S), \n  counterfactuals_aware_seq_black |&gt; mutate(S_origin = \"Black\")\n)\nunaware_seq_black &lt;- bind_rows(\n  factuals_unaware |&gt; mutate(id_indiv = row_number(), S_origin = S), \n  counterfactuals_unaware_seq_black |&gt; mutate(S_origin = \"Black\")\n)\n\n\nUnawareAware\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_seq_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 11.1: Unaware model, Sensitive: Race, Black -&gt; White\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_seq_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~S) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 11.2: Aware model, Sensitive: Race, Black -&gt; White\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Black students and factuals of white students.\n\nUnawareAware\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_seq_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 11.3: Distribution of Predicted Scores for Minority Class (Black), Unaware model, Sensitive: Race, Black -&gt; White\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_seq_black |&gt; \n    mutate(\n      group = case_when(\n        S_origin == \"Black\" & S == \"Black\" ~ \"Black (Original)\",\n        S_origin == \"Black\" & S == \"White\" ~ \"Black -&gt; White (Counterfactual)\",\n        S_origin == \"White\" & S == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Black (Original)\", \"Black -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(S_origin == \"Black\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Black (Original)\" = colours_all[[\"source\"]],\n      \"Black -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 11.4: Distribution of Predicted Scores for Minority Class (Black), Aware model, Sensitive: Race, Black -&gt; White",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Sequential Transport</span>"
    ]
  },
  {
    "objectID": "cf-seq-transport.html#sec-cf-seq-t-save",
    "href": "cf-seq-transport.html#sec-cf-seq-t-save",
    "title": "11  Sequential Transport",
    "section": "11.3 Saving Objects",
    "text": "11.3 Saving Objects\n\nsave(\n  counterfactuals_unaware_seq_black, \n  file = \"../data/counterfactuals_unaware_seq_black.rda\"\n)\nsave(\n  counterfactuals_aware_seq_black, \n  file = \"../data/counterfactuals_aware_seq_black.rda\"\n)",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Sequential Transport</span>"
    ]
  },
  {
    "objectID": "cf-comparison.html",
    "href": "cf-comparison.html",
    "title": "12  Counterfactuals: comparison",
    "section": "",
    "text": "12.1 Load Data and Classifier\nWe load the dataset where the sensitive attribute ((S)) is the race, obtained Chapter 6.3:\nload(\"../data/df_race.rda\")\nNaive counterfactuals constructed when simply changing the sensitive attribute of individuals from the minority group, and predictions by the classifiers (see Chapter 8):\nload(\"../data/counterfactuals_aware_naive_black.rda\")\nload(\"../data/counterfactuals_unaware_naive_black.rda\")\nCounterfactuals constructed with fairadapt and predictions by the classifiers (see Chapter 9):\nload(\"../data/counterfactuals_aware_fpt_black.rda\")\nload(\"../data/counterfactuals_unaware_fpt_black.rda\")\nCounterfactuals constructed with multivariate optimal transport and predictions by the classifiers (see Chapter 10):\nload(\"../data/counterfactuals_aware_ot_black.rda\")\nload(\"../data/counterfactuals_unaware_ot_black.rda\")\nCounterfactuals constructed with sequential transport and predictions by the classifiers (see Chapter 11):\nload(\"../data/counterfactuals_aware_seq_black.rda\")\nload(\"../data/counterfactuals_unaware_seq_black.rda\")\nWe also need the predictions made by the classifier (see Chapter 7):\n# Predictions on train/test sets\nload(\"../data/pred_aware.rda\")\nload(\"../data/pred_unaware.rda\")\n# Predictions on the factuals, on the whole dataset\nload(\"../data/pred_aware_all.rda\")\nload(\"../data/pred_unaware_all.rda\")\nWe create a tibble with the factuals and the predictions by the aware model, an another with the predictions by the unaware model:\nfactuals_aware &lt;- tibble(\n  S = df_race$S,\n  S_origin = df_race$S,\n  X1 = df_race$X1,\n  X2 = df_race$X2,\n  pred = pred_aware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())\n\nfactuals_unaware &lt;- tibble(\n  S = df_race$S,\n  S_origin = df_race$S,\n  X1 = df_race$X1,\n  X2 = df_race$X2,\n  pred = pred_unaware_all,\n  type = \"factual\"\n) |&gt; \n  mutate(id_indiv = row_number())",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Counterfactuals: comparison</span>"
    ]
  },
  {
    "objectID": "cf-comparison.html#comparison",
    "href": "cf-comparison.html#comparison",
    "title": "12  Counterfactuals: comparison",
    "section": "12.2 Comparison",
    "text": "12.2 Comparison\nLet us focus on the first three Black individuals from the dataset. We will compare the predicted values by the classifier (see Chapter 7) made using the observed characteristics, and the changes in the predictions when using counterfactuals. We use the three types of counterfactuals explored in the previous chapters.\n\nUnaware ModelAware Model\n\n\n\ntb_unaware &lt;- \n  factuals_unaware |&gt; mutate(counterfactual = \"none\") |&gt;\n  # Naive\n  bind_rows(counterfactuals_unaware_naive_black |&gt; mutate(counterfactual = \"naive\")) |&gt; \n  # Multivariate optimal transport\n  bind_rows(counterfactuals_unaware_ot_black |&gt; mutate(counterfactual = \"ot\")) |&gt; \n  # Fairadapt\n  bind_rows(counterfactuals_unaware_fpt_black |&gt; mutate(counterfactual = \"fpt\")) |&gt; \n  # Sequential transport\n  bind_rows(counterfactuals_unaware_seq_black |&gt; mutate(counterfactual = \"seq\"))\n\ntb_indiv_unaware &lt;- \n  tb_unaware |&gt; \n  filter(id_indiv %in% counterfactuals_unaware_seq_black$id_indiv[1:3])\n\ntb_indiv_unaware\n\n# A tibble: 15 × 9\n   S     S_origin    X1    X2  pred type           id_indiv counterfactual Y    \n   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;          &lt;fct&gt;\n 1 Black Black     2.8   29   0.300 factual              24 none           &lt;NA&gt; \n 2 Black Black     3.2   19   0.206 factual              40 none           &lt;NA&gt; \n 3 Black Black     2.6   23   0.198 factual              51 none           &lt;NA&gt; \n 4 White Black     3.3   30   0.380 counterfactual       24 naive          1    \n 5 White Black     2.9   31   0.344 counterfactual       40 naive          0    \n 6 White Black     3.4   32   0.429 counterfactual       51 naive          0    \n 7 White Black     3.20  37.6 0.502 counterfactual       24 ot             &lt;NA&gt; \n 8 White Black     3.29  28.0 0.345 counterfactual       40 ot             &lt;NA&gt; \n 9 White Black     2.96  32.1 0.371 counterfactual       51 ot             &lt;NA&gt; \n10 White Black     3.25  37.6 0.509 counterfactual       24 fpt            &lt;NA&gt; \n11 White Black     3.6   29.9 0.419 counterfactual       40 fpt            &lt;NA&gt; \n12 White Black     3.1   32.3 0.394 counterfactual       51 fpt            &lt;NA&gt; \n13 White Black     3.3   37.5 0.515 counterfactual       24 seq            &lt;NA&gt; \n14 White Black     3.6   28.5 0.395 counterfactual       40 seq            &lt;NA&gt; \n15 White Black     3.1   32   0.388 counterfactual       51 seq            &lt;NA&gt; \n\n\n\n\n\ntb_aware &lt;- \n  factuals_aware |&gt; mutate(counterfactual = \"none\") |&gt; \n  # Naive\n  bind_rows(counterfactuals_aware_naive_black |&gt; mutate(counterfactual = \"naive\")) |&gt; \n  # Multivariate optimal transport\n  bind_rows(counterfactuals_aware_ot_black |&gt; mutate(counterfactual = \"ot\")) |&gt; \n  # Fairadapt\n  bind_rows(counterfactuals_aware_fpt_black |&gt; mutate(counterfactual = \"fpt\")) |&gt; \n  # Sequential transport\n  bind_rows(counterfactuals_aware_seq_black |&gt; mutate(counterfactual = \"seq\"))\n  \ntb_indiv_aware &lt;- \n  tb_aware |&gt; \n  filter(id_indiv %in% counterfactuals_aware_seq_black$id_indiv[1:3])\n\ntb_indiv_aware\n\n# A tibble: 15 × 9\n   S     S_origin    X1    X2   pred type          id_indiv counterfactual Y    \n   &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;          &lt;fct&gt;\n 1 Black Black     2.8   29   0.133  factual             24 none           &lt;NA&gt; \n 2 Black Black     3.2   19   0.0933 factual             40 none           &lt;NA&gt; \n 3 Black Black     2.6   23   0.0882 factual             51 none           &lt;NA&gt; \n 4 White Black     3.3   30   0.416  counterfactu…       24 naive          1    \n 5 White Black     2.9   31   0.382  counterfactu…       40 naive          0    \n 6 White Black     3.4   32   0.457  counterfactu…       51 naive          0    \n 7 White Black     3.20  37.6 0.515  counterfactu…       24 ot             &lt;NA&gt; \n 8 White Black     3.29  28.0 0.386  counterfactu…       40 ot             &lt;NA&gt; \n 9 White Black     2.96  32.1 0.405  counterfactu…       51 ot             &lt;NA&gt; \n10 White Black     3.25  37.6 0.522  counterfactu…       24 fpt            &lt;NA&gt; \n11 White Black     3.6   29.9 0.451  counterfactu…       40 fpt            &lt;NA&gt; \n12 White Black     3.1   32.3 0.425  counterfactu…       51 fpt            &lt;NA&gt; \n13 White Black     3.3   37.5 0.526  counterfactu…       24 seq            &lt;NA&gt; \n14 White Black     3.6   28.5 0.430  counterfactu…       40 seq            &lt;NA&gt; \n15 White Black     3.1   32   0.420  counterfactu…       51 seq            &lt;NA&gt; \n\n\n\n\n\n\nUnaware ModelAware Model\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2, 2, 0, 0))\n# Initial characteristics with the unaware model\ntb_indiv_unaware_factual &lt;- \n  tb_indiv_unaware |&gt; filter(type == \"factual\")\n\nrange_x1 &lt;- range(tb_indiv_unaware$X1)\nexpansion_amount_x1 &lt;- .1*range_x1\nrange_x2 &lt;- range(tb_indiv_unaware$X2)\nexpansion_amount_x2 &lt;- .05*range_x2\n\n\n\nplot(\n  x = tb_indiv_unaware_factual$X1,\n  y = tb_indiv_unaware_factual$X2,\n  col = colours_all[[\"Factual\"]],\n  # xlab = \"X1 (UGPA)\", ylab = \"X2 (LSAT)\",\n  xlab = \"\", ylab = \"\",\n  xlim = c(range_x1[1] - expansion_amount_x1[1], range_x1[2] + expansion_amount_x1[2]),\n  ylim = c(range_x2[1] - expansion_amount_x2[1], range_x2[2] + expansion_amount_x2[2]),\n  pch = 19,\n  axes = FALSE\n)\naxis(1)\nmtext(expression(X[1]~(UGCA)), side = 1, padj = .5)\naxis(2)\nmtext(expression(X[2]~(LSAT)), side = 2, padj = 0)\ntext(\n  x = tb_indiv_unaware_factual$X1, \n  y = tb_indiv_unaware_factual$X2 + 1,\n  paste0(round(100*tb_indiv_unaware_factual$pred, 2), \"%\"),\n  col = colours_all[[\"Factual\"]]\n)\n# Transported characteristics with fairadapt\ntb_indiv_unaware_fpt &lt;- \n  tb_indiv_unaware |&gt; filter(counterfactual == \"fpt\")\npoints(\n  x = tb_indiv_unaware_fpt$X1,\n  y = tb_indiv_unaware_fpt$X2,\n  col = colours_all[[\"Fairadapt\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\n# x1 then x2\nsegments(\n  x0 = tb_indiv_unaware_factual$X1, \n  y0 = tb_indiv_unaware_factual$X2,\n  x1 = tb_indiv_unaware_fpt$X1, \n  y1 = tb_indiv_unaware_factual$X2, \n  col = colours_all[[\"Fairadapt\"]],\n  lty = 2\n)\nsegments(\n  x0 = tb_indiv_unaware_fpt$X1, \n  y0 = tb_indiv_unaware_factual$X2,\n  x1 = tb_indiv_unaware_fpt$X1, \n  y1 = tb_indiv_unaware_fpt$X2, \n  col = colours_all[[\"Fairadapt\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_unaware_fpt$X1, \n  y = tb_indiv_unaware_fpt$X2 + 1,\n  paste0(round(100*tb_indiv_unaware_fpt$pred, 2), \"%\"),\n  col = colours_all[[\"Fairadapt\"]]\n)\n\n# Naive\ntb_indiv_unaware_naive &lt;- \n  tb_indiv_unaware |&gt; filter(counterfactual == \"naive\")\npoints(\n  x = tb_indiv_unaware_naive$X1,\n  y = tb_indiv_unaware_naive$X2,\n  col = colours_all[[\"Naive\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\nsegments(\n  x0 = tb_indiv_unaware_factual$X1, \n  y0 = tb_indiv_unaware_factual$X2,\n  x1 = tb_indiv_unaware_naive$X1, \n  y1 = tb_indiv_unaware_naive$X2, \n  col = colours_all[[\"Naive\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_unaware_naive$X1 + .1,\n  y = tb_indiv_unaware_naive$X2,\n  paste0(round(100*tb_indiv_unaware_naive$pred, 2), \"%\"),\n  col = colours_all[[\"Naive\"]]\n)\n\n# Transported characteristics with OT\ntb_indiv_unaware_ot &lt;- \n  tb_indiv_unaware |&gt; filter(counterfactual == \"ot\")\npoints(\n  x = tb_indiv_unaware_ot$X1,\n  y = tb_indiv_unaware_ot$X2,\n  col = colours_all[[\"OT\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\nsegments(\n  x0 = tb_indiv_unaware_factual$X1, \n  y0 = tb_indiv_unaware_factual$X2,\n  x1 = tb_indiv_unaware_ot$X1, \n  y1 = tb_indiv_unaware_ot$X2, \n  col = colours_all[[\"OT\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_unaware_ot$X1 - .15, \n  y = tb_indiv_unaware_ot$X2,\n  paste0(round(100*tb_indiv_unaware_ot$pred, 2), \"%\"),\n  col = colours_all[[\"OT\"]]\n)\n\n# Transported characteristics with Sequential transport\ntb_indiv_unaware_seq &lt;- \n  tb_indiv_unaware |&gt; filter(counterfactual == \"seq\")\npoints(\n  x = tb_indiv_unaware_seq$X1,\n  y = tb_indiv_unaware_seq$X2,\n  col = colours_all[[\"Seq. T.\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\n# x1 then x2\nsegments(\n  x0 = tb_indiv_unaware_factual$X1, \n  y0 = tb_indiv_unaware_factual$X2,\n  x1 = tb_indiv_unaware_seq$X1, \n  y1 = tb_indiv_unaware_factual$X2, \n  col = colours_all[[\"Seq. T.\"]],\n  lty = 2\n)\nsegments(\n  x0 = tb_indiv_unaware_seq$X1, \n  y0 = tb_indiv_unaware_factual$X2,\n  x1 = tb_indiv_unaware_seq$X1, \n  y1 = tb_indiv_unaware_seq$X2, \n  col = colours_all[[\"Seq. T.\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_unaware_seq$X1 + .11, \n  y = tb_indiv_unaware_seq$X2 - .5,\n  paste0(round(100*tb_indiv_unaware_seq$pred, 2), \"%\"),\n  col = colours_all[[\"Seq. T.\"]]\n)\nlegend(\n  \"topleft\", \n  pch = 19, col = colours_all[c(\"Factual\", \"Naive\", \"OT\", \"Fairadapt\", \"Seq. T.\")], \n  legend = names(colours_all[c(\"Factual\", \"Naive\", \"OT\", \"Fairadapt\", \"Seq. T.\")]),\n  box.lty=0\n)\n\n\n\n\n\nFigure 12.1: Predictions by the unaware model for three Black individuals.\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\npar(mar = c(2, 2, 0, 0))\n# Initial characteristics with the aware model\ntb_indiv_aware_factual &lt;- \n  tb_indiv_aware |&gt; filter(type == \"factual\")\n\nrange_x1 &lt;- range(tb_indiv_aware$X1)\nexpansion_amount_x1 &lt;- .1*range_x1\nrange_x2 &lt;- range(tb_indiv_aware$X2)\nexpansion_amount_x2 &lt;- .05*range_x2\n\nplot(\n  x = tb_indiv_aware_factual$X1,\n  y = tb_indiv_aware_factual$X2,\n  col = colours_all[[\"Factual\"]],\n  xlab = \"\", ylab = \"\",\n  # xlab = \"X1 (UGPA)\", ylab = \"X2 (LSAT)\",\n  xlim = c(range_x1[1] - expansion_amount_x1[1], range_x1[2] + expansion_amount_x1[2]),\n  ylim = c(range_x2[1] - expansion_amount_x2[1], range_x2[2] + expansion_amount_x2[2]),\n  pch = 19,\n  axes = FALSE\n)\naxis(1)\nmtext(expression(X[1]~(UGCA)), side = 1, padj = .5)\naxis(2)\nmtext(expression(X[2]~(LSAT)), side = 2, padj = 0)\ntext(\n  x = tb_indiv_aware_factual$X1, \n  y = tb_indiv_aware_factual$X2 + 1,\n  paste0(round(100*tb_indiv_aware_factual$pred, 2), \"%\"),\n  col = colours_all[[\"Factual\"]]\n)\n\n# Naive\ntb_indiv_aware_naive &lt;- \n  tb_indiv_aware |&gt; filter(counterfactual == \"naive\")\npoints(\n  x = tb_indiv_aware_naive$X1,\n  y = tb_indiv_aware_naive$X2,\n  col = colours_all[[\"Naive\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\nsegments(\n  x0 = tb_indiv_aware_factual$X1, \n  y0 = tb_indiv_aware_factual$X2,\n  x1 = tb_indiv_aware_naive$X1, \n  y1 = tb_indiv_aware_naive$X2, \n  col = colours_all[[\"Naive\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_aware_naive$X1 - .1,\n  y = tb_indiv_aware_naive$X2,\n  paste0(round(100*tb_indiv_aware_naive$pred, 2), \"%\"),\n  col = colours_all[[\"Naive\"]]\n)\n\n# Transported characteristics with fairadapt\ntb_indiv_aware_fpt &lt;- \n  tb_indiv_aware |&gt; filter(counterfactual == \"fpt\")\npoints(\n  x = tb_indiv_aware_fpt$X1,\n  y = tb_indiv_aware_fpt$X2,\n  col = colours_all[[\"Fairadapt\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\n# x1 then x2\nsegments(\n  x0 = tb_indiv_aware_factual$X1, \n  y0 = tb_indiv_aware_factual$X2,\n  x1 = tb_indiv_aware_fpt$X1, \n  y1 = tb_indiv_aware_factual$X2, \n  col = colours_all[[\"Fairadapt\"]],\n  lty = 2\n)\nsegments(\n  x0 = tb_indiv_aware_fpt$X1, \n  y0 = tb_indiv_aware_factual$X2,\n  x1 = tb_indiv_aware_fpt$X1, \n  y1 = tb_indiv_aware_fpt$X2, \n  col = colours_all[[\"Fairadapt\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_aware_fpt$X1, \n  y = tb_indiv_aware_fpt$X2 + 1,\n  paste0(round(100*tb_indiv_aware_fpt$pred, 2), \"%\"),\n  col = colours_all[[\"Fairadapt\"]]\n)\n# Transported characteristics with OT\ntb_indiv_aware_ot &lt;- \n  tb_indiv_aware |&gt; filter(counterfactual == \"ot\")\npoints(\n  x = tb_indiv_aware_ot$X1,\n  y = tb_indiv_aware_ot$X2,\n  col = colours_all[[\"OT\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\n# x1 then x2\nsegments(\n  x0 = tb_indiv_aware_factual$X1, \n  y0 = tb_indiv_aware_factual$X2,\n  x1 = tb_indiv_aware_ot$X1, \n  y1 = tb_indiv_aware_ot$X2, \n  col = colours_all[[\"OT\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_aware_ot$X1 - .15, \n  y = tb_indiv_aware_ot$X2,\n  paste0(round(100*tb_indiv_aware_ot$pred, 2), \"%\"),\n  col = colours_all[[\"OT\"]]\n)\n\n# Transported characteristics with Sequential transport\ntb_indiv_aware_seq &lt;- \n  tb_indiv_aware |&gt; filter(counterfactual == \"seq\")\npoints(\n  x = tb_indiv_aware_seq$X1,\n  y = tb_indiv_aware_seq$X2,\n  col = colours_all[[\"Seq. T.\"]],\n  xlab = \"X1\", ylab = \"X2\",\n  pch = 19\n)\n# x1 then x2\nsegments(\n  x0 = tb_indiv_aware_factual$X1, \n  y0 = tb_indiv_aware_factual$X2,\n  x1 = tb_indiv_aware_seq$X1, \n  y1 = tb_indiv_aware_factual$X2, \n  col = colours_all[[\"Seq. T.\"]],\n  lty = 2\n)\nsegments(\n  x0 = tb_indiv_aware_seq$X1, \n  y0 = tb_indiv_aware_factual$X2,\n  x1 = tb_indiv_aware_seq$X1, \n  y1 = tb_indiv_aware_seq$X2, \n  col = colours_all[[\"Seq. T.\"]],\n  lty = 2\n)\ntext(\n  x = tb_indiv_aware_seq$X1 - .11, \n  y = tb_indiv_aware_seq$X2 - 1,\n  paste0(round(100*tb_indiv_aware_seq$pred, 2), \"%\"),\n  col = colours_all[[\"Seq. T.\"]]\n)\nlegend(\n  \"topleft\", \n  pch = 19, col = colours_all[c(\"Factual\", \"Naive\", \"OT\", \"Fairadapt\", \"Seq. T.\")], \n  legend = names(colours_all[c(\"Factual\", \"Naive\", \"OT\", \"Fairadapt\", \"Seq. T.\")]),\n  box.lty=0, bg = \"transparent\"\n)\n\n\n\n\n\nFigure 12.2: Predictions by the aware model for three Black individuals.",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Counterfactuals: comparison</span>"
    ]
  },
  {
    "objectID": "cf-comparison.html#densities",
    "href": "cf-comparison.html#densities",
    "title": "12  Counterfactuals: comparison",
    "section": "12.3 Densities",
    "text": "12.3 Densities\nLet us now compare the densities of the predicted values.\n\ncolours &lt;- c(\n  \"0\" = \"#5BBCD6\",\n  \"1\" = \"#FF0000\",\n  \"A\" = \"#00A08A\",\n  \"B\" = \"#F2AD00\",\n  \"with\" = \"#046C9A\",\n  \"without\" = \"#C93312\",\n  \"2\" = \"#0B775E\"\n)\n\n\nUnaware modelAware model\n\n\n\n\nCodes used to create the Figure.\n# Factuals\ntb_unaware_factuals &lt;- tb_unaware |&gt; \n  filter(counterfactual == \"none\")\n# Predicted values\npred_unaware_factuals_black &lt;- tb_unaware_factuals |&gt; filter(S == \"Black\") |&gt; pull(\"pred\")\npred_unaware_factuals_white &lt;- tb_unaware_factuals |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_factuals_black &lt;- density(pred_unaware_factuals_black)\nd_unaware_factuals_white &lt;- density(pred_unaware_factuals_white)\n\npar(mfrow = c(4, 1), mar = c(2, 2, 0, 0))\nx_lim &lt;- c(0, .8)\ny_lim &lt;- c(0, 8)\n\n# OT\ntb_unaware_ot &lt;- tb_unaware |&gt; filter(counterfactual == \"ot\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_ot_black_star &lt;- tb_unaware_ot |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_ot_black_star &lt;- density(pred_unaware_ot_black_star)\n\nplot(\n  d_unaware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_ot_black_star, col = alpha(colours_all[[\"OT\"]], .5), border = NA)\ntext(x = .15, y = 6, \"Factuals - Black\", col = colours_all[[\"Source\"]])\npos_arrow &lt;- .2\nind_min &lt;- which.min(abs(d_unaware_factuals_black$x - pos_arrow))\narrows(\n  x1 = d_unaware_factuals_black$x[ind_min],\n  y1 = d_unaware_factuals_black$y[ind_min],\n  x0 = .15, \n  y0 = 5,\n  length = 0.05, col = colours_all[[\"Source\"]]\n)\ntext(x = .53, y = 6, \"Multi. OT\", col = colours_all[[\"OT\"]])\npos_arrow_ref &lt;- .7\ntext(x = pos_arrow_ref, y = 6, \"Factuals - White\", col = colours_all[[\"Reference\"]])\nind_min_ref &lt;- which.min(abs(d_unaware_factuals_white$x - pos_arrow_ref))\narrows(\n  x1 = d_unaware_factuals_white$x[ind_min_ref],\n  y1 = d_unaware_factuals_white$y[ind_min_ref],\n  x0 = pos_arrow_ref, \n  y0 = 5,\n  length = 0.05, col = colours_all[[\"Reference\"]]\n)\n\n# Naive\ntb_unaware_naive &lt;- tb_unaware |&gt; filter(counterfactual == \"naive\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_naive_black_star &lt;- tb_unaware_naive |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_naive_black_star &lt;- density(pred_unaware_naive_black_star)\n\nplot(\n  d_unaware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_naive_black_star, col = alpha(colours_all[[\"Naive\"]], .5), border = NA)\ntext(x = .28, y = 6, \"Naive\", col = colours_all[[\"Naive\"]])\n\n\n# Fairadapt\ntb_unaware_fpt &lt;- tb_unaware |&gt; filter(counterfactual == \"fpt\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_fpt_black_star &lt;- \n  tb_unaware_fpt |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_fpt_black_star &lt;- density(pred_unaware_fpt_black_star)\n\nplot(\n  d_unaware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_fpt_black_star, col = alpha(colours_all[[\"Fairadapt\"]], .5), border = NA)\ntext(x = .53, y = 6, \"fairadapt\", col = colours_all[[\"Fairadapt\"]])\n\n\n# Sequential transport\ntb_unaware_seq &lt;- tb_unaware |&gt; filter(counterfactual == \"seq\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_seq_black_star &lt;- tb_unaware_seq |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_seq_black_star &lt;- density(pred_unaware_seq_black_star)\n\nplot(\n  d_unaware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_seq_black_star, col = alpha(colours_all[[\"Seq. T.\"]], .5), border = NA)\ntext(x = .53, y = 6, \"Seq. T.\", col = colours_all[[\"Seq. T.\"]])\n\n\n\n\n\nFigure 12.3: Densities of predicted scores for Black individuals with factuals and with counterfactuals. The yellow dashed line corresponds to the density of predicted scores for White individuals, using factuals.\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\n# Factuals\ntb_aware_factuals &lt;- tb_aware |&gt; \n  filter(counterfactual == \"none\")\n# Predicted values\npred_aware_factuals_black &lt;- tb_aware_factuals |&gt; filter(S == \"Black\") |&gt; pull(\"pred\")\npred_aware_factuals_white &lt;- tb_aware_factuals |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_factuals_black &lt;- density(pred_aware_factuals_black)\nd_aware_factuals_white &lt;- density(pred_aware_factuals_white)\n\npar(mfrow = c(4, 1), mar = c(2, 2, 0, 0))\nx_lim &lt;- c(0, .8)\ny_lim &lt;- c(0, 8)\n\n# OT\ntb_aware_ot &lt;- tb_aware |&gt; filter(counterfactual == \"ot\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_ot_black_star &lt;- tb_aware_ot |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_ot_black_star &lt;- density(pred_aware_ot_black_star)\n\nplot(\n  d_aware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_ot_black_star, col = alpha(colours_all[[\"OT\"]], .5), border = NA)\ntext(x = .25, y = 6, \"Factuals - Black\", col = colours_all[[\"Source\"]])\npos_arrow &lt;- .2\nind_min &lt;- which.min(abs(d_aware_factuals_black$x - .2))\narrows(\n  x1 = d_aware_factuals_black$x[ind_min],\n  y1 = d_aware_factuals_black$y[ind_min],\n  x0 = .25, \n  y0 = 5,\n  length = 0.05, col = colours_all[[\"Source\"]]\n)\npos_arrow_ref &lt;- .7\ntext(x = pos_arrow_ref, y = 6, \"Factuals - White\", col = colours_all[[\"Reference\"]])\nind_min_ref &lt;- which.min(abs(d_aware_factuals_white$x - pos_arrow_ref))\narrows(\n  x1 = d_aware_factuals_white$x[ind_min_ref],\n  y1 = d_aware_factuals_white$y[ind_min_ref],\n  x0 = pos_arrow_ref, \n  y0 = 5,\n  length = 0.05, col = colours_all[[\"Reference\"]]\n)\ntext(x = .53, y = 6, \"Multi. OT\", col = colours_all[[\"OT\"]])\n\n# Naive\ntb_aware_naive &lt;- tb_aware |&gt; filter(counterfactual == \"naive\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_naive_black_star &lt;- tb_aware_naive |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_naive_black_star &lt;- density(pred_aware_naive_black_star)\n\nplot(\n  d_aware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_naive_black_star, col = alpha(colours_all[[\"Naive\"]], .5), border = NA)\ntext(x = .35, y = 6, \"Naive\", col = colours_all[[\"Naive\"]])\n\n\n# Fairadapt\ntb_aware_fpt &lt;- tb_aware |&gt; filter(counterfactual == \"fpt\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_fpt_black_star &lt;- \n  tb_aware_fpt |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_fpt_black_star &lt;- density(pred_aware_fpt_black_star)\n\nplot(\n  d_aware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_fpt_black_star, col = alpha(colours_all[[\"Fairadapt\"]], .5), border = NA)\ntext(x = .53, y = 6, \"fairadapt\", col = colours_all[[\"Fairadapt\"]])\n\n\n# Sequential transport\ntb_aware_seq &lt;- tb_aware |&gt; filter(counterfactual == \"seq\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_seq_black_star &lt;- tb_aware_seq |&gt; filter(S == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_seq_black_star &lt;- density(pred_aware_seq_black_star)\n\nplot(\n  d_aware_factuals_black,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_black, col = alpha(colours_all[[\"Source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"Reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_seq_black_star, col = alpha(colours_all[[\"Seq. T.\"]], .5), border = NA)\ntext(x = .53, y = 6, \"Seq. T.\", col = colours_all[[\"Seq. T.\"]])\n\n\n\n\n\nFigure 12.4: Densities of predicted scores for Black individuals with factuals and with counterfactuals. The yellow dashed line corresponds to the density of predicted scores for White individuals, using factuals.",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Counterfactuals: comparison</span>"
    ]
  },
  {
    "objectID": "cf-comparison.html#metrics",
    "href": "cf-comparison.html#metrics",
    "title": "12  Counterfactuals: comparison",
    "section": "12.4 Metrics",
    "text": "12.4 Metrics\nWe load the dataset on which the classifiers were trained (see Chapter 7).\n\nload(\"../data/df_race_c.rda\")\n\nThe predictions by the model using the factuals are stored in factuals_aware and factuals_unaware.\nWe define a small function, get_prob(), to compute the average score predicted by the model (either the aware model or the unaware model) in sub-groups identified by positions of observations.\n\n\nThe get_prob() function.\nget_prob &lt;- function(type, model = \"aware\", ind, sensitive = \"Black\") {\n  if (type == \"factual\") {\n    x &lt;- get(paste0(\"factuals_\", model))\n  } else if (type == \"naive\") {\n    x &lt;- get(paste0(\"counterfactuals_\", model, \"_naive_black\"))\n  } else if (type == \"fairadapt\") {\n    x &lt;- get(paste0(\"counterfactuals_\", model, \"_fpt_black\"))\n  } else if (type == \"ot\") {\n    x &lt;- get(paste0(\"counterfactuals_\", model, \"_ot_black\"))\n  } else if (type == \"seq\") {\n    x &lt;- get(paste0(\"counterfactuals_\", model, \"_seq_black\"))\n  } else {\n    stop(\"Error type.\")\n  }\n  \n  val &lt;- x |&gt; filter(id_indiv %in% ind) |&gt; pull(\"pred\")\n  \n  tribble(\n    ~type, ~model, ~sensitive, ~value_type, ~value,\n    type, model, sensitive, \"mean\", mean(val),\n    type, model, sensitive, \"sd\", sd(val)\n  )\n}\n\n\nWe identify the following sub-groups:\n\ndf_race_c &lt;- df_race_c |&gt; mutate(id_indiv = row_number())\nind_black &lt;- df_race_c |&gt; filter(S == \"Black\") |&gt; pull(\"id_indiv\")\nind_white &lt;- df_race_c |&gt; filter(S == \"White\") |&gt; pull(\"id_indiv\")\nind_pos &lt;- df_race_c |&gt; filter(Y == 1) |&gt; pull(\"id_indiv\")\nind_neg &lt;- df_race_c |&gt; filter(Y == 0) |&gt; pull(\"id_indiv\")\nind_true_pos &lt;- intersect(ind_pos, ind_black)\nind_pos_black &lt;- intersect(ind_pos, ind_black)\nind_pos_white &lt;- intersect(ind_pos, ind_white)\nind_neg_black &lt;- intersect(ind_neg, ind_black)\nind_neg_white &lt;- intersect(ind_neg, ind_white)\n\nThen, we compute the three metrics and merge them in a single table:\n\nconditional_demographic_parity &lt;- NULL\neq_op_pos &lt;- NULL\neq_op_neg &lt;- NULL\nfor (type in c(\"factual\", \"naive\",\"ot\", \"fairadapt\", \"seq\")) {\n  for (model in c(\"aware\", \"unaware\")) {\n    if (type == \"factual\") {\n      for (sensitive in c(\"Black\", \"White\")) {\n        # Conditional Demographic Parity\n        tmp_cdp &lt;- \n          get_prob(type = type, model = model, ind = ind_black) |&gt; \n          bind_rows(\n            get_prob(\n              type = type, model = model, ind = ind_white, sensitive = \"White\"\n              )\n          )\n        # ~ Equal Opportunity for Y=1\n        tmp_eq_op_pos &lt;- \n          get_prob(type = type, model = model, ind = ind_pos_black) |&gt; \n          bind_rows(\n            get_prob(\n              type = type, model = model, ind = ind_pos_white, \n              sensitive = \"White\"\n              )\n          )\n        # ~ Equal Opportunity for Y=0\n        tmp_eq_op_neg &lt;- \n          get_prob(type = type, model = model, ind = ind_neg_black) |&gt; \n          bind_rows(\n            get_prob(\n              type = type, model = model, ind = ind_neg_white, \n              sensitive = \"White\"\n              )\n          )\n      } \n    } else {\n      tmp_cdp &lt;- get_prob(type = type, model = model, ind = ind_black)\n      tmp_eq_op_pos &lt;- get_prob(type = type, model = model, ind = ind_pos_black)\n      tmp_eq_op_neg &lt;- get_prob(type = type, model = model, ind = ind_neg_black)\n    }\n    conditional_demographic_parity &lt;- \n      bind_rows(conditional_demographic_parity, tmp_cdp)\n    eq_op_pos &lt;- bind_rows(eq_op_pos, tmp_eq_op_pos)\n    eq_op_neg &lt;- bind_rows(eq_op_neg, tmp_eq_op_neg)\n  }\n}\n\n# Merge those in a single table:\nmetrics &lt;- \n  conditional_demographic_parity |&gt; mutate(metric = \"CDP\") |&gt; \n  bind_rows(eq_op_pos |&gt; mutate(metric = \"Eq. Opp. Y=1\")) |&gt; \n  bind_rows(eq_op_neg |&gt; mutate(metric = \"Eq. Opp. Y=0\"))\n\n\n\nCodes used to create the Table.\n# digits &lt;- 2\nnum_accuracy &lt;- 0.01\ntb_res &lt;- \n  metrics |&gt; \n  mutate(type = ifelse(\n    type == \"factual\" & sensitive == \"White\", \"factual_white\", type),\n    type = factor(\n      type, \n      levels = c(\"factual_white\", \"factual\", \"naive\", \"ot\", \"fairadapt\", \"seq\")\n    )\n  ) |&gt; \n  select(-sensitive) |&gt; \n  pivot_wider(names_from = \"value_type\", values_from = \"value\") |&gt; \n  mutate(value = paste0(\n    scales::number(mean, accuracy = num_accuracy),\n    \" (\",\n    scales::number(sd, accuracy = num_accuracy),\n    \")\")\n  ) |&gt; \n  select(-mean, -sd) |&gt; \n  pivot_wider(names_from = \"type\", values_from = \"value\", names_sort = TRUE) |&gt; \n  arrange(model, metric)\n\nknitr::kable(\n  tb_res[, -1], \n  col.names = c(\"Metric\", \"Factual\", \"Factual\", \"Naive\", \"OT\", \"Fairadapt\", \"Seq. Transport\")\n) |&gt; \n  kableExtra::kable_styling(\"striped\", full_width = F) %&gt;%\n  kableExtra::add_header_above(\n    c(\" \" = 1, \"White\"=1, \"Black\"=5)\n  ) |&gt; \n  kableExtra::pack_rows(index = table(tb_res$model))\n\n\n\n\nTable 12.1: Fairness metrics computed on scores predicted by the classifier based on the factuals or the different versions of the counterfactuals, for the aware model (sensitive variable used to train the classifier) and the unaware model (sentitive variable not provided to train the classifier).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite\n\n\nBlack\n\n\n\nMetric\nFactual\nFactual\nNaive\nOT\nFairadapt\nSeq. Transport\n\n\n\n\naware\n\n\nCDP\n0.52 (0.09)\n0.15 (0.05)\n0.34 (0.09)\n0.52 (0.09)\n0.53 (0.09)\n0.53 (0.10)\n\n\nEq. Opp. Y=0\n0.50 (0.09)\n0.15 (0.05)\n0.34 (0.09)\n0.52 (0.09)\n0.53 (0.09)\n0.53 (0.09)\n\n\nEq. Opp. Y=1\n0.54 (0.09)\n0.16 (0.06)\n0.33 (0.08)\n0.54 (0.10)\n0.54 (0.09)\n0.55 (0.10)\n\n\nunaware\n\n\nCDP\n0.51 (0.11)\n0.33 (0.11)\n0.30 (0.10)\n0.51 (0.11)\n0.52 (0.11)\n0.53 (0.11)\n\n\nEq. Opp. Y=0\n0.49 (0.11)\n0.32 (0.10)\n0.30 (0.10)\n0.51 (0.11)\n0.52 (0.10)\n0.52 (0.11)\n\n\nEq. Opp. Y=1\n0.53 (0.11)\n0.35 (0.12)\n0.29 (0.08)\n0.53 (0.11)\n0.54 (0.11)\n0.54 (0.12)\n\n\n\n\n\n\n\n\n\n\n\n\nLaTeX Table\nknitr::kable(\n  tb_res[,-1], format = \"latex\", booktabs = TRUE\n) |&gt; \n  kableExtra::kable_styling(\"striped\", full_width = F) %&gt;%\n  kableExtra::add_header_above(\n    c(\" \" = 1, \"White\"=1, \"Black\"=5)\n  ) |&gt; \n  kableExtra::pack_rows(index = table(tb_res$model))",
    "crumbs": [
      "III. Counterfactuals with Law Dataset",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Counterfactuals: comparison</span>"
    ]
  },
  {
    "objectID": "example-adult.html",
    "href": "example-adult.html",
    "title": "13  Adult Dataset",
    "section": "",
    "text": "13.1 Classifier\nWe load functions defined in our small package (notably, split_dataset()):\nlibrary(devtools)\nload_all(\"../seqtransfairness/\")\n\nℹ Loading seqtransfairness\nWe fit a logistic regression model on the data to predict the outcome binary variable. First, we split the dataset into two sets: train (70%) and test (30%).\nseed &lt;- 2025\nsets &lt;- split_dataset(adult, seed, train_ratio = 0.7)\ndata_train &lt;- sets$data_train\ndata_test &lt;- sets$data_test\nAs in Chapter 7, we train two models:\nTo do so, we define the training function, log_reg_train().\nThe log_reg_train() function.\n#' @param train_data Train set.\n#' @param test_data Test set.\n#' @param s Name of the sensitive attribute.\n#' @param y Name of the target variable.\n#' @param type If `\"type=aware\"`, the model includes the sensitive attributes,\n#'        otherwise, if `type=unaware`, it does not.\n#' \n#' @returns A list with three elements:\n#' * `model`: The estimated logistic regression model.\n#' * `pred_train`: Estimated scores on the train set.\n#' * `pred_test`: Estimated scores on the test set.\n#' \n#' @importFrom dplyr select\n#' @importFrom rlang !!\n#' @importFrom stats glm predict as.formula\nlog_reg_train &lt;- function(train_data,\n                          test_data,\n                          s,\n                          y,\n                          type = c(\"aware\", \"unaware\")) {\n  if (type == \"unaware\") {\n    train_data_ &lt;- train_data %&gt;% select(-!!s)\n    test_data_ &lt;- test_data %&gt;% select(-!!s)\n  } else {\n    train_data_ &lt;- train_data\n    test_data_ &lt;- test_data\n  }\n  # Train the logistic regression model\n  form &lt;- paste0(y, \"~.\")\n  model &lt;- glm(as.formula(form), data = train_data_, family = binomial)\n  # Predictions on train and test sets\n  pred_train &lt;- predict(model, newdata = train_data_, type = \"response\")\n  pred_test &lt;- predict(model, newdata = test_data_, type = \"response\")\n  list(\n    model = model,\n    pred_train = pred_train,\n    pred_test = pred_test\n  )\n}\nLet us train the two models. Then, we extract the predicted values on both the train set and the test set.\n# Unaware logistic regression classifier (model without S)\npred_unaware &lt;- log_reg_train(data_train, data_test, s = s, y = y, type = \"unaware\")\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases\n\npred_unaware_train &lt;- pred_unaware$pred_train\npred_unaware_test &lt;- pred_unaware$pred_test\n\n# Aware logistic regression classifier (model with S)\npred_aware &lt;- log_reg_train(data_train, data_test, s = s, y = y, type = \"aware\")\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases\n\npred_aware_train &lt;- pred_aware$pred_train\npred_aware_test &lt;- pred_aware$pred_test\nWe create a table for each model, with the sensitive attribute and the predicted value by the model (\\(\\hat{y}\\)), only for observations from the test set.\ndf_test_unaware &lt;- tibble(\n  S = data_test |&gt; pull(!!s),\n  pred = pred_unaware_test\n)\n\ndf_test_aware &lt;- tibble(\n  S = data_test |&gt; pull(!!s),\n  pred = pred_aware_test\n)",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-adult.html#classifier",
    "href": "example-adult.html#classifier",
    "title": "13  Adult Dataset",
    "section": "",
    "text": "unaware logistic regression classifier: model without including the sensitive attribute.\naware logistic regression classifier: model with the sensitive attribute included in the set of features.\n\n\n\n\n\n\n\n\n13.1.1 Predictions\nWe predict values with the unaware model on the factuals:\n\nmodel_unaware &lt;- pred_unaware$model\npred_unaware_all &lt;- predict(\n  model_unaware,\n  newdata = adult,\n  type = \"response\"\n)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases\n\n\nAnd with the aware model:\n\nmodel_aware &lt;- pred_aware$model\npred_aware_all &lt;- predict(\n  model_aware,\n  newdata = adult,\n  type = \"response\"\n)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases\n\n\n\n\n13.1.2 Saving Objects\n\nsave(pred_aware, file = \"../data/pred_aware_adult.rda\")\nsave(pred_unaware, file = \"../data/pred_unaware_adult.rda\")\nsave(pred_unaware_all, file = \"../data/pred_unaware_all_adult.rda\")\nsave(pred_aware_all, file = \"../data/pred_aware_all_adult.rda\")",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-adult.html#naive-approach-ceteris-paribus",
    "href": "example-adult.html#naive-approach-ceteris-paribus",
    "title": "13  Adult Dataset",
    "section": "13.2 Naive approach: ceteris paribus",
    "text": "13.2 Naive approach: ceteris paribus\nLet us change the sensitive attribute of individuals from the source group (women) to the target group (men). Then, we use both models (unaware and aware) to predict the target binary variable.\n\npred_unaware_naive_women &lt;- predict(\n  model_unaware,\n  newdata = adult |&gt; filter(sex == \"Female\") |&gt; mutate(sex = \"Male\"),\n  type = \"response\"\n)\npred_aware_naive_women &lt;- predict(\n  model_aware,\n  newdata = adult |&gt; filter(sex == \"Female\") |&gt;  mutate(sex = \"Male\"),\n  type = \"response\"\n)\n\nind_women &lt;- which(adult$sex == \"Female\")\nind_men &lt;- which(adult$sex == \"Male\")\n\ncounterfactuals_unaware_naive_women &lt;- \n  adult |&gt; filter(sex == \"Female\") |&gt; \n  mutate(\n    sex_origin = sex,\n    sex = \"Male\",\n    pred = pred_unaware_naive_women,\n    type = \"counterfactual\",\n    id_indiv = ind_women\n  )\ncounterfactuals_aware_naive_women &lt;- \n  adult |&gt; filter(sex == \"Female\") |&gt; \n  mutate(\n    sex_origin = sex,\n    sex = \"Male\",\n    pred = pred_aware_naive_women,\n    type = \"counterfactual\",\n    id_indiv = ind_women\n  )\n\n\n13.2.1 Unaware Model\nLet us have a look at the distribution of the predicted scores of the classifier in both groups, when the predictions are made after setting the sex attribute of all women to “Male”. Since the model does not use the sensitive attribute, changing it will result in absolutely no change in its predictions in this case.\nThe predicted values using the initial characteristics (the factuals), for the unaware model are stored in the object pred_unaware_all. We put in a table the initial characteristics (factuals) and the prediction made by the unaware model:\n\nfactuals_unaware &lt;-\n  adult |&gt; \n  as_tibble() |&gt;\n  mutate(\n    sex_origin = sex,\n    pred = pred_unaware_all,\n    type = \"factual\"\n  ) |&gt; \n    mutate(id_indiv = row_number())\n\n\nunaware_naive_women &lt;- \n  factuals_unaware |&gt; mutate(sex_origin = sex) |&gt; \n  bind_rows(counterfactuals_unaware_naive_women)\n\nThe unaware model is blind to the sensitive attribute. Hence, changing the sensitive attribute does not affect the predicted scores.\n\nggplot(\n  unaware_naive_women |&gt; mutate(\n    group = case_when(\n      sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n      sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n      sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n      )\n    )\n  ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 13.3: Unaware model, Sensitive: Sex, Woman -&gt; Man\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for ccounterfactual of Women and factuals of men. Again, since the model is blind to the sensitive attribute, the distributions are perfectly aligned.\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_naive_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Female\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.4: Distribution of Predicted Scores for Minority Class (Women), Unaware model, Sensitive: Race, Woman -&gt; Man\n\n\n\n\n\n\n\n\n\n\n13.2.2 Aware Model\nWe turn to the aware model. This time, the sensitive attribute is used by the classifier when it is trained. Hence, changing the sensitive attribute of individuals in the source group to that of the target group may change the predicted values for the binary outcome variable.\nThe predicted values by the model, on the initial characteristics (on the factuals) are stored in the pred_aware_all object.\nWe create a tibble with the factuals and the predictions by the aware model:\n\nfactuals_aware &lt;-\n  adult |&gt; \n  as_tibble() |&gt;\n  mutate(\n    sex_origin = sex,\n    pred = pred_aware_all,\n    type = \"factual\"\n  ) |&gt; \n    mutate(id_indiv = row_number())\n\n\naware_naive_women &lt;- \n  factuals_aware |&gt; mutate(sex_origin = sex) |&gt; \n  bind_rows(counterfactuals_aware_naive_women)\n\n\nggplot(\n  aware_naive_women |&gt; mutate(\n    group = case_when(\n      sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n      sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n      sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n      )\n    )\n  ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 13.5: Aware model, Sensitive: Sex, Woman -&gt; Man\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for ccounterfactual of Women and factuals of men.\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_naive_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Female\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.6: Distribution of Predicted Scores for Minority Class (Women), Aware model, Sensitive: Race, Woman -&gt; Man",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-adult.html#sec-adult-dataset-fairadapt",
    "href": "example-adult.html#sec-adult-dataset-fairadapt",
    "title": "13  Adult Dataset",
    "section": "13.3 Fairadapt",
    "text": "13.3 Fairadapt\nWe have already assumed a causal graph (see Figure 13.1).\nLet us consider that we want to build counterfactuals for women: what if the individual had been a man and not a woman?\nLet us have a look at the levels of our sensitive variable:\n\nlevels(adult |&gt; pull(!!s))\n\n[1] \"Female\" \"Male\"  \n\n\nTwo configurations will be considered in turn:\n\nThe reference class consists of men, and fairadapt will be used to obtain the counterfactual values for women as if they had been men.\nThe reference class consists of women, and fairadapt will be used to obtain the counterfactual values for men as if they had been women.\n\n\n# Women (factuals) --&gt; Men (counterfactuals)\ndf_fpt &lt;- adult |&gt; mutate(sex = fct_relevel(sex, \"Female\", after = Inf))\nfpt_model_women &lt;- fairadapt(\n  income ~ .,\n  train.data = df_fpt,\n  prot.attr = \"sex\", adj.mat = adj_mat,\n  quant.method = rangerQuants\n)\nadapt_df_women &lt;- adaptedData(fpt_model_women)\n\n# Men (factuals) --&gt; Women (counterfactuals)\ndf_fpt &lt;- df_fpt |&gt; mutate(sex = fct_relevel(sex, \"Male\", after = Inf))\nfpt_model_men &lt;- fairadapt(\n  income ~ .,\n  train.data = df_fpt,\n  prot.attr = \"sex\", adj.mat = adj_mat,\n  quant.method = rangerQuants\n)\nadapt_df_men &lt;- adaptedData(fpt_model_men)\n\nLet us wrap up:\n\nwe have two predictive models for the income variable (greater than 50k per year, or lower than or equal to 50k per year):\n\nunaware (without S)\naware (with S)\n\nwe have the counterfactual characteristics obtained with fairadapt in two situations depending on the reference class:\n\nwomen individuals as reference\nmen individuals as reference.\n\n\nThe predictive models will be used to compare predictions made using:\n\nRaw characteristics (initial characteristics).\nCharacteristics possibly altered through fairadapt for individuals who were not in the reference group (i.e., using counterfactuals).\n\n\n13.3.1 Unaware Model\nLet us build a dataset containing only counterfactual characteristics obtained with fairadapt.\n\npred_unaware_fpt_women &lt;- predict(\n  model_unaware, \n  newdata = adapt_df_women[ind_women, ], \n  type = \"response\"\n)\npred_unaware_fpt_men &lt;- predict(\n  model_unaware, \n  newdata = adapt_df_men[ind_men, ],\n  type = \"response\"\n)\n\nWe create a table with the counterfactual characteristics and the prediction by the unaware model:\n\ncounterfactuals_unaware_fpt_women &lt;- \n  as_tibble(adapt_df_women[ind_women, ]) |&gt; \n  mutate(\n    sex_origin = adult$sex[ind_women],\n    pred = pred_unaware_fpt_women,\n    type = \"counterfactual\",\n    id_indiv = ind_women\n  )\n\ncounterfactuals_unaware_fpt_men &lt;- \n  as_tibble(adapt_df_men[ind_men, ]) |&gt; \n  mutate(\n    sex_origin = adult$sex[ind_men],\n    pred = pred_unaware_fpt_men,\n    type = \"counterfactual\",\n    id_indiv = ind_men\n  )\n\nWe merge the two datasets, factuals_unaware and counterfactuals_unaware_fpt_women (or counterfactuals_unaware_fpt_men) in a single one.\n\nunaware_fpt_women &lt;- \n  factuals_unaware |&gt; mutate(sex_origin = sex) |&gt; \n  bind_rows(counterfactuals_unaware_fpt_women)\n  \nunaware_fpt_men &lt;- \n  factuals_unaware |&gt; mutate(sex_origin = sex) |&gt; \n  bind_rows(counterfactuals_unaware_fpt_men)\n\n\nWoman -&gt; ManMan -&gt; Woman\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.7: Unaware model, Sensitive: Sex, Woman -&gt; Man\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_men |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\",\n        sex_origin == \"Male\" & sex == \"Female\" ~ \"Men -&gt; Women (Counterfactual)\",\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Men (Original)\", \"Men -&gt; Women (Counterfactual)\", \"Women (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Women (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Women (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.8: Unaware model, Sensitive: Sex, Man -&gt; Woman\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for counterfactual of women and factuals of men.\n\nWoman -&gt; ManMan -&gt; Woman\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Female\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.9: Distribution of Predicted Scores for Minority Class (Women), Unaware model, Sensitive: Sex, Woman -&gt; Man\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_men |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\",\n        sex_origin == \"Male\" & sex == \"Female\" ~ \"Men -&gt; Women (Counterfactual)\",\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Men (Original)\", \"Men -&gt; Women (Counterfactual)\", \"Women (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Male\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.10: Distribution of Predicted Scores for Minority Class (White), Unaware model, Sensitive: Race, Man -&gt; Woman\n\n\n\n\n\n\n\n\n\n\n\n\n\n13.3.2 Aware Model\nNow, we turn to the model that includes the sensitive attribute, i.e., the aware model. Let us get the predicted values for the counterfactuals, using the aware model:\n\npred_aware_fpt_women &lt;- predict(\n  model_aware, \n  newdata = adapt_df_women[ind_women, ], \n  type = \"response\"\n)\npred_aware_fpt_men &lt;- predict(\n  model_aware, \n  newdata = adapt_df_men[ind_men, ],\n  type = \"response\"\n)\n\nThen, we create a table with the counterfactuals and the predicted value by the aware model:\n\ncounterfactuals_aware_fpt_women &lt;- \n  as_tibble(adapt_df_women[ind_women, ]) |&gt; \n  mutate(\n    sex_origin = adult$sex[ind_women],\n    pred = pred_aware_fpt_women,\n    type = \"counterfactual\",\n    id_indiv = ind_women\n  )\n\ncounterfactuals_aware_fpt_men &lt;- \n  as_tibble(adapt_df_men[ind_men, ]) |&gt; \n  mutate(\n    sex_origin = adult$sex[ind_men],\n    pred = pred_aware_fpt_men,\n    type = \"counterfactual\",\n    id_indiv = ind_men\n  )\n\nWe merge the two datasets, factuals_unaware and counterfactuals_aware_fpt_women (or counterfactuals_aware_fpt_men) in a single one.\n\n# dataset with counterfactuals, for aware model\naware_fpt_women &lt;- \n  factuals_aware |&gt; mutate(sex_origin = sex) |&gt; \n  bind_rows(counterfactuals_aware_fpt_women)\n  \naware_fpt_men &lt;- \n  factuals_aware |&gt; mutate(sex_origin = sex) |&gt; \n  bind_rows(counterfactuals_aware_fpt_men)\n\n\nWomen -&gt; MenMen -&gt; Women\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.11: Aware model, Sensitive: Race, Reference: Men individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_men |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\",\n        sex_origin == \"Male\" & sex == \"Female\" ~ \"Men -&gt; Women (Counterfactual)\",\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Men (Original)\", \"Men -&gt; Women (Counterfactual)\", \"Women (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Women (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Women (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.12: Aware model, Sensitive: Race, Reference: Women individuals\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for counterfactual of Women and factuals of men.\n\nWomen -&gt; MenMen -&gt; Women\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Female\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.13: Distribution of Predicted Scores for Minority Class (Women), Aware model, Sensitive: Race, Reference: Men individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_men |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\",\n        sex_origin == \"Male\" & sex == \"Female\" ~ \"Men -&gt; Women (Counterfactual)\",\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Men (Original)\", \"Men -&gt; Women (Counterfactual)\", \"Women (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Male\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Men (Original)\" = colours_all[[\"source\"]],\n      \"Men -&gt; Women (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.14: Distribution of Predicted Scores for Minority Class (Men), Aware model, Sensitive: Race, Reference: Women individuals",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-adult.html#sequential-transport",
    "href": "example-adult.html#sequential-transport",
    "title": "13  Adult Dataset",
    "section": "13.4 Sequential Transport",
    "text": "13.4 Sequential Transport\nWe now turn to sequential transport (the methodology developed in our paper). We use the seq_trans() function defined in our small package to perform a fast sequential transport on causal graph.\nWe use the same causal graph as in Section 13.3.\n\nsequential_transport &lt;- seq_trans(\n  data = adult, adj = adj_mat, s = \"sex\", S_0 = \"Female\", y = \"income\"\n)\n\nTransporting  age \nTransporting  native_country \nTransporting  marital_status \n# weights:  4 (3 variable)\ninitial  value 927.430928 \nfinal  value 779.199404 \nconverged\nTransporting  education_num \nTransporting  workclass \n# weights:  24 (15 variable)\ninitial  value 1854.861855 \niter  10 value 1418.843645\niter  20 value 1226.860388\nfinal  value 1224.646984 \nconverged\nTransporting  hours_per_week \nTransporting  occupation \n\n\nWarning in nnet::multinom(x_S0 ~ ., data = mutate(data_1_parents, x_S0 =\nx_S1)): group 'Armed-Forces' is empty\n\n\n# weights:  84 (65 variable)\ninitial  value 3531.058707 \niter  10 value 3268.247749\niter  20 value 3150.146313\niter  30 value 3013.347818\niter  40 value 2880.348969\niter  50 value 2868.888514\niter  60 value 2865.551923\niter  70 value 2864.693363\niter  80 value 2864.661456\niter  90 value 2864.641525\nfinal  value 2864.640591 \nconverged\n\n\nWe build a dataset with the sensitive attribute of Women changed to Male, and their characteristics changed to their transported characteristics:\n\ndf_counterfactuals_seq_women &lt;- \n  as_tibble(sequential_transport$transported) |&gt; \n  mutate(\n    id_indiv = ind_women,\n    sex_origin = \"Female\",\n    sex = \"Male\"\n  )\n\nWe make predictions based on those counterfactuals obtained with sequential transport, on both models (the unaware model, and the aware model):\n\npred_seq_unaware &lt;- predict(\n  model_unaware, newdata = df_counterfactuals_seq_women, type = \"response\"\n)\n\npred_seq_aware &lt;- predict(\n  model_aware, newdata = df_counterfactuals_seq_women, type = \"response\"\n)\n\n\ncounterfactuals_unaware_seq_women &lt;- \n  df_counterfactuals_seq_women |&gt; \n  mutate(pred = pred_seq_unaware, type = \"counterfactual\")\ncounterfactuals_aware_seq_women &lt;- \n  df_counterfactuals_seq_women |&gt; \n  mutate(pred = pred_seq_aware, type = \"counterfactual\")\n\nLet us put in a single table the predictions made by the classifier (either aware or unaware) on Women based on their factual characteristics, and those made based on the counterfactuals:\n\naware_seq_women &lt;- bind_rows(\n  factuals_aware |&gt; mutate(id_indiv = row_number(), sex_origin = sex), \n  counterfactuals_aware_seq_women |&gt; mutate(S_origin = \"Female\")\n)\nunaware_seq_women &lt;- bind_rows(\n  factuals_unaware |&gt; mutate(id_indiv = row_number(), sex_origin = sex), \n  counterfactuals_unaware_seq_women |&gt; mutate(S_origin = \"Female\")\n)\n\n\nUnawareAware\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_seq_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.15: Unaware model, Sensitive: Race, Woman -&gt; Man\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_seq_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~sex) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.16: Aware model, Sensitive: Race, Woman -&gt; Man\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for counterfactual of women and factuals of men\n\nUnawareAware\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_seq_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Female\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.17: Distribution of Predicted Scores for Minority Class (Women), Unaware model, Sensitive: Race, Woman -&gt; Man\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_seq_women |&gt; \n    mutate(\n      group = case_when(\n        sex_origin == \"Female\" & sex == \"Female\" ~ \"Women (Original)\",\n        sex_origin == \"Female\" & sex == \"Male\" ~ \"Women -&gt; Men (Counterfactual)\",\n        sex_origin == \"Male\" & sex == \"Male\" ~ \"Men (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Women (Original)\", \"Women -&gt; Men (Counterfactual)\", \"Men (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(sex_origin == \"Female\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Women (Original)\" = colours_all[[\"source\"]],\n      \"Women -&gt; Men (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"Men (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 13.18: Distribution of Predicted Scores for Minority Class (Women), Aware model, Sensitive: Race, Woman -&gt; Man",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-adult.html#comparison",
    "href": "example-adult.html#comparison",
    "title": "13  Adult Dataset",
    "section": "13.5 Comparison",
    "text": "13.5 Comparison\nLet us now compare the results.\n\nUnaware ModelAware Model\n\n\n\ntb_unaware &lt;- \n  factuals_unaware |&gt; mutate(counterfactual = \"none\") |&gt;\n  # Naive\n  bind_rows(\n    counterfactuals_unaware_naive_women |&gt; mutate(counterfactual = \"naive\")\n  ) |&gt; \n  # Fairadapt\n  bind_rows(\n    counterfactuals_unaware_fpt_women |&gt; mutate(counterfactual = \"fpt\")\n  ) |&gt; \n  # Sequential transport\n  bind_rows(\n    counterfactuals_unaware_seq_women |&gt; mutate(counterfactual = \"seq\")\n  )\n\n\n\n\ntb_aware &lt;- \n  factuals_aware |&gt; mutate(counterfactual = \"none\") |&gt; \n  # Naive\n  bind_rows(\n    counterfactuals_aware_naive_women |&gt; mutate(counterfactual = \"naive\")\n  ) |&gt; \n  # Fairadapt\n  bind_rows(\n    counterfactuals_aware_fpt_women |&gt; mutate(counterfactual = \"fpt\")\n  ) |&gt; \n  # Sequential transport\n  bind_rows(\n    counterfactuals_aware_seq_women |&gt; mutate(counterfactual = \"seq\")\n  )\n\n\n\n\nLet us compare the densities of the predicted values.\n\nUnaware modelAware model\n\n\n\n\nCodes used to create the Figure.\n# Factuals\ntb_unaware_factuals &lt;- tb_unaware |&gt; filter(counterfactual == \"none\")\n# Predicted values\npred_unaware_factuals_women &lt;- tb_unaware_factuals |&gt; filter(sex == \"Female\") |&gt; pull(\"pred\")\npred_unaware_factuals_men &lt;- tb_unaware_factuals |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_factuals_women &lt;- density(pred_unaware_factuals_women)\nd_unaware_factuals_men &lt;- density(pred_unaware_factuals_men)\n\npar(mfrow = c(3, 1), mar = c(2, 2, 0, 0))\nx_lim &lt;- c(0, .8)\ny_lim &lt;- c(0, 10)\n\n# Naive\ntb_unaware_naive &lt;- tb_unaware |&gt; filter(counterfactual == \"naive\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_naive_women_star &lt;- tb_unaware_naive |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_naive_women_star &lt;- density(pred_unaware_naive_women_star)\n\nplot(\n  d_unaware_factuals_women,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_women, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_unaware_factuals_men, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_naive_women_star, col = alpha(colours_all[[\"naive\"]], .5), border = NA)\npos_arrow_ref &lt;- .6\ntext(x = pos_arrow_ref, y = 8, \"Factuals - Men\", col = colours_all[[\"reference\"]])\nind_min_ref &lt;- which.min(abs(d_unaware_factuals_men$x - pos_arrow_ref))\narrows(\n  x1 = d_unaware_factuals_men$x[ind_min_ref],\n  y1 = d_unaware_factuals_men$y[ind_min_ref],\n  x0 = pos_arrow_ref, \n  y0 = 7,\n  length = 0.05, col = colours_all[[\"reference\"]]\n)\ntext(x = .09, y = 8, \"Naive\", col = colours_all[[\"naive\"]])\n\n\n# Fairadapt\ntb_unaware_fpt &lt;- tb_unaware |&gt; filter(counterfactual == \"fpt\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_fpt_women_star &lt;- \n  tb_unaware_fpt |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_fpt_women_star &lt;- density(pred_unaware_fpt_women_star)\n\nplot(\n  d_unaware_factuals_women,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_women, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_unaware_factuals_men, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_fpt_women_star, col = alpha(colours_all[[\"fairadapt\"]], .5), border = NA)\ntext(x = .15, y = 6, \"Factuals - Women\", col = colours_all[[\"source\"]])\npos_arrow &lt;- .07\nind_min &lt;- which.min(abs(d_unaware_factuals_women$x - pos_arrow))\narrows(\n  x1 = d_unaware_factuals_women$x[ind_min],\n  y1 = d_unaware_factuals_women$y[ind_min],\n  x0 = .15, \n  y0 = 5,\n  length = 0.05, col = colours_all[[\"source\"]]\n)\ntext(x = .4, y = 6, \"fairadapt\", col = colours_all[[\"fairadapt\"]])\n\n\n# Sequential transport\ntb_unaware_seq &lt;- tb_unaware |&gt; filter(counterfactual == \"seq\")\n# Predicted values, focusing on Black --&gt; White\npred_unaware_seq_women_star &lt;- tb_unaware_seq |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_seq_women_star &lt;- density(pred_unaware_seq_women_star)\n\nplot(\n  d_unaware_factuals_women,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_women, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_unaware_factuals_men, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_seq_women_star, col = alpha(colours_all[[\"seq\"]], .5), border = NA)\ntext(x = .4, y = 6, \"Seq. T.\", col = colours_all[[\"seq\"]])\n\n\n\n\n\nFigure 13.19: Densities of predicted scores for Women with factuals and with counterfactuals. The yellow dashed line corresponds to the density of predicted scores for Women, using factuals.\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\n# Factuals\ntb_aware_factuals &lt;- tb_aware |&gt; filter(counterfactual == \"none\")\n# Predicted values\npred_aware_factuals_women &lt;- tb_aware_factuals |&gt; filter(sex == \"Female\") |&gt; pull(\"pred\")\npred_aware_factuals_men &lt;- tb_aware_factuals |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_factuals_women &lt;- density(pred_aware_factuals_women)\nd_aware_factuals_men &lt;- density(pred_aware_factuals_men)\n\npar(mfrow = c(3, 1), mar = c(2, 2, 0, 0))\nx_lim &lt;- c(0, .8)\ny_lim &lt;- c(0, 16)\n\n# Naive\ntb_aware_naive &lt;- tb_aware |&gt; filter(counterfactual == \"naive\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_naive_women_star &lt;- tb_aware_naive |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_naive_women_star &lt;- density(pred_aware_naive_women_star)\n\nplot(\n  d_aware_factuals_women,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_women, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_aware_factuals_men, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_naive_women_star, col = alpha(colours_all[[\"naive\"]], .5), border = NA)\ntext(x = .15, y = 13, \"Factuals - Women\", col = colours_all[[\"source\"]])\npos_arrow &lt;- .03\nind_min &lt;- which.min(abs(d_aware_factuals_women$x - pos_arrow))\narrows(\n  x1 = d_aware_factuals_women$x[ind_min],\n  y1 = d_aware_factuals_women$y[ind_min],\n  x0 = .15, \n  y0 = 11,\n  length = 0.05, col = colours_all[[\"source\"]]\n)\npos_arrow_ref &lt;- .6\ntext(x = pos_arrow_ref, y = 13, \"Factuals - Men\", col = colours_all[[\"reference\"]])\nind_min_ref &lt;- which.min(abs(d_aware_factuals_men$x - pos_arrow_ref))\narrows(\n  x1 = d_aware_factuals_men$x[ind_min_ref],\n  y1 = d_aware_factuals_men$y[ind_min_ref],\n  x0 = pos_arrow_ref, \n  y0 = 11,\n  length = 0.05, col = colours_all[[\"reference\"]]\n)\ntext(x = .4, y = 6, \"Naive\", col = colours_all[[\"naive\"]])\n\n\n# Fairadapt\ntb_aware_fpt &lt;- tb_aware |&gt; filter(counterfactual == \"fpt\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_fpt_women_star &lt;- \n  tb_aware_fpt |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_fpt_women_star &lt;- density(pred_aware_fpt_women_star)\n\nplot(\n  d_aware_factuals_women,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_women, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_aware_factuals_men, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_fpt_women_star, col = alpha(colours_all[[\"fairadapt\"]], .5), border = NA)\ntext(x = .4, y = 6, \"fairadapt\", col = colours_all[[\"fairadapt\"]])\n\n\n# Sequential transport\ntb_aware_seq &lt;- tb_aware |&gt; filter(counterfactual == \"seq\")\n# Predicted values, focusing on Black --&gt; White\npred_aware_seq_women_star &lt;- tb_aware_seq |&gt; filter(sex == \"Male\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_seq_women_star &lt;- density(pred_aware_seq_women_star)\n\nplot(\n  d_aware_factuals_women,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_women, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_aware_factuals_men, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_seq_women_star, col = alpha(colours_all[[\"seq\"]], .5), border = NA)\ntext(x = .4, y = 6, \"Seq. T.\", col = colours_all[[\"seq\"]])\n\n\n\n\n\nFigure 13.20: Densities of predicted scores for Women with factuals and with counterfactuals. The yellow dashed line corresponds to the density of predicted scores for Women, using factuals.",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-adult.html#metrics",
    "href": "example-adult.html#metrics",
    "title": "13  Adult Dataset",
    "section": "13.6 Metrics",
    "text": "13.6 Metrics\n\n\n\n\n\n\nWarning\n\n\n\nThis section is still under construction. Results may not correct. The metrics used should be changed soon.\n\n\nLet us compute a few metrics metrics, such as the accuracy, the log-loss, and the Brier Score, as well as the counterfactual demographic parity. For the accuracy, we define the set the probability threshold to .5.\nThe counterfactual demographic parity writes:\n\\[\n\\mathrm{CDP}=\\frac{1}{n_0}\\sum_{i\\in\\mathcal{D}_0}m(1,\\boldsymbol{x}_{i}^\\star) - m(0,\\boldsymbol{x}_{i}),\n\\] where \\(n_0\\) is the number of women in the sample, \\(m()\\) is the classifier, with \\(m(1,\\boldsymbol{x}_{i}^\\star)\\) the score returned when the sensitive attribute is \\(S=1\\), i.e., “Male” and \\(\\boldsymbol{x}_{i}^\\star\\) are the counterfactual values, \\(m(0,\\boldsymbol{x}_{i})\\) is the score returned by the model when using the factuals.\nWe compute the Equalized Odds criterion as the absolute difference between true positive rate (TPR) across the two groups (Women/Men):\n\\[\nEO = | TPR_{\\text{Women}} - TPR_{\\text{Men}} |\n\\]\nA binary predictor \\(\\hat{Y}\\) satisfies equal opportunity with respect to \\(S\\) and \\(Y\\) if Hardt, Price, and Srebro (2016): \\[\nP\\big(\\hat{Y} = 1 | S=0, Y=1 \\big) = P\\big(\\hat{Y} = 1 | S=1, Y=1 \\big)\n\\]\n\nprob_threshold &lt;- .5\n\n#' Log loss\n#' \n#' @param y vector or binary obsevations\n#' @param s vector of predicted scores\ncalculate_log_loss &lt;- function(y, s){\n  s_pred &lt;- pmin(pmax(s, 1e-15), 1 - 1e-15)\n  mean(-y*log(s_pred) - (1-y)*log(1-s_pred))\n}\n\n#' Brier Score\n#'\n#' The Brier Score \\citep{brier_1950}, is expressed as: \\deqn{\\text{BS} =\n#' \\frac{1}{n}\\sum_{i=1}^{n} \\big(\\hat{s}(\\mathbf{x}_i) - d_i\\big)^{2}} where\n#' \\eqn{d_i \\in \\{0,1\\}} is the observed event for observation \\eqn{i}.\n#'\n#' @param obs vector of observed binary events\n#' @param scores vector of scores\n#'\n#' @references Brier, G. W. (1950). Verification of forecasts expressed in terms\n#' of probability. Monthly Weather Review 78: 1–3.\n#'\n#' @export\nbrier_score &lt;- function(obs, scores) mean((scores - obs)^2)\n\nWe will then put in a table all the predictions made in each case: without using counterfactuals, and with using each counterfactual technique applied on women’s characteristics. Since we do not get counterfactual values for men, their predictions remain unchanged in each case. We will therefore complete the dataset with their unchanged predictions.\n\ntb_complement_men &lt;- \n  factuals_aware |&gt; \n  select(id_indiv, sex, sex_origin, income, pred) |&gt; \n  filter(sex_origin == \"Male\")\n\nWe put the predicted values in a table named tb_pred.\n\n\nCodes to create tb_pred.\ntb_pred_aware &lt;- \n  factuals_aware |&gt; \n  select(id_indiv, sex, sex_origin, income, pred) |&gt; \n  mutate(type = \"factual\") |&gt; \n  bind_rows(\n    counterfactuals_aware_naive_women |&gt; \n      select(id_indiv, sex, sex_origin, income, pred) |&gt; \n      bind_rows(tb_complement_men) |&gt; \n      mutate(type = \"naive\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_aware_fpt_women |&gt; \n      select(id_indiv, sex, sex_origin, income, pred) |&gt; \n      bind_rows(tb_complement_men) |&gt; \n      mutate(type = \"fairadapt\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_aware_seq_women |&gt; \n      left_join(\n        adult |&gt; mutate(id_indiv = row_number()) |&gt; \n          select(id_indiv, income), by = \"id_indiv\"\n      ) |&gt; \n      bind_rows(tb_complement_men) |&gt; \n      select(id_indiv, sex, sex_origin, income, pred) |&gt; \n      mutate(type = \"seq\")\n  ) |&gt; \n  mutate(\n    y_binary = as.numeric(income) - 1,\n    pred_class = ifelse(\n      pred &gt; prob_threshold, levels(adult$income)[2], \n      levels(adult$income)[1]\n    ),\n    pred_correct = income == pred_class\n  )\n\ntb_pred_unaware &lt;- \n  factuals_unaware |&gt; \n  select(id_indiv, sex, sex_origin, income, pred) |&gt; \n  mutate(type = \"factual\") |&gt; \n  bind_rows(\n    counterfactuals_unaware_naive_women |&gt; \n      select(id_indiv, sex, sex_origin, income, pred) |&gt; \n      bind_rows(tb_complement_men) |&gt; \n      mutate(type = \"naive\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_unaware_fpt_women |&gt; \n      select(id_indiv, sex, sex_origin, income, pred) |&gt; \n      bind_rows(tb_complement_men) |&gt; \n      mutate(type = \"fairadapt\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_unaware_seq_women |&gt; \n      left_join(\n        adult |&gt; mutate(id_indiv = row_number()) |&gt; \n          select(id_indiv, income), by = \"id_indiv\") |&gt; \n      bind_rows(tb_complement_men) |&gt; \n      select(id_indiv, sex, sex_origin, income, pred) |&gt; \n      mutate(type = \"seq\")\n  ) |&gt; \n  mutate(\n    y_binary = as.numeric(income) - 1,\n    pred_class = ifelse(\n      pred &gt; prob_threshold, levels(adult$income)[2], \n      levels(adult$income)[1]\n    ),\n    pred_correct = income == pred_class\n  )\n\ntb_pred &lt;- \n  tb_pred_aware |&gt; mutate(model = \"aware\") |&gt; \n  bind_rows(\n    tb_pred_unaware |&gt; mutate(model = \"unaware\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, levels = c(\"aware\", \"unaware\"),\n      labels = c(\"Aware model\", \"Unware model\")\n    ),\n    type = factor(type, levels = c(\"factual\", \"naive\", \"fairadapt\", \"seq\"))\n  )\n\n\nWe compute some metrics on the whole sample, in each case:\n\noverall_perf_metrics &lt;- \n  tb_pred |&gt; \n  group_by(model, type) |&gt; \n  summarise(\n    mean = mean(pred),\n    eq_opp_pos = sum(pred * (y_binary == 1)) / (sum(y_binary == 1)),\n    eq_opp_neg = sum(pred * (y_binary == 0)) / (sum(y_binary == 0)),\n    acc = mean(pred_correct),\n    ll = calculate_log_loss(y_binary, pred),\n    bs = brier_score(y_binary, pred),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(sex_origin = \"Whole\")\noverall_perf_metrics\n\n# A tibble: 8 × 9\n  model        type      mean eq_opp_pos eq_opp_neg   acc    ll    bs sex_origin\n  &lt;fct&gt;        &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Aware model  factual  0.222      0.521      0.135 0.838 0.341 0.110 Whole     \n2 Aware model  naive    0.239      0.537      0.151 0.838 0.346 0.111 Whole     \n3 Aware model  fairada… 0.301      0.546      0.197 0.782 0.440 0.144 Whole     \n4 Aware model  seq      0.319      0.551      0.252 0.753 0.496 0.167 Whole     \n5 Unware model factual  0.223      0.518      0.137 0.840 0.342 0.110 Whole     \n6 Unware model naive    0.232      0.532      0.143 0.839 0.342 0.110 Whole     \n7 Unware model fairada… 0.296      0.542      0.193 0.784 0.440 0.144 Whole     \n8 Unware model seq      0.315      0.549      0.246 0.754 0.489 0.164 Whole     \n\n\nAnd then we compute the same metrics but within the group of women and within the group of men.\n\ngroup_perf_metrics &lt;- \n  tb_pred |&gt; \n  group_by(model, type, sex_origin) |&gt; \n  summarise(\n    mean = mean(pred),\n    eq_opp_pos = sum(pred * (y_binary == 1)) / (sum(y_binary == 1)),\n    eq_opp_neg = sum(pred * (y_binary == 0)) / (sum(y_binary == 0)),\n    acc = mean(pred_correct),\n    ll = calculate_log_loss(y_binary, pred),\n    bs = brier_score(y_binary, pred),\n    .groups = \"drop\"\n  )\ngroup_perf_metrics\n\n# A tibble: 16 × 9\n   model        type  sex_origin   mean eq_opp_pos eq_opp_neg   acc    ll     bs\n   &lt;fct&gt;        &lt;fct&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Aware model  fact… Female     0.0749      0.325     0.0528 0.934 0.176 0.0507\n 2 Aware model  fact… Male       0.295       0.547     0.188  0.791 0.423 0.140 \n 3 Aware model  naive Female     0.125       0.455     0.0953 0.932 0.189 0.0531\n 4 Aware model  naive Male       0.295       0.547     0.188  0.791 0.423 0.140 \n 5 Aware model  fair… Female     0.311       0.543     0.217  0.763 0.474 0.154 \n 6 Aware model  fair… Male       0.295       0.547     0.188  0.791 0.423 0.140 \n 7 Aware model  seq   Female     0.369       0.574     0.350  0.677 0.644 0.221 \n 8 Aware model  seq   Male       0.295       0.547     0.188  0.791 0.423 0.140 \n 9 Unware model fact… Female     0.103       0.417     0.0754 0.937 0.177 0.0503\n10 Unware model fact… Male       0.282       0.531     0.176  0.791 0.424 0.140 \n11 Unware model naive Female     0.103       0.417     0.0754 0.937 0.177 0.0503\n12 Unware model naive Male       0.295       0.547     0.188  0.791 0.423 0.140 \n13 Unware model fair… Female     0.299       0.529     0.204  0.770 0.474 0.154 \n14 Unware model fair… Male       0.295       0.547     0.188  0.791 0.423 0.140 \n15 Unware model seq   Female     0.355       0.556     0.337  0.680 0.623 0.214 \n16 Unware model seq   Male       0.295       0.547     0.188  0.791 0.423 0.140 \n\n\nWe compute the Counterfactual Demographic Parity:\n\npred_women_factuals &lt;- \n  tb_pred |&gt; filter(type == \"factual\") |&gt; \n  filter(sex_origin == \"Female\") |&gt; \n  select(model, id_indiv, pred_origin = pred)\n\ncdp &lt;- tb_pred |&gt; \n  filter(sex_origin == \"Female\") |&gt; \n  left_join(pred_women_factuals, by = c(\"id_indiv\", \"model\")) |&gt; \n  group_by(model, type) |&gt; \n  summarise(\n    CDP = mean(pred - pred_origin),\n    .groups = \"drop\"\n  )\n\nThe summary of the metrics are shown in Table 13.1.\n\n\nCodes used to create the Table.\ntbl_print &lt;- \n  group_perf_metrics |&gt; filter(sex_origin == \"Female\") |&gt; \n  left_join(cdp, by = c(\"model\", \"type\")) |&gt; \n  pivot_longer(cols = -c(\"model\", \"type\", \"sex_origin\")) |&gt; \n  pivot_wider(names_from = type, values_from = value) |&gt; \n  select(-sex_origin) |&gt; \n  left_join(\n    group_perf_metrics |&gt; filter(sex_origin == \"Male\" & type == \"factual\") |&gt; \n      pivot_longer(cols = -c(\"model\", \"type\", \"sex_origin\"), values_to = \"factual_men\") |&gt; \n      select(model, name, factual_men),\n    by = c(\"model\", \"name\")\n  ) |&gt; \n  left_join(\n    overall_perf_metrics |&gt; \n      pivot_longer(cols = -c(\"model\", \"type\", \"sex_origin\"), values_to = \"factual_whole\") |&gt; \n      filter(sex_origin == \"Whole\", type == \"factual\") |&gt; \n      select(model, name, factual_whole),\n    by = c(\"model\", \"name\")\n  ) |&gt; \n  select(\n    model, name, factual_whole, factual_men, factual_women = factual,\n    naive, fairadapt, seq\n  ) |&gt; \n  mutate(\n    name = factor(\n      name,\n      levels = c(\"CDP\", \"mean\", \"eq_opp_pos\", \"eq_opp_neg\", \"acc\", \"ll\", \"bs\"),\n      labels = c(\"CDP\", \"Mean\", \"Eq. Opp. Y=1\", \"Eq. Opp Y=0\", \"Accuracy\", \"Log-loss\", \"Brier Score\")\n    )\n  ) |&gt; \n  arrange(model, name)\n\ntbl_print[, -1] |&gt; \n  knitr::kable(\n    digits = 2,\n    col.names = c(\n      \"Metric\", \"Factual\", \"Factual\", \"Factual\", \"Naive\", \"Fairadapt\", \n      \"Seq. Transport\"\n    )\n  ) |&gt; \n  kableExtra::kable_styling() |&gt; \n  # kableExtra::pack_rows(index = table(tbl_print$sex_origin))\n  # kableExtra::collapse_rows(columns = 1, valign = \"top\")\n  kableExtra::add_header_above(\n    c(\" \" = 1, \"Whole\" = \"1\", \"Men\" = 1, \"Women\" = 4)\n  ) |&gt; \n  kableExtra::pack_rows(index = table(tbl_print$model))\n\n\n\n\nTable 13.1: Metrics computed on scores predicted by the classifier based on the factuals or the different versions of the counterfactuals, for the aware model (sensitive variable used to train the classifier) and the unaware model (sentitive variable not provided to train the classifier).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhole\n\n\nMen\n\n\nWomen\n\n\n\nMetric\nFactual\nFactual\nFactual\nNaive\nFairadapt\nSeq. Transport\n\n\n\n\nAware model\n\n\nCDP\nNA\nNA\n0.00\n0.05\n0.24\n0.29\n\n\nMean\n0.22\n0.30\n0.07\n0.12\n0.31\n0.37\n\n\nEq. Opp. Y=1\n0.52\n0.55\n0.32\n0.46\n0.54\n0.57\n\n\nEq. Opp Y=0\n0.13\n0.19\n0.05\n0.10\n0.22\n0.35\n\n\nAccuracy\n0.84\n0.79\n0.93\n0.93\n0.76\n0.68\n\n\nLog-loss\n0.34\n0.42\n0.18\n0.19\n0.47\n0.64\n\n\nBrier Score\n0.11\n0.14\n0.05\n0.05\n0.15\n0.22\n\n\nUnware model\n\n\nCDP\nNA\nNA\n0.00\n0.00\n0.20\n0.25\n\n\nMean\n0.22\n0.28\n0.10\n0.10\n0.30\n0.36\n\n\nEq. Opp. Y=1\n0.52\n0.53\n0.42\n0.42\n0.53\n0.56\n\n\nEq. Opp Y=0\n0.14\n0.18\n0.08\n0.08\n0.20\n0.34\n\n\nAccuracy\n0.84\n0.79\n0.94\n0.94\n0.77\n0.68\n\n\nLog-loss\n0.34\n0.42\n0.18\n0.18\n0.47\n0.62\n\n\nBrier Score\n0.11\n0.14\n0.05\n0.05\n0.15\n0.21\n\n\n\n\n\n\n\n\n\n\n\n\nLaTeX code\nknitr::kable(\n  tbl_print[, -1], format = \"latex\", booktabs = TRUE, digits = 2,\n) |&gt; \n  kableExtra::kable_styling(\"striped\", full_width = F) %&gt;%\n  kableExtra::add_header_above(\n    c(\" \" = 1, \"Whole\" = 1, \"Men\" = 1, \"Women\" = 4)\n  ) |&gt; \n  kableExtra::pack_rows(index = table(tbl_print$model))\n\n\n\n# Brouillon\ntb_pred$type |&gt; unique()\n\n[1] factual   naive     fairadapt seq      \nLevels: factual naive fairadapt seq\n\nlvl_neg &lt;- levels(tb_pred$income)[1]\nlvl_pos &lt;- levels(tb_pred$income)[2]\n\ntb_pred |&gt; \n  group_by(model, type, sex_origin) |&gt; \n  summarise(\n    TP = sum(income == lvl_pos & pred_class == lvl_pos),\n    FP = sum(income == lvl_neg & pred_class == lvl_pos),\n    FN = sum(income == lvl_pos & pred_class == lvl_neg),\n    TN = sum(income == lvl_neg & pred_class == lvl_neg),\n    P = TP + FN,\n    N = FP + TN\n  ) |&gt; \n  rowwise() |&gt; \n  mutate(\n    TPR = TP/P,\n    FPR = FN / N\n  ) |&gt; \n  group_by(model, type) |&gt; \n  mutate(\n    eq_odds_diff = abs(diff(TPR))\n  )\n\n`summarise()` has grouped output by 'model', 'type'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 16 × 12\n# Groups:   model, type [8]\n   model       type  sex_origin    TP    FP    FN    TN     P     N   TPR    FPR\n   &lt;fct&gt;       &lt;fct&gt; &lt;chr&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Aware model fact… Female        14     4    40   604    54   608 0.259 0.0658\n 2 Aware model fact… Male         218    98   182   840   400   938 0.545 0.194 \n 3 Aware model naive Female        24    15    30   593    54   608 0.444 0.0493\n 4 Aware model naive Male         218    98   182   840   400   938 0.545 0.194 \n 5 Aware model fair… Female       106    71    86   399   192   470 0.552 0.183 \n 6 Aware model fair… Male         218    98   182   840   400   938 0.545 0.194 \n 7 Aware model seq   Female        33   193    21   415    54   608 0.611 0.0345\n 8 Aware model seq   Male         218    98   182   840   400   938 0.545 0.194 \n 9 Unware mod… fact… Female        22    10    32   598    54   608 0.407 0.0526\n10 Unware mod… fact… Male         215    94   185   844   400   938 0.538 0.197 \n11 Unware mod… naive Female        22    10    32   598    54   608 0.407 0.0526\n12 Unware mod… naive Male         218    98   182   840   400   938 0.545 0.194 \n13 Unware mod… fair… Female       105    65    87   405   192   470 0.547 0.185 \n14 Unware mod… fair… Male         218    98   182   840   400   938 0.545 0.194 \n15 Unware mod… seq   Female        30   188    24   420    54   608 0.556 0.0395\n16 Unware mod… seq   Male         218    98   182   840   400   938 0.545 0.194 \n# ℹ 1 more variable: eq_odds_diff &lt;dbl&gt;\n\n\n\n\n\n\nHardt, Moritz, Eric Price, and Nati Srebro. 2016. “Equality of Opportunity in Supervised Learning.” Advances in Neural Information Processing Systems 29: 3315–23.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data Adaptation with Quantile Preservation.” Journal of Machine Learning Research 21 (242): 1–44.",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Adult Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html",
    "href": "example-compas.html",
    "title": "14  COMPAS Dataset",
    "section": "",
    "text": "14.1 Classifier\nWe load functions defined in our small package (notably, split_dataset()):\nlibrary(devtools)\nload_all(\"../seqtransfairness/\")\n\nℹ Loading seqtransfairness\nWe fit a logistic regression model on the data to predict the outcome binary variable. First, we split the dataset into two sets: train (70%) and test (30%).\nseed &lt;- 2025\nsets &lt;- split_dataset(compas, seed, train_ratio = 0.7)\ndata_train &lt;- sets$data_train\ndata_test &lt;- sets$data_test\nAs in Chapter 7, we train two models:\nTo do so, we use the training function, log_reg_train(), defined in our small package. When the two models are trained, we extract the predicted values on both the train set and the test set.\n# Unaware logistic regression classifier (model without S)\npred_unaware &lt;- log_reg_train(\n  data_train, data_test, s = s, y = y, type = \"unaware\"\n)\npred_unaware_train &lt;- pred_unaware$pred_train\npred_unaware_test &lt;- pred_unaware$pred_test\n\n# Aware logistic regression classifier (model with S)\npred_aware &lt;- log_reg_train(\n  data_train, data_test, s = s, y = y, type = \"aware\"\n)\npred_aware_train &lt;- pred_aware$pred_train\npred_aware_test &lt;- pred_aware$pred_test\nWe create a table for each model, with the sensitive attribute and the predicted value by the model (\\(\\hat{y}\\)), only for observations from the test set.\ndf_test_unaware &lt;- tibble(\n  S = data_test |&gt; pull(!!s),\n  pred = pred_unaware_test\n)\n\ndf_test_aware &lt;- tibble(\n  S = data_test |&gt; pull(!!s),\n  pred = pred_aware_test\n)",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html#classifier",
    "href": "example-compas.html#classifier",
    "title": "14  COMPAS Dataset",
    "section": "",
    "text": "unaware logistic regression classifier: model without including the sensitive attribute.\naware logistic regression classifier: model with the sensitive attribute included in the set of features.\n\n\n\n\n\n\n14.1.1 Predictions\nWe predict values with the unaware model on the factuals:\n\nmodel_unaware &lt;- pred_unaware$model\npred_unaware_all &lt;- predict(\n  model_unaware,\n  newdata = compas,\n  type = \"response\"\n)\n\nAnd with the aware model:\n\nmodel_aware &lt;- pred_aware$model\npred_aware_all &lt;- predict(\n  model_aware,\n  newdata = compas,\n  type = \"response\"\n)\n\n\n\n14.1.2 Saving Objects\n\nsave(pred_aware, file = \"../data/pred_aware_compas.rda\")\nsave(pred_unaware, file = \"../data/pred_unaware_compas.rda\")\nsave(pred_unaware_all, file = \"../data/pred_unaware_all_compas.rda\")\nsave(pred_aware_all, file = \"../data/pred_aware_all_compas.rda\")",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html#naive-approach-ceteris-paribus",
    "href": "example-compas.html#naive-approach-ceteris-paribus",
    "title": "14  COMPAS Dataset",
    "section": "14.2 Naive approach: ceteris paribus",
    "text": "14.2 Naive approach: ceteris paribus\nLet us change the sensitive attribute of individuals from the source group (Non-White) to the target group (White). Then, we use both models (unaware and aware) to predict the target binary variable.\n\npred_unaware_naive_nonwhite &lt;- predict(\n  model_unaware,\n  newdata = compas |&gt; filter(race == \"Non-White\") |&gt; mutate(race = \"White\"),\n  type = \"response\"\n)\npred_aware_naive_nonwhite &lt;- predict(\n  model_aware,\n  newdata = compas |&gt; filter(race == \"Non-White\") |&gt;  mutate(race = \"White\"),\n  type = \"response\"\n)\n\nind_nonwhite &lt;- which(compas$race == \"Non-White\")\nind_white &lt;- which(compas$race == \"White\")\n\ncounterfactuals_unaware_naive_nonwhite &lt;- \n  compas |&gt; filter(race == \"Non-White\") |&gt; \n  mutate(\n    race_origin = race,\n    race = \"White\",\n    pred = pred_unaware_naive_nonwhite,\n    type = \"counterfactual\",\n    id_indiv = ind_nonwhite\n  )\ncounterfactuals_aware_naive_nonwhite &lt;- \n  compas |&gt; filter(race == \"Non-White\") |&gt; \n  mutate(\n    race_origin = race,\n    race = \"White\",\n    pred = pred_aware_naive_nonwhite,\n    type = \"counterfactual\",\n    id_indiv = ind_nonwhite\n  )\n\n\n14.2.1 Unaware Model\nLet us have a look at the distribution of the predicted scores of the classifier in both groups, when the predictions are made after setting the race attribute of all Non-White to White. Since the model does not use the sensitive attribute, changing it will result in absolutely no change in its predictions in this case.\nThe predicted values using the initial characteristics (the factuals), for the unaware model are stored in the object pred_unaware_all. We put in a table the initial characteristics (factuals) and the prediction made by the unaware model:\n\nfactuals_unaware &lt;-\n  compas |&gt; \n  as_tibble() |&gt;\n  mutate(\n    race_origin = race,\n    pred = pred_unaware_all,\n    type = \"factual\"\n  ) |&gt; \n    mutate(id_indiv = row_number())\n\n\nunaware_naive_nonwhite &lt;- \n  factuals_unaware |&gt; mutate(race_origin = race) |&gt; \n  bind_rows(counterfactuals_unaware_naive_nonwhite)\n\nThe unaware model is blind to the sensitive attribute. Hence, changing the sensitive attribute does not affect the predicted scores.\n\nggplot(\n  unaware_naive_nonwhite |&gt; mutate(\n    group = case_when(\n      race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n      race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n      race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n      )\n    )\n  ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 14.3: Unaware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for ccounterfactual of Non-White individuals and factuals of White individuals Again, since the model is blind to the sensitive attribute, the distributions are perfectly aligned.\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_naive_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"Non-White\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.4: Distribution of Predicted Scores for Minority Class (Non-White), Unaware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\n\n\n14.2.2 Aware Model\nWe turn to the aware model. This time, the sensitive attribute is used by the classifier when it is trained. Hence, changing the sensitive attribute of individuals in the source group to that of the target group may change the predicted values for the binary outcome variable.\nThe predicted values by the model, on the initial characteristics (on the factuals) are stored in the pred_aware_all object.\nWe create a tibble with the factuals and the predictions by the aware model:\n\nfactuals_aware &lt;-\n  compas |&gt; \n  as_tibble() |&gt;\n  mutate(\n    race_origin = race,\n    pred = pred_aware_all,\n    type = \"factual\"\n  ) |&gt; \n    mutate(id_indiv = row_number())\n\n\naware_naive_nonwhite &lt;- \n  factuals_aware |&gt; mutate(race_origin = race) |&gt; \n  bind_rows(counterfactuals_aware_naive_nonwhite)\n\n\nggplot(\n  aware_naive_nonwhite |&gt; mutate(\n    group = case_when(\n      race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n      race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n      race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n      )\n    )\n  ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 14.5: Aware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for counterfactual of Non-White individuals and factuals of White individuals\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_naive_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"Non-White\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"naive\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.6: Distribution of Predicted Scores for Minority Class (Non-White), Aware model, Sensitive: Race, Non-White -&gt; White",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html#sec-compas-dataset-fairadapt",
    "href": "example-compas.html#sec-compas-dataset-fairadapt",
    "title": "14  COMPAS Dataset",
    "section": "14.3 Fairadapt",
    "text": "14.3 Fairadapt\nWe have already assumed a causal graph (see Figure 14.2).\nLet us consider that we want to build counterfactuals for Non-White individuals: what if the individual had been White and not Non-White?\nLet us have a look at the levels of our sensitive variable:\n\nlevels(compas |&gt; pull(!!s))\n\n[1] \"Non-White\" \"White\"    \n\n\nTwo configurations will be considered in turn:\n\nThe reference class consists of White individuals, and fairadapt will be used to obtain the counterfactual values for Non-White individuals as if they had been White individuals.\nThe reference class consists of Non-White individuals, and fairadapt will be used to obtain the counterfactual values for White individuals as if they had been Non-White individuals.\n\n\n# Non-White (factuals) --&gt; White (counterfactuals)\ndf_fpt &lt;- compas |&gt; mutate(race = fct_relevel(race, \"Non-White\", after = Inf))\nfpt_model_nonwhite &lt;- fairadapt(\n  two_year_recid ~ .,\n  train.data = df_fpt,\n  prot.attr = \"race\", adj.mat = adj_mat,\n  quant.method = rangerQuants\n)\nadapt_df_nonwhite &lt;- adaptedData(fpt_model_nonwhite)\n\n# White (factuals) --&gt; Non-White (counterfactuals)\ndf_fpt &lt;- df_fpt |&gt; mutate(race = fct_relevel(race, \"White\", after = Inf))\nfpt_model_white &lt;- fairadapt(\n  two_year_recid ~ .,\n  train.data = df_fpt,\n  prot.attr = \"race\", adj.mat = adj_mat,\n  quant.method = rangerQuants\n)\nadapt_df_white &lt;- adaptedData(fpt_model_white)\n\nLet us wrap up:\n\nwe have two predictive models for the target variable (whether the person has re-offended within two years):\n\nunaware (without S)\naware (with S)\n\nwe have the counterfactual characteristics obtained with fairadapt in two situations depending on the reference class:\n\nNon-White individuals as reference\nWhite individuals as reference.\n\n\nThe predictive models will be used to compare predictions made using:\n\nRaw characteristics (initial characteristics).\nCharacteristics possibly altered through fairadapt for individuals who were not in the reference group (i.e., using counterfactuals).\n\n\n14.3.1 Unaware Model\nLet us build a dataset containing only counterfactual characteristics obtained with fairadapt.\n\npred_unaware_fpt_nonwhite &lt;- predict(\n  model_unaware, \n  newdata = adapt_df_nonwhite[ind_nonwhite, ], \n  type = \"response\"\n)\npred_unaware_fpt_white &lt;- predict(\n  model_unaware, \n  newdata = adapt_df_white[ind_white, ],\n  type = \"response\"\n)\n\nWe create a table with the counterfactual characteristics and the prediction by the unaware model:\n\ncounterfactuals_unaware_fpt_nonwhite &lt;- \n  as_tibble(adapt_df_nonwhite[ind_nonwhite, ]) |&gt; \n  mutate(\n    race_origin = compas$race[ind_nonwhite],\n    pred = pred_unaware_fpt_nonwhite,\n    type = \"counterfactual\",\n    id_indiv = ind_nonwhite\n  )\n\ncounterfactuals_unaware_fpt_white &lt;- \n  as_tibble(adapt_df_white[ind_white, ]) |&gt; \n  mutate(\n    race_origin = compas$race[ind_white],\n    pred = pred_unaware_fpt_white,\n    type = \"counterfactual\",\n    id_indiv = ind_white\n  )\n\nWe merge the two datasets, factuals_unaware and counterfactuals_unaware_fpt_nonwhite (or counterfactuals_unaware_fpt_white) in a single one.\n\nunaware_fpt_nonwhite &lt;- \n  factuals_unaware |&gt; mutate(race_origin = race) |&gt; \n  bind_rows(counterfactuals_unaware_fpt_nonwhite)\n  \nunaware_fpt_white &lt;- \n  factuals_unaware |&gt; mutate(race_origin = race) |&gt; \n  bind_rows(counterfactuals_unaware_fpt_white)\n\n\nNon-White -&gt; WhiteWhite -&gt; Non-White\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.7: Unaware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\",\n        race_origin ==\"White\" & race == \"Non-White\" ~ \"White -&gt; Non-White (Counterfactual)\",\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Non-White (Counterfactual)\", \"Non-White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Non-White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Non-White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.8: Unaware model, Sensitive: Race, White -&gt; Non-White\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for counterfactual of Non-White individuals and factuals of White individuals.\n\nNon-White -&gt; WhiteWhite -&gt; Non-White\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"Non-White\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.9: Distribution of Predicted Scores for Minority Class (Non-White), Unaware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\",\n        race_origin ==\"White\" & race == \"Non-White\" ~ \"White -&gt; Non-White (Counterfactual)\",\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Non-White (Counterfactual)\", \"Non-White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"White\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.10: Distribution of Predicted Scores for Minority Class (White), Unaware model, Sensitive: Race, White -&gt; Non-White\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.3.2 Aware Model\nNow, we turn to the model that includes the sensitive attribute, i.e., the aware model. Let us get the predicted values for the counterfactuals, using the aware model:\n\npred_aware_fpt_nonwhite &lt;- predict(\n  model_aware, \n  newdata = adapt_df_nonwhite[ind_nonwhite, ], \n  type = \"response\"\n)\npred_aware_fpt_white &lt;- predict(\n  model_aware, \n  newdata = adapt_df_white[ind_white, ],\n  type = \"response\"\n)\n\nThen, we create a table with the counterfactuals and the predicted value by the aware model:\n\ncounterfactuals_aware_fpt_nonwhite &lt;- \n  as_tibble(adapt_df_nonwhite[ind_nonwhite, ]) |&gt; \n  mutate(\n    race_origin = compas$race[ind_nonwhite],\n    pred = pred_aware_fpt_nonwhite,\n    type = \"counterfactual\",\n    id_indiv = ind_nonwhite\n  )\n\ncounterfactuals_aware_fpt_white &lt;- \n  as_tibble(adapt_df_white[ind_white, ]) |&gt; \n  mutate(\n    race_origin = compas$race[ind_white],\n    pred = pred_aware_fpt_white,\n    type = \"counterfactual\",\n    id_indiv = ind_white\n  )\n\nWe merge the two datasets, factuals_unaware and counterfactuals_aware_fpt_nonwhite (or counterfactuals_aware_fpt_white) in a single one.\n\n# dataset with counterfactuals, for aware model\naware_fpt_nonwhite &lt;- \n  factuals_aware |&gt; mutate(rac_origin = race) |&gt; \n  bind_rows(counterfactuals_aware_fpt_nonwhite)\n  \naware_fpt_white &lt;- \n  factuals_aware |&gt; mutate(race_origin = race) |&gt; \n  bind_rows(counterfactuals_aware_fpt_white)\n\n\nNon-White -&gt; WhiteWhite -&gt; Non-White\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.11: Aware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\",\n        race_origin ==\"White\" & race == \"Non-White\" ~ \"White -&gt; Non-White (Counterfactual)\",\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Non-White (Counterfactual)\", \"Non-White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Non-White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"Non-White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.12: Aware model, Sensitive: Race, Reference: Non-White individuals\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores for counterfactual of Non-White individuals and factuals of White individuals.\n\nNon-White -&gt; WhiteWhite -&gt; Non-White\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"Non-White\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"fairadapt\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.13: Distribution of Predicted Scores for Minority Class (Non-White), Aware model, Sensitive: Race, Reference: White individuals\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_fpt_white |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\",\n        race_origin ==\"White\" & race == \"Non-White\" ~ \"White -&gt; Non-White (Counterfactual)\",\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"White (Original)\", \"White -&gt; Non-White (Counterfactual)\", \"Non-White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"White\"),\n  mapping = aes(x = pred, fill = group)) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"White (Original)\" = colours_all[[\"source\"]],\n      \"White -&gt; Non-White (Counterfactual)\" = colours_all[[\"fairadapt\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.14: Distribution of Predicted Scores for Minority Class (White), Aware model, Sensitive: Race, Reference: Non-White individuals",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html#sequential-transport",
    "href": "example-compas.html#sequential-transport",
    "title": "14  COMPAS Dataset",
    "section": "14.4 Sequential Transport",
    "text": "14.4 Sequential Transport\nWe now turn to sequential transport (the methodology developed in our paper). We use the seq_trans() function defined in our small package to perform a fast sequential transport on causal graph.\nWe use the same causal graph as in Section 14.3.\n\nsequential_transport &lt;- seq_trans(\n  data = compas, adj = adj_mat,\n  s = \"race\", S_0 = \"Non-White\", y = \"two_year_recid\"\n)\n\nTransporting  age \nTransporting  sex \nTransporting  juv_misd_count \nTransporting  juv_other_count \nTransporting  juv_fel_count \nTransporting  priors_count \nTransporting  c_charge_degree \n# weights:  8 (7 variable)\ninitial  value 1700.983181 \niter  10 value 1591.143276\nfinal  value 1591.092129 \nconverged\n\n\nWe build a dataset with the sensitive attribute of Non-White individuals changed to White individuals, and their characteristics changed to their transported characteristics:\n\ndf_counterfactuals_seq_nonwhite &lt;- \n  as_tibble(sequential_transport$transported) |&gt; \n  mutate(\n    id_indiv = ind_nonwhite,\n    race_origin = \"Non-White\",\n    race = \"White\"\n  )\n\nWe make predictions based on those counterfactuals obtained with sequential transport, on both models (the unaware model, and the aware model):\n\npred_seq_unaware &lt;- predict(\n  model_unaware, newdata = df_counterfactuals_seq_nonwhite, type = \"response\"\n)\n\npred_seq_aware &lt;- predict(\n  model_aware, newdata = df_counterfactuals_seq_nonwhite, type = \"response\"\n)\n\n\ncounterfactuals_unaware_seq_nonwhite &lt;- \n  df_counterfactuals_seq_nonwhite |&gt; \n  mutate(pred = pred_seq_unaware, type = \"counterfactual\")\ncounterfactuals_aware_seq_nonwhite &lt;- \n  df_counterfactuals_seq_nonwhite |&gt; \n  mutate(pred = pred_seq_aware, type = \"counterfactual\")\n\nLet us put in a single table the predictions made by the classifier (either aware or unaware) on Non-White individuals based on their factual characteristics, and those made based on the counterfactuals:\n\naware_seq_nonwhite &lt;- bind_rows(\n  factuals_aware |&gt; mutate(id_indiv = row_number(), race_origin = race), \n  counterfactuals_aware_seq_nonwhite |&gt; mutate(S_origin = \"Non-White\")\n)\nunaware_seq_nonwhite &lt;- bind_rows(\n  factuals_unaware |&gt; mutate(id_indiv = row_number(), race_origin = race), \n  counterfactuals_unaware_seq_nonwhite |&gt; mutate(S_origin = \"Non-White\")\n)\n\n\nUnawareAware\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_seq_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.15: Unaware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_seq_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ),\n  aes(x = pred, fill = group, colour = group)\n) +\n  geom_histogram(\n    mapping = aes(\n      y = after_stat(density)), alpha = 0.5, colour = NA,\n    position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.3, linewidth = 1) +\n  facet_wrap(~race) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.16: Aware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\n\n\n\nThen, we focus on the distribution of predicted scores forcounterfactual of Non-White individuals and factuals of White individuals.\n\nUnawareAware\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = unaware_seq_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"Non-White\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.17: Distribution of Predicted Scores for Minority Class (Non-White), Unaware model, Sensitive: Race, Non-White -&gt; White\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\nggplot(\n  data = aware_seq_nonwhite |&gt; \n    mutate(\n      group = case_when(\n        race_origin ==\"Non-White\" & race == \"Non-White\" ~ \"Non-White (Original)\",\n        race_origin ==\"Non-White\" & race == \"White\" ~ \"Non-White -&gt; White (Counterfactual)\",\n        race_origin ==\"White\" & race == \"White\" ~ \"White (Original)\"\n      ),\n      group = factor(\n        group, \n        levels = c(\n          \"Non-White (Original)\", \"Non-White -&gt; White (Counterfactual)\", \"White (Original)\"\n        )\n      )\n    ) |&gt; \n    filter(race_origin ==\"Non-White\"),\n  mapping = aes(x = pred, fill = group)\n) +\n  geom_histogram(\n    mapping = aes(y = after_stat(density)), \n    alpha = 0.5, position = \"identity\", binwidth = 0.05\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  scale_colour_manual(\n    NULL, values = c(\n      \"Non-White (Original)\" = colours_all[[\"source\"]],\n      \"Non-White -&gt; White (Counterfactual)\" = colours_all[[\"seq\"]],\n      \"White (Original)\" = colours_all[[\"reference\"]]\n    )\n  ) +\n  labs(\n    x = \"Predictions for Y\",\n    y = \"Density\"\n  ) +\n  global_theme() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 14.18: Distribution of Predicted Scores for Minority Class (Non-White), Aware model, Sensitive: Race, Non-White -&gt; White",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html#comparison",
    "href": "example-compas.html#comparison",
    "title": "14  COMPAS Dataset",
    "section": "14.5 Comparison",
    "text": "14.5 Comparison\nLet us now compare the results.\n\nUnaware ModelAware Model\n\n\n\ntb_unaware &lt;- \n  factuals_unaware |&gt; mutate(counterfactual = \"none\") |&gt;\n  # Naive\n  bind_rows(\n    counterfactuals_unaware_naive_nonwhite |&gt; mutate(counterfactual = \"naive\")\n  ) |&gt; \n  # Fairadapt\n  bind_rows(\n    counterfactuals_unaware_fpt_nonwhite |&gt; mutate(counterfactual = \"fpt\")\n  ) |&gt; \n  # Sequential transport\n  bind_rows(\n    counterfactuals_unaware_seq_nonwhite |&gt; mutate(counterfactual = \"seq\")\n  )\n\n\n\n\ntb_aware &lt;- \n  factuals_aware |&gt; mutate(counterfactual = \"none\") |&gt; \n  # Naive\n  bind_rows(\n    counterfactuals_aware_naive_nonwhite |&gt; mutate(counterfactual = \"naive\")\n  ) |&gt; \n  # Fairadapt\n  bind_rows(\n    counterfactuals_aware_fpt_nonwhite |&gt; mutate(counterfactual = \"fpt\")\n  ) |&gt; \n  # Sequential transport\n  bind_rows(\n    counterfactuals_aware_seq_nonwhite |&gt; mutate(counterfactual = \"seq\")\n  )\n\n\n\n\nLet us compare the densities of the predicted values.\n\nUnaware modelAware model\n\n\n\n\nCodes used to create the Figure.\n# Factuals\ntb_unaware_factuals &lt;- tb_unaware |&gt; filter(counterfactual == \"none\")\n# Predicted values\npred_unaware_factuals_nonwhite &lt;- tb_unaware_factuals |&gt; filter(race == \"Non-White\") |&gt; pull(\"pred\")\npred_unaware_factuals_white &lt;- tb_unaware_factuals |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_factuals_nonwhite &lt;- density(pred_unaware_factuals_nonwhite)\nd_unaware_factuals_white &lt;- density(pred_unaware_factuals_white)\n\npar(mfrow = c(3, 1), mar = c(2, 2, 0, 0))\nx_lim &lt;- c(0, .8)\ny_lim &lt;- c(0, 10)\n\n# Naive\ntb_unaware_naive &lt;- tb_unaware |&gt; filter(counterfactual == \"naive\")\n# Predicted values, focusing on Non-White --&gt; White\npred_unaware_naive_nonwhite_star &lt;- tb_unaware_naive |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_naive_nonwhite_star &lt;- density(pred_unaware_naive_nonwhite_star)\n\nplot(\n  d_unaware_factuals_nonwhite,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_nonwhite, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_naive_nonwhite_star, col = alpha(colours_all[[\"naive\"]], .5), border = NA)\npos_arrow_ref &lt;- .6\ntext(x = pos_arrow_ref, y = 8, \"Factuals - White\", col = colours_all[[\"reference\"]])\nind_min_ref &lt;- which.min(abs(d_unaware_factuals_white$x - pos_arrow_ref))\narrows(\n  x1 = d_unaware_factuals_white$x[ind_min_ref],\n  y1 = d_unaware_factuals_white$y[ind_min_ref],\n  x0 = pos_arrow_ref, \n  y0 = 7,\n  length = 0.05, col = colours_all[[\"reference\"]]\n)\ntext(x = .09, y = 8, \"Naive\", col = colours_all[[\"naive\"]])\n\n\n# Fairadapt\ntb_unaware_fpt &lt;- tb_unaware |&gt; filter(counterfactual == \"fpt\")\n# Predicted values, focusing on Non-White --&gt; White\npred_unaware_fpt_nonwhite_star &lt;- \n  tb_unaware_fpt |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_fpt_nonwhite_star &lt;- density(pred_unaware_fpt_nonwhite_star)\n\nplot(\n  d_unaware_factuals_nonwhite,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_nonwhite, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_fpt_nonwhite_star, col = alpha(colours_all[[\"fairadapt\"]], .5), border = NA)\ntext(x = .15, y = 6, \"Factuals - Non-White\", col = colours_all[[\"source\"]])\npos_arrow &lt;- .07\nind_min &lt;- which.min(abs(d_unaware_factuals_nonwhite$x - pos_arrow))\narrows(\n  x1 = d_unaware_factuals_nonwhite$x[ind_min],\n  y1 = d_unaware_factuals_nonwhite$y[ind_min],\n  x0 = .15, \n  y0 = 5,\n  length = 0.05, col = colours_all[[\"source\"]]\n)\ntext(x = .4, y = 6, \"fairadapt\", col = colours_all[[\"fairadapt\"]])\n\n\n# Sequential transport\ntb_unaware_seq &lt;- tb_unaware |&gt; filter(counterfactual == \"seq\")\n# Predicted values, focusing on Non-White --&gt; White\npred_unaware_seq_nonwhite_star &lt;- tb_unaware_seq |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_unaware_seq_nonwhite_star &lt;- density(pred_unaware_seq_nonwhite_star)\n\nplot(\n  d_unaware_factuals_nonwhite,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_unaware_factuals_nonwhite, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_unaware_factuals_white, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_unaware_seq_nonwhite_star, col = alpha(colours_all[[\"seq\"]], .5), border = NA)\ntext(x = .4, y = 6, \"Seq. T.\", col = colours_all[[\"seq\"]])\n\n\n\n\n\nFigure 14.19: Densities of predicted scores for Non-White individuals with factuals and White individuals counterfactuals. The yellow dashed line corresponds to the density of predicted scores for Non-White individuals, using factuals.\n\n\n\n\n\n\n\n\n\n\n\n\nCodes used to create the Figure.\n# Factuals\ntb_aware_factuals &lt;- tb_aware |&gt; filter(counterfactual == \"none\")\n# Predicted values\npred_aware_factuals_nonwhite &lt;- tb_aware_factuals |&gt; filter(race == \"Non-White\") |&gt; pull(\"pred\")\npred_aware_factuals_white &lt;- tb_aware_factuals |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_factuals_nonwhite &lt;- density(pred_aware_factuals_nonwhite)\nd_aware_factuals_white &lt;- density(pred_aware_factuals_white)\n\npar(mfrow = c(3, 1), mar = c(2, 2, 0, 0))\nx_lim &lt;- c(0, .8)\ny_lim &lt;- c(0, 16)\n\n# Naive\ntb_aware_naive &lt;- tb_aware |&gt; filter(counterfactual == \"naive\")\n# Predicted values, focusing on Non-White --&gt; White\npred_aware_naive_nonwhite_star &lt;- tb_aware_naive |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_naive_nonwhite_star &lt;- density(pred_aware_naive_nonwhite_star)\n\nplot(\n  d_aware_factuals_nonwhite,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_nonwhite, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_naive_nonwhite_star, col = alpha(colours_all[[\"naive\"]], .5), border = NA)\ntext(x = .15, y = 13, \"Factuals - Non-White\", col = colours_all[[\"source\"]])\npos_arrow &lt;- .03\nind_min &lt;- which.min(abs(d_aware_factuals_nonwhite$x - pos_arrow))\narrows(\n  x1 = d_aware_factuals_nonwhite$x[ind_min],\n  y1 = d_aware_factuals_nonwhite$y[ind_min],\n  x0 = .15, \n  y0 = 11,\n  length = 0.05, col = colours_all[[\"source\"]]\n)\npos_arrow_ref &lt;- .6\ntext(x = pos_arrow_ref, y = 13, \"Factuals - White\", col = colours_all[[\"reference\"]])\nind_min_ref &lt;- which.min(abs(d_aware_factuals_white$x - pos_arrow_ref))\narrows(\n  x1 = d_aware_factuals_white$x[ind_min_ref],\n  y1 = d_aware_factuals_white$y[ind_min_ref],\n  x0 = pos_arrow_ref, \n  y0 = 11,\n  length = 0.05, col = colours_all[[\"reference\"]]\n)\ntext(x = .4, y = 6, \"Naive\", col = colours_all[[\"naive\"]])\n\n\n# Fairadapt\ntb_aware_fpt &lt;- tb_aware |&gt; filter(counterfactual == \"fpt\")\n# Predicted values, focusing on Non-White --&gt; White\npred_aware_fpt_nonwhite_star &lt;- \n  tb_aware_fpt |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_fpt_nonwhite_star &lt;- density(pred_aware_fpt_nonwhite_star)\n\nplot(\n  d_aware_factuals_nonwhite,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_nonwhite, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_fpt_nonwhite_star, col = alpha(colours_all[[\"fairadapt\"]], .5), border = NA)\ntext(x = .4, y = 6, \"fairadapt\", col = colours_all[[\"fairadapt\"]])\n\n\n# Sequential transport\ntb_aware_seq &lt;- tb_aware |&gt; filter(counterfactual == \"seq\")\n# Predicted values, focusing on Non-White --&gt; White\npred_aware_seq_nonwhite_star &lt;- tb_aware_seq |&gt; filter(race == \"White\") |&gt; pull(\"pred\")\n# Estimated densities\nd_aware_seq_nonwhite_star &lt;- density(pred_aware_seq_nonwhite_star)\n\nplot(\n  d_aware_factuals_nonwhite,\n  main = \"\", xlab = \"\", ylab = \"\",\n  axes = FALSE, col = NA,\n  xlim = x_lim, ylim = y_lim\n)\naxis(1)\naxis(2)\npolygon(d_aware_factuals_nonwhite, col = alpha(colours_all[[\"source\"]], .5), border = NA)\nlines(d_aware_factuals_white, col = colours_all[[\"reference\"]], lty = 2, lwd = 2)\npolygon(d_aware_seq_nonwhite_star, col = alpha(colours_all[[\"seq\"]], .5), border = NA)\ntext(x = .4, y = 6, \"Seq. T.\", col = colours_all[[\"seq\"]])\n\n\n\n\n\nFigure 14.20: Densities of predicted scores for Non-White individuals with factuals and with counterfactuals. The yellow dashed line corresponds to the density of predicted scores for Non-White individuals, using factuals.",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "example-compas.html#metrics",
    "href": "example-compas.html#metrics",
    "title": "14  COMPAS Dataset",
    "section": "14.6 Metrics",
    "text": "14.6 Metrics\n\n\n\n\n\n\nWarning\n\n\n\nThis section is still under construction. Results may not correct. The metrics used should be changed soon.\n\n\nLet us compute a few metrics metrics, such as the accuracy, the log-loss, and the Brier Score, as well as the counterfactual demographic parity. For the accuracy, we define the set the probability threshold to .5.\nThe counterfactual demographic parity writes:\n\\[\n\\mathrm{CDP}=\\frac{1}{n_0}\\sum_{i\\in\\mathcal{D}_0}m(1,\\boldsymbol{x}_{i}^\\star) - m(0,\\boldsymbol{x}_{i}),\n\\] where \\(n_0\\) is the number of Non-White individuals in the sample, \\(m()\\) is the classifier, with \\(m(1,\\boldsymbol{x}_{i}^\\star)\\) the score returned when the sensitive attribute is \\(S=1\\), i.e., “White” and \\(\\boldsymbol{x}_{i}^\\star\\) are the counterfactual values, \\(m(0,\\boldsymbol{x}_{i})\\) is the score returned by the model when using the factuals.\nWe compute the Equalized Odds criterion as the absolute difference between true positive rate (TPR) across the two groups (Non-White/White):\n\\[\nEO = | TPR_{\\text{Non-White}} - TPR_{\\text{White}} |\n\\]\nA binary predictor \\(\\hat{Y}\\) satisfies equal opportunity with respect to \\(S\\) and \\(Y\\) if Hardt, Price, and Srebro (2016): \\[\nP\\big(\\hat{Y} = 1 | S=0, Y=1 \\big) = P\\big(\\hat{Y} = 1 | S=1, Y=1 \\big)\n\\]\n\nprob_threshold &lt;- .5\n\n#' Log loss\n#' \n#' @param y vector or binary obsevations\n#' @param s vector of predicted scores\ncalculate_log_loss &lt;- function(y, s){\n  s_pred &lt;- pmin(pmax(s, 1e-15), 1 - 1e-15)\n  mean(-y*log(s_pred) - (1-y)*log(1-s_pred))\n}\n\n#' Brier Score\n#'\n#' The Brier Score \\citep{brier_1950}, is expressed as: \\deqn{\\text{BS} =\n#' \\frac{1}{n}\\sum_{i=1}^{n} \\big(\\hat{s}(\\mathbf{x}_i) - d_i\\big)^{2}} where\n#' \\eqn{d_i \\in \\{0,1\\}} is the observed event for observation \\eqn{i}.\n#'\n#' @param obs vector of observed binary events\n#' @param scores vector of scores\n#'\n#' @references Brier, G. W. (1950). Verification of forecasts expressed in terms\n#' of probability. Monthly Weather Review 78: 1–3.\n#'\n#' @export\nbrier_score &lt;- function(obs, scores) mean((scores - obs)^2)\n\nWe will then put in a table all the predictions made in each case: without using counterfactuals, and with using each counterfactual technique applied on Non-White individuals’ characteristics. Since we do not get counterfactual values for White individuals, their predictions remain unchanged in each case. We will therefore complete the dataset with their unchanged predictions.\n\ntb_complement_white &lt;- \n  factuals_aware |&gt; \n  select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n  filter(race_origin ==\"White\")\n\nWe put the predicted values in a table named tb_pred.\n\n\nCodes to create tb_pred.\ntb_pred_aware &lt;- \n  factuals_aware |&gt; \n  select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n  mutate(type = \"factual\") |&gt; \n  bind_rows(\n    counterfactuals_aware_naive_nonwhite |&gt; \n      select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n      bind_rows(tb_complement_white) |&gt; \n      mutate(type = \"naive\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_aware_fpt_nonwhite |&gt; \n      select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n      bind_rows(tb_complement_white) |&gt; \n      mutate(type = \"fairadapt\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_aware_seq_nonwhite |&gt; \n      left_join(\n        compas |&gt; mutate(id_indiv = row_number()) |&gt; \n          select(id_indiv, two_year_recid), by = \"id_indiv\"\n      ) |&gt; \n      bind_rows(tb_complement_white) |&gt; \n      select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n      mutate(type = \"seq\")\n  ) |&gt; \n  mutate(\n    y_binary = as.numeric(two_year_recid),\n    pred_class = ifelse(pred &gt; prob_threshold, 1, 0),\n    pred_correct = two_year_recid == pred_class\n  )\n\ntb_pred_unaware &lt;- \n  factuals_unaware |&gt; \n  select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n  mutate(type = \"factual\") |&gt; \n  bind_rows(\n    counterfactuals_unaware_naive_nonwhite |&gt; \n      select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n      bind_rows(tb_complement_white) |&gt; \n      mutate(type = \"naive\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_unaware_fpt_nonwhite |&gt; \n      select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n      bind_rows(tb_complement_white) |&gt; \n      mutate(type = \"fairadapt\")\n  ) |&gt; \n  bind_rows(\n    counterfactuals_unaware_seq_nonwhite |&gt; \n      left_join(\n        compas |&gt; mutate(id_indiv = row_number()) |&gt; \n          select(id_indiv, two_year_recid), by = \"id_indiv\") |&gt; \n      bind_rows(tb_complement_white) |&gt; \n      select(id_indiv, race, race_origin, two_year_recid, pred) |&gt; \n      mutate(type = \"seq\")\n  ) |&gt; \n  mutate(\n    y_binary = as.numeric(two_year_recid),\n    pred_class = ifelse(pred &gt; prob_threshold, 1, 0),\n    pred_correct = two_year_recid == pred_class\n  )\n\ntb_pred &lt;- \n  tb_pred_aware |&gt; mutate(model = \"aware\") |&gt; \n  bind_rows(\n    tb_pred_unaware |&gt; mutate(model = \"unaware\")\n  ) |&gt; \n  mutate(\n    model = factor(\n      model, levels = c(\"aware\", \"unaware\"),\n      labels = c(\"Aware model\", \"Unware model\")\n    ),\n    type = factor(type, levels = c(\"factual\", \"naive\", \"fairadapt\", \"seq\"))\n  )\n\n\nWe compute some metrics on the whole sample, in each case:\n\noverall_perf_metrics &lt;- \n  tb_pred |&gt; \n  group_by(model, type) |&gt; \n  summarise(\n    mean = mean(pred),\n    eq_opp_pos = sum(pred * (y_binary == 1)) / (sum(y_binary == 1)),\n    eq_opp_neg = sum(pred * (y_binary == 0)) / (sum(y_binary == 0)),\n    acc = mean(pred_correct),\n    ll = calculate_log_loss(y_binary, pred),\n    bs = brier_score(y_binary, pred),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(race_origin = \"Whole\")\noverall_perf_metrics\n\n# A tibble: 8 × 9\n  model        type     mean eq_opp_pos eq_opp_neg   acc    ll    bs race_origin\n  &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      \n1 Aware model  factual 0.458      0.537      0.393 0.674 0.614 0.212 Whole      \n2 Aware model  naive   0.474      0.554      0.409 0.678 0.615 0.212 Whole      \n3 Aware model  fairad… 0.443      0.510      0.400 0.661 0.625 0.217 Whole      \n4 Aware model  seq     0.472      0.542      0.414 0.638 0.657 0.229 Whole      \n5 Unware model factual 0.458      0.537      0.394 0.679 0.614 0.211 Whole      \n6 Unware model naive   0.463      0.542      0.399 0.678 0.614 0.212 Whole      \n7 Unware model fairad… 0.432      0.498      0.389 0.664 0.622 0.216 Whole      \n8 Unware model seq     0.463      0.532      0.406 0.639 0.655 0.229 Whole      \n\n\nAnd then we compute the same metrics but within the group of Non-White individuals and within the group of White individuals.\n\ngroup_perf_metrics &lt;- \n  tb_pred |&gt; \n  group_by(model, type, race_origin) |&gt; \n  summarise(\n    mean = mean(pred),\n    eq_opp_pos = sum(pred * (y_binary == 1)) / (sum(y_binary == 1)),\n    eq_opp_neg = sum(pred * (y_binary == 0)) / (sum(y_binary == 0)),\n    acc = mean(pred_correct),\n    ll = calculate_log_loss(y_binary, pred),\n    bs = brier_score(y_binary, pred),\n    .groups = \"drop\"\n  )\ngroup_perf_metrics\n\n# A tibble: 16 × 9\n   model        type   race_origin  mean eq_opp_pos eq_opp_neg   acc    ll    bs\n   &lt;fct&gt;        &lt;fct&gt;  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aware model  factu… Non-White   0.481      0.557      0.410 0.676 0.615 0.212\n 2 Aware model  factu… White       0.414      0.489      0.365 0.670 0.612 0.212\n 3 Aware model  naive  Non-White   0.505      0.582      0.435 0.683 0.616 0.212\n 4 Aware model  naive  White       0.414      0.489      0.365 0.670 0.612 0.212\n 5 Aware model  faira… Non-White   0.458      0.520      0.417 0.656 0.631 0.220\n 6 Aware model  faira… White       0.414      0.489      0.365 0.670 0.612 0.212\n 7 Aware model  seq    Non-White   0.502      0.565      0.444 0.621 0.679 0.238\n 8 Aware model  seq    White       0.414      0.489      0.365 0.670 0.612 0.212\n 9 Unware model factu… Non-White   0.489      0.565      0.419 0.681 0.615 0.212\n10 Unware model factu… White       0.399      0.473      0.351 0.673 0.611 0.211\n11 Unware model naive  Non-White   0.489      0.565      0.419 0.681 0.615 0.212\n12 Unware model naive  White       0.414      0.489      0.365 0.670 0.612 0.212\n13 Unware model faira… Non-White   0.441      0.503      0.401 0.661 0.627 0.218\n14 Unware model faira… White       0.414      0.489      0.365 0.670 0.612 0.212\n15 Unware model seq    Non-White   0.488      0.550      0.430 0.623 0.677 0.237\n16 Unware model seq    White       0.414      0.489      0.365 0.670 0.612 0.212\n\n\nWe compute the Counterfactual Demographic Parity:\n\npred_nonwhite_factuals &lt;- \n  tb_pred |&gt; filter(type == \"factual\") |&gt; \n  filter(race_origin ==\"Non-White\") |&gt; \n  select(model, id_indiv, pred_origin = pred)\n\ncdp &lt;- tb_pred |&gt; \n  filter(race_origin ==\"Non-White\") |&gt; \n  left_join(pred_nonwhite_factuals, by = c(\"id_indiv\", \"model\")) |&gt; \n  group_by(model, type) |&gt; \n  summarise(\n    CDP = mean(pred - pred_origin),\n    .groups = \"drop\"\n  )\n\nThe summary of the metrics are shown in Table 14.1.\n\n\nCodes used to create the Table.\ntbl_print &lt;- \n  group_perf_metrics |&gt; filter(race_origin ==\"Non-White\") |&gt; \n  left_join(cdp, by = c(\"model\", \"type\")) |&gt; \n  pivot_longer(cols = -c(\"model\", \"type\", \"race_origin\")) |&gt; \n  pivot_wider(names_from = type, values_from = value) |&gt; \n  select(-race_origin) |&gt; \n  left_join(\n    group_perf_metrics |&gt; filter(race_origin ==\"White\" & type == \"factual\") |&gt; \n      pivot_longer(cols = -c(\"model\", \"type\", \"race_origin\"), values_to = \"factual_white\") |&gt; \n      select(model, name, factual_white),\n    by = c(\"model\", \"name\")\n  ) |&gt; \n  left_join(\n    overall_perf_metrics |&gt; \n      pivot_longer(cols = -c(\"model\", \"type\", \"race_origin\"), values_to = \"factual_whole\") |&gt; \n      filter(race_origin ==\"Whole\", type == \"factual\") |&gt; \n      select(model, name, factual_whole),\n    by = c(\"model\", \"name\")\n  ) |&gt; \n  select(\n    model, name, factual_whole, factual_white, factual_nonwhite = factual,\n    naive, fairadapt, seq\n  ) |&gt; \n  mutate(\n    name = factor(\n      name,\n      levels = c(\"CDP\", \"mean\", \"eq_opp_pos\", \"eq_opp_neg\", \"acc\", \"ll\", \"bs\"),\n      labels = c(\"CDP\", \"Mean\", \"Eq. Opp. Y=1\", \"Eq. Opp Y=0\", \"Accuracy\", \"Log-loss\", \"Brier Score\")\n    )\n  ) |&gt; \n  arrange(model, name)\n\ntbl_print[, -1] |&gt; \n  knitr::kable(\n    digits = 2,\n    col.names = c(\n      \"Metric\", \"Factual\", \"Factual\", \"Factual\", \"Naive\", \"Fairadapt\", \n      \"Seq. Transport\"\n    )\n  ) |&gt; \n  kableExtra::kable_styling() |&gt; \n  # kableExtra::pack_rows(index = table(tbl_print$race_origin))\n  # kableExtra::collapse_rows(columns = 1, valign = \"top\")\n  kableExtra::add_header_above(\n    c(\" \" = 1, \"Whole\" = \"1\", \"White\" = 1, \"Non-White\" = 4)\n  ) |&gt; \n  kableExtra::pack_rows(index = table(tbl_print$model))\n\n\n\n\nTable 14.1: Metrics computed on scores predicted by the classifier based on the factuals or the different versions of the counterfactuals, for the aware model (sensitive variable used to train the classifier) and the unaware model (sentitive variable not provided to train the classifier).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhole\n\n\nWhite\n\n\nNon-White\n\n\n\nMetric\nFactual\nFactual\nFactual\nNaive\nFairadapt\nSeq. Transport\n\n\n\n\nAware model\n\n\nCDP\nNA\nNA\n0.00\n0.02\n-0.02\n0.02\n\n\nMean\n0.46\n0.41\n0.48\n0.51\n0.46\n0.50\n\n\nEq. Opp. Y=1\n0.54\n0.49\n0.56\n0.58\n0.52\n0.56\n\n\nEq. Opp Y=0\n0.39\n0.37\n0.41\n0.43\n0.42\n0.44\n\n\nAccuracy\n0.67\n0.67\n0.68\n0.68\n0.66\n0.62\n\n\nLog-loss\n0.61\n0.61\n0.61\n0.62\n0.63\n0.68\n\n\nBrier Score\n0.21\n0.21\n0.21\n0.21\n0.22\n0.24\n\n\nUnware model\n\n\nCDP\nNA\nNA\n0.00\n0.00\n-0.05\n0.00\n\n\nMean\n0.46\n0.40\n0.49\n0.49\n0.44\n0.49\n\n\nEq. Opp. Y=1\n0.54\n0.47\n0.56\n0.56\n0.50\n0.55\n\n\nEq. Opp Y=0\n0.39\n0.35\n0.42\n0.42\n0.40\n0.43\n\n\nAccuracy\n0.68\n0.67\n0.68\n0.68\n0.66\n0.62\n\n\nLog-loss\n0.61\n0.61\n0.61\n0.61\n0.63\n0.68\n\n\nBrier Score\n0.21\n0.21\n0.21\n0.21\n0.22\n0.24\n\n\n\n\n\n\n\n\n\n\n\n\nLaTeX code\nknitr::kable(\n  tbl_print[, -1], format = \"latex\", booktabs = TRUE, digits = 2,\n) |&gt; \n  kableExtra::kable_styling(\"striped\", full_width = F) %&gt;%\n  kableExtra::add_header_above(\n    c(\" \" = 1, \"Whole\" = 1, \"White\" = 1, \"Non-White\" = 4)\n  ) |&gt; \n  kableExtra::pack_rows(index = table(tbl_print$model))\n\n\n\n# Brouillon\ntb_pred$type |&gt; unique()\n\n[1] factual   naive     fairadapt seq      \nLevels: factual naive fairadapt seq\n\nlvl_neg &lt;- 0\nlvl_pos &lt;- 1\n\ntb_pred |&gt; \n  group_by(model, type, race_origin) |&gt; \n  summarise(\n    TP = sum(two_year_recid == lvl_pos & pred_class == lvl_pos),\n    FP = sum(two_year_recid == lvl_neg & pred_class == lvl_pos),\n    FN = sum(two_year_recid == lvl_pos & pred_class == lvl_neg),\n    TN = sum(two_year_recid == lvl_neg & pred_class == lvl_neg),\n    P = TP + FN,\n    N = FP + TN\n  ) |&gt; \n  rowwise() |&gt; \n  mutate(\n    TPR = TP/P,\n    FPR = FN / N\n  ) |&gt; \n  group_by(model, type) |&gt; \n  mutate(\n    eq_odds_diff = abs(diff(TPR))\n  )\n\n`summarise()` has grouped output by 'model', 'type'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 16 × 12\n# Groups:   model, type [8]\n   model       type  race_origin    TP    FP    FN    TN     P     N   TPR   FPR\n   &lt;fct&gt;       &lt;fct&gt; &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aware model fact… Non-White    1307   564   978  1911  2285  2475 0.572 0.395\n 2 Aware model fact… White         435   278   531  1210   966  1488 0.450 0.357\n 3 Aware model naive Non-White    1537   763   748  1712  2285  2475 0.673 0.302\n 4 Aware model naive White         435   278   531  1210   966  1488 0.450 0.357\n 5 Aware model fair… Non-White     991   754   883  2132  1874  2886 0.529 0.306\n 6 Aware model fair… White         435   278   531  1210   966  1488 0.450 0.357\n 7 Aware model seq   Non-White    1484  1003   801  1472  2285  2475 0.649 0.324\n 8 Aware model seq   White         435   278   531  1210   966  1488 0.450 0.357\n 9 Unware mod… fact… Non-White    1391   623   894  1852  2285  2475 0.609 0.361\n10 Unware mod… fact… White         386   222   580  1266   966  1488 0.400 0.390\n11 Unware mod… naive Non-White    1391   623   894  1852  2285  2475 0.609 0.361\n12 Unware mod… naive White         435   278   531  1210   966  1488 0.450 0.357\n13 Unware mod… fair… Non-White     867   609  1007  2277  1874  2886 0.463 0.349\n14 Unware mod… fair… White         435   278   531  1210   966  1488 0.450 0.357\n15 Unware mod… seq   Non-White    1426   935   859  1540  2285  2475 0.624 0.347\n16 Unware mod… seq   White         435   278   531  1210   966  1488 0.450 0.357\n# ℹ 1 more variable: eq_odds_diff &lt;dbl&gt;\n\n\n\n\n\n\nHardt, Moritz, Eric Price, and Nati Srebro. 2016. “Equality of Opportunity in Supervised Learning.” Advances in Neural Information Processing Systems 29: 3315–23.\n\n\nLarson, Surya, Jeff ans Mattu, Lauren Kirchner, and Julia Angwin. 2016. “How We Analyzed the COMPAS Recidivism Algorithm.” Edited by ProPublica. https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data Adaptation with Quantile Preservation.” Journal of Machine Learning Research 21 (242): 1–44.",
    "crumbs": [
      "IV. Counterfactuals with Other Datasets",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>COMPAS Dataset</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Black, Emily, Samuel Yeom, and Matt Fredrikson. 2020. “Fliptest:\nFairness Testing via Optimal Transport.” In Proceedings of\nthe 2020 Conference on Fairness, Accountability, and Transparency,\n111–21.\n\n\nBonnotte, Nicolas. 2013. “From Knothe’s Rearrangement\nto Brenier’s Optimal Transport Map.” SIAM\nJournal on Mathematical Analysis 45 (1): 64–87.\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, and Jean-Michel\nLoubes. 2021. “Transport-Based Counterfactual Models.”\narXiv 2108.13025.\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser,\nand Jean-Michel Loubes. 2024. “Transport-Based Counterfactual\nModels.” Journal of Machine Learning Research 25 (136):\n1–59.\n\n\nHardt, Moritz, Eric Price, and Nati Srebro. 2016. “Equality of\nOpportunity in Supervised Learning.” Advances in Neural\nInformation Processing Systems 29: 3315–23.\n\n\nHigham, Nicholas J. 2008. Functions of Matrices: Theory and\nComputation. SIAM.\n\n\nKusner, Matt J, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017.\n“Counterfactual Fairness.” In Advances in Neural\nInformation Processing Systems 30, edited by I. Guyon, U. V.\nLuxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R.\nGarnett, 4066–76. NIPS.\n\n\nLarson, Surya, Jeff ans Mattu, Lauren Kirchner, and Julia Angwin. 2016.\n“How We Analyzed the COMPAS Recidivism Algorithm.” Edited\nby ProPublica. https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n\n\nPlečko, Drago, Nicolas Bennett, and Nicolai Meinshausen. 2021.\n“Fairadapt: Causal Reasoning for Fair Data Pre-Processing.”\narXiv Preprint arXiv:2110.10200.\n\n\nPlečko, Drago, and Nicolai Meinshausen. 2020. “Fair Data\nAdaptation with Quantile Preservation.” Journal of Machine\nLearning Research 21 (242): 1–44.\n\n\nTakatsu, Asuka. 2011. “Wasserstein Geometry of Gaussian\nMeasures.” Osaka Journal of Mathematics 48 (4): 1005–26.\n\n\nWightman, Linda F. 1998. “LSAC National Longitudinal Bar Passage\nStudy. LSAC Research Report Series.” In. https://api.semanticscholar.org/CorpusID:151073942.\n\n\nZech, Jakob, and Youssef Marzouk. 2022. “Sparse Approximation of\nTriangular Transports, Part I: The Finite-Dimensional\nCase.” Constructive Approximation 55 (3): 919–86.",
    "crumbs": [
      "References"
    ]
  }
]